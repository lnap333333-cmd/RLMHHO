#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„RL-Chaotic-HHOç®—æ³•æµ‹è¯•
æµ‹è¯•å››å±‚é¹°ç¾¤åˆ†ç»„åä½œå’Œå¼ºåŒ–å­¦ä¹ è°ƒåº¦å™¨çš„å®ç°
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.visualization import ResultVisualizer

def test_four_layer_grouping():
    """æµ‹è¯•å››å±‚é¹°ç¾¤åˆ†ç»„æœºåˆ¶"""
    print("=" * 80)
    print("ğŸ¦… å››å±‚é¹°ç¾¤åˆ†ç»„åä½œæœºåˆ¶æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•é—®é¢˜
    data_gen = DataGenerator()
    problem_data = data_gen.generate_problem(
        n_jobs=30,
        n_factories=3,
        n_stages=3,
        machines_per_stage=[2, 3, 2],
        processing_time_range=(1, 10)
    )
    
    problem = MO_DHFSP_Problem(problem_data)
    
    # åˆå§‹åŒ–ä¼˜åŒ–å™¨
    optimizer = RL_ChaoticHHO_Optimizer(problem, max_iterations=30)
    
    print(f"\nğŸ“Š åˆ†ç»„é…ç½®éªŒè¯:")
    print(f"  æ¢ç´¢ç»„å¤§å°: {len(optimizer.eagle_groups.get_group('exploration'))}")
    print(f"  å¼€å‘ç»„å¤§å°: {len(optimizer.eagle_groups.get_group('exploitation'))}")
    print(f"  å¹³è¡¡ç»„å¤§å°: {len(optimizer.eagle_groups.get_group('balance'))}")
    print(f"  ç²¾è‹±ç»„å¤§å°: {len(optimizer.eagle_groups.get_group('elite'))}")
    
    # éªŒè¯åˆ†ç»„è¦†ç›–æ€§
    total_assigned = sum(len(optimizer.eagle_groups.get_group(g)) 
                        for g in ['exploration', 'exploitation', 'balance', 'elite'])
    print(f"  æ€»åˆ†é…ä¸ªä½“: {total_assigned}/{optimizer.population_size}")
    
    return optimizer, problem

def test_reinforcement_learning():
    """æµ‹è¯•å¼ºåŒ–å­¦ä¹ è°ƒåº¦å™¨"""
    print("\nğŸ¤– å¼ºåŒ–å­¦ä¹ è°ƒåº¦å™¨æµ‹è¯•")
    print("-" * 60)
    
    optimizer, problem = test_four_layer_grouping()
    
    # æµ‹è¯•çŠ¶æ€è·å–
    optimizer._initialize_population()
    state = optimizer._get_current_state()
    print(f"çŠ¶æ€å‘é‡ç»´åº¦: {len(state)}")
    print(f"çŠ¶æ€å‘é‡: {state[:5]}... (æ˜¾ç¤ºå‰5ç»´)")
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
    action = optimizer.rl_coordinator.select_action(state)
    print(f"é€‰æ‹©çš„ç­–ç•¥: {action} - {optimizer.rl_coordinator.action_space[action]}")
    
    # æµ‹è¯•ç­–ç•¥æ‰§è¡Œ
    print(f"\næ‰§è¡Œç­–ç•¥: {optimizer.rl_coordinator.action_space[action]}")
    optimizer._execute_strategy(action)
    
    # è·å–åŠ¨ä½œæ¨è
    recommendations = optimizer.rl_coordinator.get_action_recommendations(state)
    print(f"\nç­–ç•¥æ¨èæ’åº:")
    for i, (action_name, confidence) in enumerate(recommendations[:3]):
        print(f"  {i+1}. {action_name}: {confidence:.3f}")
    
    return optimizer

def test_chaotic_maps():
    """æµ‹è¯•å¢å¼ºæ··æ²Œæ˜ å°„ç³»ç»Ÿ"""
    print("\nğŸŒ€ å¢å¼ºæ··æ²Œæ˜ å°„ç³»ç»Ÿæµ‹è¯•")
    print("-" * 60)
    
    from algorithm.chaotic_maps import ChaoticMaps
    
    chaos_maps = ChaoticMaps()
    
    # æµ‹è¯•å„ç§æ˜ å°„
    print("å„æ˜ å°„ç”Ÿæˆçš„æ··æ²Œå€¼:")
    print(f"  Logisticæ˜ å°„: {chaos_maps.logistic_map():.4f}")
    print(f"  Tentæ˜ å°„: {chaos_maps.tent_map():.4f}")
    print(f"  Sineæ˜ å°„: {chaos_maps.sine_map():.4f}")
    print(f"  Chebyshevæ˜ å°„: {chaos_maps.chebyshev_map():.4f}")
    
    # æµ‹è¯•ç»„ä¸“ç”¨æ··æ²Œå€¼
    print(f"\nå„ç»„ä¸“ç”¨æ··æ²Œå€¼:")
    for group in ['exploration', 'exploitation', 'balance', 'elite']:
        values = chaos_maps.get_group_chaos_values(group, 3)
        print(f"  {group}: {[f'{v:.4f}' for v in values]}")
    
    # æµ‹è¯•å¢å¼ºæ··æ²Œåºåˆ—
    enhanced_seq = chaos_maps.enhanced_chaos_sequence(5, intensity=0.7, diversity_boost=True)
    print(f"\nå¢å¼ºæ··æ²Œåºåˆ—: {[f'{v:.4f}' for v in enhanced_seq]}")
    
    return chaos_maps

def test_complete_optimization():
    """æµ‹è¯•å®Œæ•´ä¼˜åŒ–æµç¨‹"""
    print("\nğŸ¯ å®Œæ•´ä¼˜åŒ–æµç¨‹æµ‹è¯•")
    print("-" * 60)
    
    # åˆ›å»ºä¸­ç­‰è§„æ¨¡æµ‹è¯•é—®é¢˜
    data_gen = DataGenerator()
    problem_data = data_gen.generate_problem(
        n_jobs=20,
        n_factories=2,
        n_stages=3,
        machines_per_stage=[2, 2, 2],
        processing_time_range=(1, 8)
    )
    
    problem = MO_DHFSP_Problem(problem_data)
    
    # è¿è¡Œä¼˜åŒ–
    print(f"é—®é¢˜è§„æ¨¡: {problem.n_jobs}ä½œä¸š Ã— {problem.n_factories}å·¥å‚ Ã— {problem.n_stages}é˜¶æ®µ")
    
    optimizer = RL_ChaoticHHO_Optimizer(problem, max_iterations=25)
    
    start_time = time.time()
    pareto_solutions, convergence_data = optimizer.optimize()
    end_time = time.time()
    
    print(f"\nâœ… ä¼˜åŒ–å®Œæˆ!")
    print(f"è¿è¡Œæ—¶é—´: {end_time - start_time:.2f}ç§’")
    print(f"å¸•ç´¯æ‰˜è§£æ•°é‡: {len(pareto_solutions)}")
    
    if pareto_solutions:
        best_makespan = min(sol.makespan for sol in pareto_solutions)
        best_tardiness = min(sol.total_tardiness for sol in pareto_solutions)
        print(f"æœ€ä¼˜å®Œå·¥æ—¶é—´: {best_makespan:.2f}")
        print(f"æœ€ä¼˜æ€»æ‹–æœŸ: {best_tardiness:.2f}")
    
    # è·å–è¯¦ç»†ç»Ÿè®¡
    stats = optimizer.get_algorithm_statistics()
    print(f"\nğŸ“ˆ ç®—æ³•ç»Ÿè®¡:")
    print(f"  æ€»è¿­ä»£æ¬¡æ•°: {stats['iteration']}")
    print(f"  åœæ»æ¬¡æ•°: {stats['no_improvement_count']}")
    
    # ç»„æ€§èƒ½ç»Ÿè®¡
    if 'group_performance' in stats:
        print(f"\nğŸ¦… åˆ†ç»„æ€§èƒ½:")
        for group_name, performance in stats['group_performance'].items():
            print(f"  {group_name}: å¹³å‡={performance['average']:.4f}, "
                  f"æœ€æ–°={performance['latest']:.4f}, è¶‹åŠ¿={performance['trend']:.4f}")
    
    # RLç»Ÿè®¡
    if 'rl_statistics' in stats:
        rl_stats = stats['rl_statistics']
        print(f"\nğŸ¤– å¼ºåŒ–å­¦ä¹ ç»Ÿè®¡:")
        print(f"  è®­ç»ƒæ­¥æ•°: {rl_stats['training_steps']}")
        print(f"  æ¢ç´¢ç‡: {rl_stats['epsilon']:.4f}")
        print(f"  ç»éªŒæ± å¤§å°: {rl_stats['memory_size']}")
        print(f"  å¹³å‡æŸå¤±: {rl_stats['average_loss']:.6f}")
    
    # ç­–ç•¥ä½¿ç”¨ç»Ÿè®¡
    if 'strategy_statistics' in stats:
        print(f"\nğŸ“Š ç­–ç•¥ä½¿ç”¨ç»Ÿè®¡:")
        for strategy, stat in stats['strategy_statistics'].items():
            print(f"  {strategy}: ä½¿ç”¨{stat['usage_count']}æ¬¡ "
                  f"(æ¯”ä¾‹={stat['usage_rate']:.3f}, æˆåŠŸç‡={stat['success_rate']:.3f})")
    
    return optimizer, pareto_solutions, convergence_data

def test_adaptive_mechanisms():
    """æµ‹è¯•è‡ªé€‚åº”æœºåˆ¶"""
    print("\nğŸ”„ è‡ªé€‚åº”æœºåˆ¶æµ‹è¯•")
    print("-" * 60)
    
    optimizer, pareto_solutions, convergence_data = test_complete_optimization()
    
    # æµ‹è¯•ç»„æ€§èƒ½ç»Ÿè®¡
    group_stats = optimizer.eagle_groups.get_group_statistics()
    print("åˆ†ç»„ç»Ÿè®¡ä¿¡æ¯:")
    for group_name, stats in group_stats.items():
        print(f"  {group_name}: å¤§å°={stats['size']}, æ¯”ä¾‹={stats['ratio']:.3f}, "
              f"è´¨é‡={stats['average_quality']:.4f}")
    
    # æµ‹è¯•æ··æ²Œæ˜ å°„ç»Ÿè®¡
    chaos_stats = optimizer.chaotic_maps.get_chaos_statistics()
    if chaos_stats:
        print(f"\næ··æ²Œæ˜ å°„ä½¿ç”¨ç»Ÿè®¡:")
        for map_type, stats in chaos_stats.items():
            print(f"  {map_type}: ä½¿ç”¨{stats['usage_count']}æ¬¡ "
                  f"(æ¯”ä¾‹={stats['usage_rate']:.3f}, å½“å‰å€¼={stats['current_state']:.4f})")
    
    return optimizer

def create_performance_visualization(optimizer, pareto_solutions):
    """åˆ›å»ºæ€§èƒ½å¯è§†åŒ–"""
    print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½å¯è§†åŒ–å›¾è¡¨")
    print("-" * 60)
    
    try:
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('RL-Chaotic-HHO å››å±‚åˆ†ç»„åä½œæ€§èƒ½åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. å¸•ç´¯æ‰˜å‰æ²¿
        if pareto_solutions:
            makespans = [sol.makespan for sol in pareto_solutions]
            tardiness = [sol.total_tardiness for sol in pareto_solutions]
            
            axes[0, 0].scatter(makespans, tardiness, c='red', alpha=0.6, s=50)
            axes[0, 0].set_xlabel('å®Œå·¥æ—¶é—´ (Makespan)')
            axes[0, 0].set_ylabel('æ€»æ‹–æœŸ (Total Tardiness)')
            axes[0, 0].set_title('å¸•ç´¯æ‰˜å‰æ²¿')
            axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ç»„æ€§èƒ½è¶‹åŠ¿
        group_colors = {'exploration': 'blue', 'exploitation': 'green', 
                       'balance': 'orange', 'elite': 'purple'}
        
        for group_name, history in optimizer.group_performance_history.items():
            if history:
                axes[0, 1].plot(history, label=f'{group_name}ç»„', 
                               color=group_colors.get(group_name, 'black'))
        
        axes[0, 1].set_xlabel('è¿­ä»£æ¬¡æ•°')
        axes[0, 1].set_ylabel('ç»„æ€§èƒ½åˆ†æ•°')
        axes[0, 1].set_title('å„ç»„æ€§èƒ½è¶‹åŠ¿')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. RLå¥–åŠ±å†å²
        if hasattr(optimizer, 'rl_reward_history') and optimizer.rl_reward_history:
            axes[1, 0].plot(optimizer.rl_reward_history, 'g-', alpha=0.7)
            axes[1, 0].set_xlabel('è¿­ä»£æ¬¡æ•°')
            axes[1, 0].set_ylabel('RLå¥–åŠ±')
            axes[1, 0].set_title('å¼ºåŒ–å­¦ä¹ å¥–åŠ±å†å²')
            axes[1, 0].grid(True, alpha=0.3)
        else:
            axes[1, 0].text(0.5, 0.5, 'æš‚æ— RLå¥–åŠ±æ•°æ®', ha='center', va='center', 
                           transform=axes[1, 0].transAxes)
            axes[1, 0].set_title('å¼ºåŒ–å­¦ä¹ å¥–åŠ±å†å²')
        
        # 4. ç­–ç•¥ä½¿ç”¨åˆ†å¸ƒ
        rl_stats = optimizer.rl_coordinator.get_strategy_statistics()
        if rl_stats:
            strategies = list(rl_stats.keys())
            usage_counts = [rl_stats[s]['usage_count'] for s in strategies]
            
            axes[1, 1].pie(usage_counts, labels=strategies, autopct='%1.1f%%', startangle=90)
            axes[1, 1].set_title('ç­–ç•¥ä½¿ç”¨åˆ†å¸ƒ')
        else:
            axes[1, 1].text(0.5, 0.5, 'æš‚æ— ç­–ç•¥ç»Ÿè®¡æ•°æ®', ha='center', va='center',
                           transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('ç­–ç•¥ä½¿ç”¨åˆ†å¸ƒ')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"results/complete_rl_chaotic_hho_test_{timestamp}.png"
        os.makedirs('results', exist_ok=True)
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… æ€§èƒ½å›¾è¡¨å·²ä¿å­˜: {filename}")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨æ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ RL-Chaotic-HHO å®Œæ•´å®ç°æµ‹è¯•")
    print("=" * 80)
    
    try:
        # 1. æµ‹è¯•å››å±‚åˆ†ç»„æœºåˆ¶
        optimizer = test_four_layer_grouping()[0]
        
        # 2. æµ‹è¯•å¼ºåŒ–å­¦ä¹ è°ƒåº¦å™¨
        test_reinforcement_learning()
        
        # 3. æµ‹è¯•æ··æ²Œæ˜ å°„ç³»ç»Ÿ
        test_chaotic_maps()
        
        # 4. æµ‹è¯•å®Œæ•´ä¼˜åŒ–æµç¨‹
        optimizer, pareto_solutions, convergence_data = test_complete_optimization()
        
        # 5. æµ‹è¯•è‡ªé€‚åº”æœºåˆ¶
        test_adaptive_mechanisms()
        
        # 6. åˆ›å»ºæ€§èƒ½å¯è§†åŒ–
        create_performance_visualization(optimizer, pareto_solutions)
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("=" * 80)
        print("âœ… å››å±‚é¹°ç¾¤åˆ†ç»„åä½œæœºåˆ¶: æ­£å¸¸")
        print("âœ… å¼ºåŒ–å­¦ä¹ è°ƒåº¦å™¨: æ­£å¸¸")  
        print("âœ… å¢å¼ºæ··æ²Œæ˜ å°„ç³»ç»Ÿ: æ­£å¸¸")
        print("âœ… å®Œæ•´ä¼˜åŒ–æµç¨‹: æ­£å¸¸")
        print("âœ… è‡ªé€‚åº”æœºåˆ¶: æ­£å¸¸")
        print("âœ… æ€§èƒ½å¯è§†åŒ–: æ­£å¸¸")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 