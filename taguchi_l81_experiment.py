#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•L81ç”°å£æ­£äº¤å®éªŒè®¾è®¡
é’ˆå¯¹100Ã—5Ã—3è§„æ¨¡ï¼Œæ€»æœºå™¨æ•°40çš„MO-DHFSPé—®é¢˜
4ä¸ªå‚æ•°9ä¸ªæ°´å¹³çš„å…¨é¢å‚æ•°è°ƒä¼˜å®éªŒ
è¯„ä»·æŒ‡æ ‡ï¼šè¶…ä½“ç§¯:IGD:GD = 5:3:2
"""

import numpy as np
import pandas as pd
import time
import json
import pickle
from datetime import datetime
from typing import List, Dict, Tuple, Any
import logging
import os

# å¯¼å…¥ç®—æ³•å’Œé—®é¢˜å®šä¹‰
from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('taguchi_l81_experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TaguchiL81Experiment:
    """L81ç”°å£æ­£äº¤å®éªŒä¸»æ§åˆ¶ç±» - 4å‚æ•°9æ°´å¹³"""
    
    def __init__(self):
        self.problem_config = {
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'total_machines': 40,
            'processing_time_range': (1, 10),
            'due_date_tightness': 1.5,
            'random_seed': 2025
        }
        
        # L81æ­£äº¤è¡¨å‚æ•°é…ç½® - 4å‚æ•°9æ°´å¹³
        self.factor_levels = self._initialize_factor_levels()
        self.l81_design = self._generate_l81_design()
        
        # å®éªŒæ§åˆ¶å‚æ•°
        self.runs_per_experiment = 5  # æ¯ç»„å®éªŒé‡å¤5æ¬¡
        self.max_iterations = 50     # ç®—æ³•è¿­ä»£æ¬¡æ•°
        
        # ç»“æœå­˜å‚¨
        self.results_dir = f"taguchi_l81_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # æ€§èƒ½è¯„ä¼°å™¨
        self.metrics_evaluator = MetricsEvaluator()
        
    def _initialize_factor_levels(self) -> Dict:
        """åˆå§‹åŒ–4å› å­9æ°´å¹³å‚æ•°"""
        return {
            'A_learning_rate': {
                1: 0.00001,  # æä½å­¦ä¹ ç‡
                2: 0.00005,  # å¾ˆä½å­¦ä¹ ç‡
                3: 0.0001,   # ä½å­¦ä¹ ç‡
                4: 0.0005,   # ä¸­ä½å­¦ä¹ ç‡
                5: 0.001,    # ä¸­ç­‰å­¦ä¹ ç‡
                6: 0.002,    # ä¸­é«˜å­¦ä¹ ç‡
                7: 0.005,    # é«˜å­¦ä¹ ç‡
                8: 0.01,     # å¾ˆé«˜å­¦ä¹ ç‡
                9: 0.02      # æé«˜å­¦ä¹ ç‡
            },
            'B_epsilon_decay': {
                1: 0.985,    # å¿«é€Ÿè¡°å‡
                2: 0.988,    # è¾ƒå¿«è¡°å‡
                3: 0.990,    # ä¸­å¿«è¡°å‡
                4: 0.993,    # ä¸­ç­‰è¡°å‡
                5: 0.995,    # æ ‡å‡†è¡°å‡
                6: 0.997,    # æ…¢è¡°å‡
                7: 0.999,    # å¾ˆæ…¢è¡°å‡
                8: 0.9995,   # ææ…¢è¡°å‡
                9: 0.9999    # æœ€æ…¢è¡°å‡
            },
            'C_group_ratios': {
                1: [0.80, 0.10, 0.07, 0.03],  # æç«¯æ¢ç´¢ä¸»å¯¼
                2: [0.70, 0.15, 0.10, 0.05],  # è¶…çº§æ¢ç´¢ä¸»å¯¼
                3: [0.60, 0.20, 0.15, 0.05],  # å¼ºæ¢ç´¢ä¸»å¯¼
                4: [0.50, 0.30, 0.15, 0.05],  # æ¢ç´¢ä¸»å¯¼
                5: [0.45, 0.25, 0.20, 0.10],  # åŸºå‡†å¹³è¡¡
                6: [0.35, 0.40, 0.20, 0.05],  # å¼€å‘ä¸»å¯¼
                7: [0.25, 0.45, 0.20, 0.10],  # å¼ºå¼€å‘ä¸»å¯¼
                8: [0.20, 0.50, 0.20, 0.10],  # è¶…çº§å¼€å‘ä¸»å¯¼
                9: [0.15, 0.55, 0.20, 0.10]   # æç«¯å¼€å‘ä¸»å¯¼
            },
            'D_gamma': {
                1: 0.75,     # çŸ­æœŸè®°å¿†
                2: 0.80,     # è¾ƒçŸ­è®°å¿†
                3: 0.85,     # ä¸­çŸ­è®°å¿†
                4: 0.90,     # ä¸­ç­‰è®°å¿†
                5: 0.95,     # æ ‡å‡†è®°å¿†
                6: 0.98,     # é•¿è®°å¿†
                7: 0.99,     # å¾ˆé•¿è®°å¿†
                8: 0.995,    # æé•¿è®°å¿†
                9: 0.999     # æœ€é•¿è®°å¿†
            }
        }
    
    def _generate_l81_design(self) -> List[Dict]:
        """ç”ŸæˆL81(9^4)æ­£äº¤è¡¨è®¾è®¡"""
        l81_experiments = []
        exp_id = 1
        
        # ç”ŸæˆL81æ­£äº¤è¡¨ï¼ˆ9^4è®¾è®¡ï¼‰
        for a in range(1, 10):  # Aå› å­ï¼š9ä¸ªæ°´å¹³
            for b in range(1, 10):  # Bå› å­ï¼š9ä¸ªæ°´å¹³
                if exp_id > 81:  # é™åˆ¶ä¸º81ç»„å®éªŒ
                    break
                c = ((a - 1) + (b - 1)) % 9 + 1  # Cå› å­ï¼šåŸºäºAå’ŒBè®¡ç®—
                d = ((a - 1) * 2 + (b - 1) * 3) % 9 + 1  # Då› å­ï¼šåŸºäºAå’ŒBçš„å¤åˆè®¡ç®—
                
                l81_experiments.append({
                    'exp_id': exp_id,
                    'A': a,
                    'B': b,
                    'C': c,
                    'D': d
                })
                exp_id += 1
            
            if exp_id > 81:  # é™åˆ¶ä¸º81ç»„å®éªŒ
                break
        
        return l81_experiments
    
    def generate_problem_instance(self) -> MO_DHFSP_Problem:
        """ç”Ÿæˆæ ‡å‡†åŒ–çš„é—®é¢˜å®ä¾‹"""
        logger.info("ç”Ÿæˆ100Ã—5Ã—3è§„æ¨¡é—®é¢˜å®ä¾‹ï¼Œæ€»æœºå™¨æ•°40")
        
        generator = DataGenerator(seed=self.problem_config['random_seed'])
        
        # åˆ†é…å„å·¥å‚å„é˜¶æ®µçš„æœºå™¨æ•°é‡ï¼Œç¡®ä¿æ€»æ•°ä¸º40
        machines_config = self._distribute_machines()
        
        problem_data = generator.generate_problem(
            n_jobs=self.problem_config['n_jobs'],
            n_factories=self.problem_config['n_factories'],
            n_stages=self.problem_config['n_stages'],
            machines_per_stage=machines_config[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥å‚çš„é…ç½®ä½œä¸ºåŸºå‡†
            processing_time_range=self.problem_config['processing_time_range'],
            due_date_tightness=self.problem_config['due_date_tightness']
        )
        
        # æ·»åŠ å¤šå·¥å‚æœºå™¨é…ç½®ä¿¡æ¯ï¼ˆä½¿ç”¨æ•´æ•°é”®ï¼‰
        problem_data['factory_machines'] = {
            i: machines_config[i] for i in range(len(machines_config))
        }
        
        problem = MO_DHFSP_Problem(problem_data)
        
        # ä¿å­˜é—®é¢˜å®ä¾‹
        with open(f"{self.results_dir}/problem_instance.pkl", 'wb') as f:
            pickle.dump(problem, f)
        
        logger.info(f"é—®é¢˜å®ä¾‹å·²ä¿å­˜ï¼Œæ€»æœºå™¨æ•°: {sum(sum(stage) for stage in machines_config)}")
        return problem
    
    def _distribute_machines(self) -> List[List[int]]:
        """åˆ†é…40å°æœºå™¨åˆ°5ä¸ªå·¥å‚3ä¸ªé˜¶æ®µ"""
        # ç¡®ä¿å¼‚æ„é…ç½®ï¼Œæ¯ä¸ªå·¥å‚æ¯ä¸ªé˜¶æ®µè‡³å°‘1å°æœºå™¨
        machines_config = [
            [3, 2, 2],  # å·¥å‚1: 7å°æœºå™¨
            [3, 3, 2],  # å·¥å‚2: 8å°æœºå™¨  
            [2, 3, 3],  # å·¥å‚3: 8å°æœºå™¨
            [3, 2, 3],  # å·¥å‚4: 8å°æœºå™¨
            [3, 3, 3]   # å·¥å‚5: 9å°æœºå™¨
        ]
        # æ€»è®¡: 7+8+8+8+9 = 40å°æœºå™¨
        return machines_config
    
    def run_single_experiment(self, exp_config: Dict, run_id: int, problem: MO_DHFSP_Problem) -> Dict:
        """è¿è¡Œå•æ¬¡å®éªŒ"""
        exp_id = exp_config['exp_id']
        
        # è·å–å®éªŒå‚æ•°
        params = self._get_experiment_parameters(exp_config)
        
        logger.info(f"å®éªŒ{exp_id}-è¿è¡Œ{run_id}: LR={params['learning_rate']:.5f}, "
                   f"Decay={params['epsilon_decay']:.4f}, "
                   f"Groups={params['group_ratios']}, "
                   f"Gamma={params['gamma']:.3f}")
        
        start_time = time.time()
        
        try:
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = RL_ChaoticHHO_Optimizer(problem, **params)
            
            # è¿è¡Œä¼˜åŒ–
            pareto_solutions, convergence_data = optimizer.optimize()
            runtime = time.time() - start_time
            
            # è¯„ä¼°æ€§èƒ½
            metrics = self.metrics_evaluator.evaluate_performance(
                pareto_solutions, problem, runtime
            )
            
            result = {
                'exp_id': exp_id,
                'run_id': run_id,
                'exp_config': exp_config,
                'parameters': params,
                'pareto_solutions': pareto_solutions,
                'metrics': metrics,
                'convergence_data': convergence_data,
                'runtime': runtime,
                'timestamp': datetime.now().isoformat(),
                'success': True
            }
            
            logger.info(f"å®éªŒ{exp_id}-è¿è¡Œ{run_id}å®Œæˆ: HV={metrics['hypervolume']:.4f}, "
                       f"IGD={metrics['igd']:.4f}, GD={metrics['gd']:.4f}, "
                       f"æ—¶é—´={runtime:.2f}s")
            
        except Exception as e:
            logger.error(f"å®éªŒ{exp_id}-è¿è¡Œ{run_id}å¤±è´¥: {str(e)}")
            result = {
                'exp_id': exp_id,
                'run_id': run_id,
                'exp_config': exp_config,
                'parameters': params,
                'error': str(e),
                'success': False
            }
        
        return result
    
    def _get_experiment_parameters(self, exp_config: Dict) -> Dict:
        """æ ¹æ®å®éªŒé…ç½®è·å–å…·ä½“å‚æ•°å€¼"""
        params = {
            'learning_rate': self.factor_levels['A_learning_rate'][exp_config['A']],
            'epsilon_decay': self.factor_levels['B_epsilon_decay'][exp_config['B']],
            'group_ratios': self.factor_levels['C_group_ratios'][exp_config['C']],
            'gamma': self.factor_levels['D_gamma'][exp_config['D']],
            # å›ºå®šå‚æ•°
            'population_size': 100,
            'max_iterations': self.max_iterations,
            'epsilon': 0.9,
            'epsilon_min': 0.01
        }
        return params
    
    def run_experiment_group(self, exp_config: Dict, problem: MO_DHFSP_Problem) -> Dict:
        """è¿è¡Œå•ç»„å®éªŒï¼ˆ5æ¬¡é‡å¤ï¼‰"""
        exp_id = exp_config['exp_id']
        logger.info(f"å¼€å§‹å®éªŒç»„{exp_id} ({exp_id}/81)")
        
        group_results = []
        
        # è¿è¡Œ5æ¬¡é‡å¤å®éªŒ
        for run_id in range(1, self.runs_per_experiment + 1):
            result = self.run_single_experiment(exp_config, run_id, problem)
            group_results.append(result)
            
            # ä¿å­˜å•æ¬¡å®éªŒç»“æœ
            with open(f"{self.results_dir}/exp_{exp_id:02d}_run_{run_id}.json", 'w') as f:
                json.dump(result, f, indent=2, default=str)
        
        # ç»Ÿè®¡åˆ†æ
        statistics = self._analyze_group_results(group_results)
        
        group_summary = {
            'exp_id': exp_id,
            'exp_config': exp_config,
            'individual_results': group_results,
            'statistics': statistics,
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜ç»„æ±‡æ€»ç»“æœ
        with open(f"{self.results_dir}/exp_{exp_id:02d}_summary.json", 'w') as f:
            json.dump(group_summary, f, indent=2, default=str)
        
        logger.info(f"å®éªŒç»„{exp_id}å®Œæˆ: å¹³å‡HV={statistics['hv_mean']:.4f}, "
                   f"å¹³å‡IGD={statistics['igd_mean']:.4f}, "
                   f"å¹³å‡GD={statistics['gd_mean']:.4f}, "
                   f"ç»¼åˆå¾—åˆ†={statistics['comprehensive_mean']:.4f}, "
                   f"SNR={statistics['snr_value']:.2f}")
        
        return group_summary
    
    def _analyze_group_results(self, group_results: List[Dict]) -> Dict:
        """åˆ†æç»„å®éªŒç»“æœ"""
        successful_results = [r for r in group_results if r.get('success', False)]
        
        if not successful_results:
            return {
                'success_count': 0,
                'hv_mean': 0.0, 'hv_std': 0.0,
                'igd_mean': float('inf'), 'igd_std': 0.0,
                'gd_mean': float('inf'), 'gd_std': 0.0,
                'comprehensive_mean': 0.0, 'comprehensive_std': 0.0,
                'runtime_mean': 0.0, 'runtime_std': 0.0,
                'snr_value': -50.0
            }
        
        # æå–æŒ‡æ ‡
        hvs = [r['metrics']['hypervolume'] for r in successful_results]
        igds = [r['metrics']['igd'] for r in successful_results]
        gds = [r['metrics']['gd'] for r in successful_results]
        comprehensives = [r['metrics']['comprehensive'] for r in successful_results]
        runtimes = [r['runtime'] for r in successful_results]
        
        # è®¡ç®—ç»Ÿè®¡é‡
        stats = {
            'success_count': len(successful_results),
            'hv_mean': np.mean(hvs), 'hv_std': np.std(hvs),
            'igd_mean': np.mean(igds), 'igd_std': np.std(igds),
            'gd_mean': np.mean(gds), 'gd_std': np.std(gds),
            'comprehensive_mean': np.mean(comprehensives), 'comprehensive_std': np.std(comprehensives),
            'runtime_mean': np.mean(runtimes), 'runtime_std': np.std(runtimes)
        }
        
        # è®¡ç®—ä¿¡å™ªæ¯”
        stats['snr_value'] = self.metrics_evaluator.calculate_snr_comprehensive(comprehensives)
        
        return stats
    
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰81ç»„å®éªŒ"""
        logger.info("å¼€å§‹L81ç”°å£æ­£äº¤å®éªŒ")
        
        # ç”Ÿæˆé—®é¢˜å®ä¾‹
        problem = self.generate_problem_instance()
        
        # ç”Ÿæˆå‚è€ƒå‰æ²¿
        logger.info("ç”Ÿæˆå‚è€ƒå‰æ²¿...")
        self.metrics_evaluator.generate_reference_front(problem)
        
        # è¿è¡Œæ‰€æœ‰å®éªŒç»„
        all_results = []
        total_experiments = len(self.l81_design)
        
        for i, exp_config in enumerate(self.l81_design):
            logger.info(f"è¿›åº¦: {i+1}/{total_experiments}")
            
            try:
                group_result = self.run_experiment_group(exp_config, problem)
                all_results.append(group_result)
                
                # æ¯5ç»„å®éªŒä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
                if (i + 1) % 5 == 0:
                    self._save_intermediate_results(all_results[:i+1])
                    
            except Exception as e:
                logger.error(f"å®éªŒç»„{exp_config['exp_id']}è¿è¡Œå¤±è´¥: {str(e)}")
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_final_results(all_results)
        
        # è¿›è¡Œç”°å£åˆ†æ
        logger.info("å¼€å§‹ç”°å£åˆ†æ...")
        taguchi_results = self._perform_taguchi_analysis(all_results)
        
        logger.info("L81ç”°å£å®éªŒå®Œæˆ!")
        return all_results, taguchi_results
    
    def _save_intermediate_results(self, results: List[Dict]):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        with open(f"{self.results_dir}/intermediate_results.json", 'w') as f:
            json.dump(results, f, indent=2, default=str)
    
    def _save_final_results(self, results: List[Dict]):
        """ä¿å­˜æœ€ç»ˆç»“æœå¹¶å¯¼å‡ºExcel"""
        # ä¿å­˜JSONæ ¼å¼
        with open(f"{self.results_dir}/final_results.json", 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # å¯¼å‡ºExcelæ ¼å¼
        self._export_to_excel(results)
    
    def _export_to_excel(self, results: List[Dict]):
        """å¯¼å‡ºç»“æœåˆ°Excelæ–‡ä»¶"""
        logger.info("å¼€å§‹å¯¼å‡ºåˆ°Excelæ–‡ä»¶")
        
        # å‡†å¤‡æ•°æ®
        data_rows = []
        for result in results:
            exp_config = result['exp_config']
            stats = result['statistics']
            
            row = {
                'å®éªŒID': result['exp_id'],
                'A_å­¦ä¹ ç‡': self.factor_levels['A_learning_rate'][exp_config['A']],
                'B_è¡°å‡ç‡': self.factor_levels['B_epsilon_decay'][exp_config['B']],
                'C_åˆ†ç»„æ¯”ä¾‹': str(self.factor_levels['C_group_ratios'][exp_config['C']]),
                'D_æŠ˜æ‰£å› å­': self.factor_levels['D_gamma'][exp_config['D']],
                'æˆåŠŸæ¬¡æ•°': stats['success_count'],
                'å¹³å‡è¶…ä½“ç§¯': stats['hv_mean'],
                'è¶…ä½“ç§¯æ ‡å‡†å·®': stats['hv_std'],
                'å¹³å‡IGD': stats['igd_mean'],
                'IGDæ ‡å‡†å·®': stats['igd_std'],
                'å¹³å‡GD': stats['gd_mean'],
                'GDæ ‡å‡†å·®': stats['gd_std'],
                'å¹³å‡ç»¼åˆå¾—åˆ†': stats['comprehensive_mean'],
                'ç»¼åˆå¾—åˆ†æ ‡å‡†å·®': stats['comprehensive_std'],
                'å¹³å‡è¿è¡Œæ—¶é—´': stats['runtime_mean'],
                'SNRå€¼': stats['snr_value']
            }
            data_rows.append(row)
        
        # åˆ›å»ºDataFrameå¹¶ä¿å­˜
        df = pd.DataFrame(data_rows)
        excel_filename = f"{self.results_dir}/L81_experiment_results.xlsx"
        df.to_excel(excel_filename, index=False, sheet_name='å®éªŒç»“æœ')
        
        logger.info(f"ç»“æœå·²å¯¼å‡ºåˆ°Excel: {excel_filename}")
    
    def _perform_taguchi_analysis(self, results: List[Dict]) -> Dict:
        """æ‰§è¡Œç”°å£åˆ†æ"""
        analyzer = TaguchiL81Analyzer(self.factor_levels)
        taguchi_results = analyzer.analyze(results)
        
        # ä¿å­˜ç”°å£åˆ†æç»“æœ
        with open(f"{self.results_dir}/taguchi_analysis.json", 'w') as f:
            json.dump(taguchi_results, f, indent=2, default=str)
        
        return taguchi_results

class MetricsEvaluator:
    """æ€§èƒ½æŒ‡æ ‡è¯„ä¼°å™¨"""
    
    def __init__(self):
        self.reference_front = None
    
    def generate_reference_front(self, problem: MO_DHFSP_Problem):
        """ç”Ÿæˆå‚è€ƒå‰æ²¿"""
        logger.info("ç”Ÿæˆå‚è€ƒå‰æ²¿ï¼Œè¿è¡Œå¤šç§ç®—æ³•...")
        
        all_solutions = []
        algorithms = [
            ('NSGA2', NSGA2_Optimizer),
            ('MOEA/D', MOEAD_Optimizer),
            ('MOPSO', MOPSO_Optimizer),
            ('RL-Chaotic-HHO', RL_ChaoticHHO_Optimizer)
        ]
        
        for name, AlgorithmClass in algorithms:
            try:
                logger.info(f"è¿è¡Œ{name}ç®—æ³•...")
                if name == 'RL-Chaotic-HHO':
                    optimizer = AlgorithmClass(
                        problem, 
                        learning_rate=0.001,
                        epsilon_decay=0.997,
                        group_ratios=[0.45, 0.25, 0.20, 0.10],
                        gamma=0.95,
                        population_size=100,
                        max_iterations=30
                    )
                else:
                    optimizer = AlgorithmClass(problem, population_size=100, max_iterations=30)
                
                solutions, _ = optimizer.optimize()
                all_solutions.extend(solutions)
                logger.info(f"{name}è´¡çŒ®{len(solutions)}ä¸ªè§£")
                
            except Exception as e:
                logger.warning(f"{name}ç®—æ³•è¿è¡Œå¤±è´¥: {str(e)}")
        
        # æå–å¸•ç´¯æ‰˜å‰æ²¿ä½œä¸ºå‚è€ƒå‰æ²¿
        self.reference_front = self._extract_pareto_front(all_solutions)
        logger.info(f"å‚è€ƒå‰æ²¿åŒ…å«{len(self.reference_front)}ä¸ªè§£")
        
        # ä¿å­˜å‚è€ƒå‰æ²¿
        reference_data = [
            {'makespan': sol.makespan, 'total_tardiness': sol.total_tardiness}
            for sol in self.reference_front
        ]
        with open("reference_front.json", 'w') as f:
            json.dump(reference_data, f, indent=2)
    
    def _extract_pareto_front(self, solutions: List) -> List:
        """æå–å¸•ç´¯æ‰˜å‰æ²¿"""
        if not solutions:
            return []
        
        pareto_front = []
        for candidate in solutions:
            is_dominated = False
            
            for other in solutions:
                if (other.makespan <= candidate.makespan and 
                    other.total_tardiness <= candidate.total_tardiness and
                    (other.makespan < candidate.makespan or 
                     other.total_tardiness < candidate.total_tardiness)):
                    is_dominated = True
                    break
            
            if not is_dominated:
                pareto_front.append(candidate)
        
        return pareto_front
    
    def evaluate_performance(self, pareto_solutions: List, problem: MO_DHFSP_Problem, runtime: float) -> Dict:
        """è¯„ä¼°ç®—æ³•æ€§èƒ½"""
        if not pareto_solutions:
            return {
                'hypervolume': 0.0,
                'igd': float('inf'),
                'gd': float('inf'),
                'comprehensive': 0.0,
                'runtime': runtime
            }
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        hv = self._calculate_hypervolume(pareto_solutions)
        igd = self._calculate_igd(pareto_solutions)
        gd = self._calculate_gd(pareto_solutions)
        
        # ç»¼åˆè¯„ä»·ï¼ˆ5:3:2æƒé‡ï¼‰
        comprehensive = self.comprehensive_evaluation_5_3_2(hv, igd, gd)
        
        return {
            'hypervolume': hv,
            'igd': igd,
            'gd': gd,
            'comprehensive': comprehensive,
            'runtime': runtime
        }
    
    def _calculate_hypervolume(self, pareto_solutions: List) -> float:
        """è®¡ç®—è¶…ä½“ç§¯æŒ‡æ ‡"""
        if not pareto_solutions:
            return 0.0
        
        # æå–ç›®æ ‡å€¼
        objectives = np.array([[sol.makespan, sol.total_tardiness] for sol in pareto_solutions])
        
        # è®¾ç½®å‚è€ƒç‚¹ï¼ˆç¨å¤§äºæœ€å¤§å€¼ï¼‰
        max_makespan = np.max(objectives[:, 0])
        max_tardiness = np.max(objectives[:, 1])
        reference_point = np.array([max_makespan * 1.1, max_tardiness * 1.1])
        
        # ç®€åŒ–çš„è¶…ä½“ç§¯è®¡ç®—
        normalized_objectives = objectives / reference_point
        volumes = []
        
        for obj in normalized_objectives:
            if all(obj < 1.0):
                volume = np.prod(1.0 - obj)
                volumes.append(volume)
        
        return sum(volumes) / len(objectives) if volumes else 0.0
    
    def _calculate_igd(self, pareto_solutions: List) -> float:
        """è®¡ç®—åå‘ä¸–ä»£è·ç¦»"""
        if not self.reference_front or not pareto_solutions:
            return float('inf')
        
        distances = []
        for ref_sol in self.reference_front:
            min_dist = float('inf')
            for sol in pareto_solutions:
                dist = self._euclidean_distance(
                    [ref_sol.makespan, ref_sol.total_tardiness],
                    [sol.makespan, sol.total_tardiness]
                )
                min_dist = min(min_dist, dist)
            distances.append(min_dist)
        
        return np.mean(distances)
    
    def _calculate_gd(self, pareto_solutions: List) -> float:
        """è®¡ç®—ä¸–ä»£è·ç¦»"""
        if not self.reference_front or not pareto_solutions:
            return float('inf')
        
        distances = []
        for sol in pareto_solutions:
            min_dist = float('inf')
            for ref_sol in self.reference_front:
                dist = self._euclidean_distance(
                    [sol.makespan, sol.total_tardiness],
                    [ref_sol.makespan, ref_sol.total_tardiness]
                )
                min_dist = min(min_dist, dist)
            distances.append(min_dist)
        
        return np.mean(distances)
    
    def _euclidean_distance(self, point1: List[float], point2: List[float]) -> float:
        """è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»"""
        return np.sqrt(sum((a - b) ** 2 for a, b in zip(point1, point2)))
    
    def comprehensive_evaluation_5_3_2(self, hv: float, igd: float, gd: float) -> float:
        """5:3:2æƒé‡ç»¼åˆè¯„ä»·"""
        # å½’ä¸€åŒ–å¤„ç†
        normalized_hv = hv  # è¶…ä½“ç§¯è¶Šå¤§è¶Šå¥½ï¼Œç›´æ¥ä½¿ç”¨
        normalized_igd = 1.0 / (1.0 + igd) if igd != float('inf') else 0.0  # IGDè¶Šå°è¶Šå¥½
        normalized_gd = 1.0 / (1.0 + gd) if gd != float('inf') else 0.0    # GDè¶Šå°è¶Šå¥½
        
        # åŠ æƒç»¼åˆ
        comprehensive = (0.5 * normalized_hv + 0.3 * normalized_igd + 0.2 * normalized_gd)
        return comprehensive
    
    def calculate_snr_comprehensive(self, scores: List[float]) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†çš„ä¿¡å™ªæ¯”"""
        if not scores or all(s == 0 for s in scores):
            return -50.0
        
        mean_score = np.mean(scores)
        if mean_score <= 0:
            return -50.0
        
        # ä¿¡å™ªæ¯”è®¡ç®—ï¼šSNR = -10 * log10(1/mean^2)
        snr = -10 * np.log10(1.0 / (mean_score ** 2))
        return snr

class TaguchiL81Analyzer:
    """ç”°å£L81åˆ†æå™¨"""
    
    def __init__(self, factor_levels: Dict):
        self.factor_levels = factor_levels
    
    def analyze(self, results: List[Dict]) -> Dict:
        """æ‰§è¡Œç”°å£åˆ†æ"""
        logger.info("å¼€å§‹ç”°å£åˆ†æ...")
        
        # æå–ä¿¡å™ªæ¯”æ•°æ®
        snr_data = self._extract_snr_data(results)
        
        # å› å­æ•ˆåº”åˆ†æ
        factor_effects = self._calculate_factor_effects(snr_data)
        
        # ç¡®å®šæœ€ä¼˜æ°´å¹³ç»„åˆ
        optimal_combination = self._determine_optimal_combination(factor_effects)
        
        # æ–¹å·®åˆ†æ
        anova_results = self._perform_anova(snr_data, factor_effects)
        
        # é¢„æµ‹æœ€ä¼˜æ€§èƒ½
        predicted_snr = self._predict_optimal_snr(factor_effects, optimal_combination)
        
        logger.info("ç”°å£åˆ†æå®Œæˆ")
        
        return {
            'factor_effects': factor_effects,
            'optimal_combination': optimal_combination,
            'anova_results': anova_results,
            'predicted_snr': predicted_snr,
            'snr_data': snr_data.tolist()
        }
    
    def _extract_snr_data(self, results: List[Dict]) -> np.ndarray:
        """æå–ä¿¡å™ªæ¯”æ•°æ®"""
        snr_values = []
        for result in results:
            snr = result['statistics']['snr_value']
            snr_values.append(snr if snr != -float('inf') else -50.0)
        
        return np.array(snr_values)
    
    def _calculate_factor_effects(self, snr_data: np.ndarray) -> Dict:
        """è®¡ç®—å› å­æ•ˆåº”"""
        factor_effects = {}
        
        for factor in ['A', 'B', 'C', 'D']:
            factor_effects[factor] = {}
            
            for level in range(1, 10):  # 9ä¸ªæ°´å¹³
                # æ‰¾åˆ°è¯¥å› å­è¯¥æ°´å¹³å¯¹åº”çš„å®éªŒç´¢å¼•
                level_indices = self._get_level_indices(factor, level)
                
                # è®¡ç®—è¯¥æ°´å¹³çš„å¹³å‡SNR
                if level_indices:
                    level_snr = np.mean(snr_data[level_indices])
                else:
                    level_snr = -50.0
                
                factor_effects[factor][level] = level_snr
        
        return factor_effects
    
    def _get_level_indices(self, factor: str, level: int) -> List[int]:
        """è·å–æŒ‡å®šå› å­æ°´å¹³å¯¹åº”çš„å®éªŒç´¢å¼•"""
        indices = []
        
        if factor == 'A':
            # Aå› å­æŒ‰é¡ºåºåˆ†å¸ƒ
            start_idx = (level - 1) * 9
            end_idx = min(start_idx + 9, 81)
            indices = list(range(start_idx, end_idx))
        elif factor == 'B':
            # Bå› å­æ¯9ä¸ªå®éªŒå¾ªç¯ä¸€æ¬¡
            for i in range(81):
                if (i % 9) + 1 == level:
                    indices.append(i)
        elif factor == 'C':
            # Cå› å­åŸºäºAå’ŒBè®¡ç®—
            for i in range(81):
                a = i // 9 + 1
                b = (i % 9) + 1
                c = ((a - 1) + (b - 1)) % 9 + 1
                if c == level:
                    indices.append(i)
        elif factor == 'D':
            # Då› å­åŸºäºAå’ŒBçš„å¤åˆè®¡ç®—
            for i in range(81):
                a = i // 9 + 1
                b = (i % 9) + 1
                d = ((a - 1) * 2 + (b - 1) * 3) % 9 + 1
                if d == level:
                    indices.append(i)
        
        return indices
    
    def _determine_optimal_combination(self, factor_effects: Dict) -> Dict:
        """ç¡®å®šæœ€ä¼˜å‚æ•°ç»„åˆ"""
        optimal = {}
        for factor in ['A', 'B', 'C', 'D']:
            # é€‰æ‹©ä¿¡å™ªæ¯”æœ€å¤§çš„æ°´å¹³
            best_level = max(
                range(1, 10), 
                key=lambda level: factor_effects[factor][level]
            )
            optimal[factor] = best_level
        
        return optimal
    
    def _perform_anova(self, snr_data: np.ndarray, factor_effects: Dict) -> Dict:
        """æ‰§è¡Œæ–¹å·®åˆ†æ"""
        grand_mean = np.mean(snr_data)
        sst = np.sum((snr_data - grand_mean) ** 2)  # æ€»å¹³æ–¹å’Œ
        
        anova = {}
        for factor in ['A', 'B', 'C', 'D']:
            # è®¡ç®—å› å­å¹³æ–¹å’Œ
            ss_factor = 0
            for level in range(1, 10):
                level_indices = self._get_level_indices(factor, level)
                if level_indices:
                    level_mean = np.mean(snr_data[level_indices])
                    ss_factor += len(level_indices) * (level_mean - grand_mean) ** 2
            
            # è®¡ç®—Få€¼
            df_factor = 8  # è‡ªç”±åº¦ = æ°´å¹³æ•° - 1
            df_error = 81 - 9  # ç®€åŒ–çš„è¯¯å·®è‡ªç”±åº¦
            ms_factor = ss_factor / df_factor
            ms_error = (sst - ss_factor) / df_error if df_error > 0 else 1
            f_value = ms_factor / ms_error if ms_error > 0 else 0
            
            anova[factor] = {
                'sum_of_squares': ss_factor,
                'mean_square': ms_factor,
                'f_value': f_value,
                'contribution': ss_factor / sst * 100 if sst > 0 else 0  # è´¡çŒ®ç‡%
            }
        
        return anova
    
    def _predict_optimal_snr(self, factor_effects: Dict, optimal_combination: Dict) -> float:
        """é¢„æµ‹æœ€ä¼˜ç»„åˆçš„ä¿¡å™ªæ¯”"""
        grand_mean = np.mean([
            np.mean(list(factor_effects[factor].values()))
            for factor in ['A', 'B', 'C', 'D']
        ])
        
        predicted_snr = grand_mean
        for factor in ['A', 'B', 'C', 'D']:
            optimal_level = optimal_combination[factor]
            level_effect = factor_effects[factor][optimal_level] - np.mean(
                list(factor_effects[factor].values())
            )
            predicted_snr += level_effect
        
        return predicted_snr

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHO L81ç”°å£æ­£äº¤å®éªŒ")
    print("=" * 60)
    print("ğŸ“Š å®éªŒé…ç½®:")
    print("   - æ­£äº¤è¡¨: L81(9^4)")
    print("   - å‚æ•°æ•°é‡: 4ä¸ª")
    print("   - æ°´å¹³æ•°é‡: 9ä¸ª")
    print("   - é—®é¢˜è§„æ¨¡: 100Ã—5Ã—3")
    print("   - æ€»æœºå™¨æ•°: 40å°")
    print("   - å®éªŒç»„æ•°: 81ç»„")
    print("   - æ¯ç»„é‡å¤: 5æ¬¡")
    print("   - æ€»å®éªŒé‡: 405æ¬¡")
    print("   - è¯„ä»·æŒ‡æ ‡: è¶…ä½“ç§¯:åå‘ä¸–ä»£è·ç¦»:ä¸–ä»£è·ç¦» = 5:3:2åŠ æƒç»¼åˆ")
    print("=" * 60)
    
    print(f"\nğŸ“ˆ L81è®¾è®¡ç›¸æ¯”L49çš„æ”¹è¿›:")
    print(f"   - å‚æ•°æ°´å¹³: 7 â†’ 9 (å¢åŠ 28.6%)")
    print(f"   - å®éªŒç»„æ•°: 49 â†’ 81 (å¢åŠ 65.3%)")
    print(f"   - æ¯ç»„é‡å¤: 10 â†’ 5 (å‡å°‘50%ï¼Œå¹³è¡¡æ€»å®éªŒé‡)")
    print(f"   - æ€»å®éªŒé‡: 490 â†’ 405 (å‡å°‘17.3%ï¼Œæé«˜æ•ˆç‡)")
    print(f"   - å‚æ•°è¦†ç›–: æ›´å…¨é¢çš„å‚æ•°ç©ºé—´æ¢ç´¢")
    print(f"   - å­¦ä¹ ç‡èŒƒå›´: 0.00005~0.005 â†’ 0.00001~0.02")
    print(f"   - è¡°å‡ç‡ç²¾åº¦: 0.988~0.9995 â†’ 0.985~0.9999")
    print(f"   - åˆ†ç»„ç­–ç•¥: 7ç§ â†’ 9ç§æ›´å¤šæ ·åŒ–çš„æ¢ç´¢-å¼€å‘å¹³è¡¡")
    print(f"   - æŠ˜æ‰£å› å­: 0.80~0.995 â†’ 0.75~0.999")
    
    # åˆ›å»ºå®éªŒæ§åˆ¶å™¨
    experiment = TaguchiL81Experiment()
    
    # è¿è¡Œå®éªŒ
    start_time = time.time()
    try:
        all_results, taguchi_results = experiment.run_all_experiments()
        
        total_time = time.time() - start_time
        print(f"\nğŸ‰ å®éªŒå®Œæˆ! æ€»è€—æ—¶: {total_time/3600:.2f}å°æ—¶")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {experiment.results_dir}")
        
        # è¾“å‡ºå…³é”®ç»“æœ
        print("\nğŸ“ˆ ç”°å£åˆ†æç»“æœ:")
        optimal = taguchi_results['optimal_combination']
        print(f"   æœ€ä¼˜å­¦ä¹ ç‡: {experiment.factor_levels['A_learning_rate'][optimal['A']]}")
        print(f"   æœ€ä¼˜è¡°å‡ç‡: {experiment.factor_levels['B_epsilon_decay'][optimal['B']]}")
        print(f"   æœ€ä¼˜åˆ†ç»„æ¯”ä¾‹: {experiment.factor_levels['C_group_ratios'][optimal['C']]}")
        print(f"   æœ€ä¼˜æŠ˜æ‰£å› å­: {experiment.factor_levels['D_gamma'][optimal['D']]}")
        print(f"   é¢„æµ‹SNR: {taguchi_results['predicted_snr']:.2f}")
        
        # è¾“å‡ºå› å­è´¡çŒ®ç‡
        print("\nğŸ“Š å› å­è´¡çŒ®ç‡:")
        for factor in ['A', 'B', 'C', 'D']:
            contribution = taguchi_results['anova_results'][factor]['contribution']
            print(f"   {factor}å› å­: {contribution:.2f}%")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å®éªŒè¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 