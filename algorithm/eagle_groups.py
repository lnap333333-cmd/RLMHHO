#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å››å±‚é¹°ç¾¤åˆ†ç»„åä½œç®¡ç†å™¨ - å®Œæ•´å®ç°
åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•çš„æ ¸å¿ƒç»„ä»¶
"""

import numpy as np
import random
import copy
from typing import List, Dict, Tuple, Optional
from collections import deque
from dataclasses import dataclass
from problem.mo_dhfsp import Solution
from .chaotic_maps import ChaoticMaps

@dataclass
class GroupPerformance:
    """ç»„æ€§èƒ½æŒ‡æ ‡"""
    improvement_count: int = 0           # æ”¹è¿›æ¬¡æ•°
    average_quality: float = 0.0         # å¹³å‡è´¨é‡
    diversity_score: float = 0.0         # å¤šæ ·æ€§åˆ†æ•°
    convergence_rate: float = 0.0        # æ”¶æ•›ç‡
    success_rate: float = 0.0            # æˆåŠŸç‡
    energy_consumption: float = 0.0      # èƒ½é‡æ¶ˆè€—
    exploration_efficiency: float = 0.0  # æ¢ç´¢æ•ˆç‡
    exploitation_efficiency: float = 0.0 # å¼€å‘æ•ˆç‡

class EagleGroupManager:
    """å››å±‚é¹°ç¾¤åˆ†ç»„åä½œç®¡ç†å™¨"""
    
    def __init__(self, population_size: int, n_jobs: int, n_factories: int):
        """
        åˆå§‹åŒ–é¹°ç¾¤ç®¡ç†å™¨
        
        Args:
            population_size: ç§ç¾¤å¤§å°
            n_jobs: ä½œä¸šæ•°é‡
            n_factories: å·¥å‚æ•°é‡
        """
        self.population_size = population_size
        self.n_jobs = n_jobs
        self.n_factories = n_factories
        
        # æ··æ²Œæ˜ å°„ç³»ç»Ÿ
        self.chaos_maps = ChaoticMaps()
        
        # å››å¤§åˆ†ç»„é…ç½® - è°ƒæ•´æ¯”ä¾‹ä¸º0.4, 0.35, 0.15, 0.1
        self.group_config = {
            'exploration': {'ratio': 0.40, 'chaos_type': 'logistic'},    # æ¢ç´¢ç»„ 40%
            'exploitation': {'ratio': 0.35, 'chaos_type': 'tent'},      # å¼€å‘ç»„ 35%
            'balance': {'ratio': 0.15, 'chaos_type': 'sine'},           # å¹³è¡¡ç»„ 15%
            'elite': {'ratio': 0.10, 'chaos_type': 'chebyshev'}         # ç²¾è‹±ç»„ 10%
        }
        
        # åŠ¨æ€è°ƒæ•´å‚æ•°ï¼ˆå¿…é¡»åœ¨åˆå§‹åŒ–åˆ†ç»„ä¹‹å‰ï¼‰
        self.adaptation_threshold = 0.1      # é€‚åº”é˜ˆå€¼
        self.performance_window = 10         # æ€§èƒ½è¯„ä¼°çª—å£
        self.min_group_size = max(2, population_size // 20)  # æœ€å°ç»„å¤§å°
        
        # åˆå§‹åŒ–åˆ†ç»„
        self._initialize_groups()
        
        # æ€§èƒ½ç›‘æ§
        self.group_performance = {
            group: GroupPerformance() for group in self.group_config.keys()
        }
        
        # å†å²è®°å½•
        self.performance_history = {group: deque(maxlen=20) for group in self.group_config.keys()}
        self.adaptation_history = []
        
        print(f"åˆå§‹åŒ–å››å±‚é¹°ç¾¤åˆ†ç»„ç®¡ç†å™¨:")
        print(f"  æ¢ç´¢ç»„: {len(self.groups['exploration'])}åªé¹° ({self.group_config['exploration']['ratio']*100:.1f}%)")
        print(f"  å¼€å‘ç»„: {len(self.groups['exploitation'])}åªé¹° ({self.group_config['exploitation']['ratio']*100:.1f}%)")
        print(f"  å¹³è¡¡ç»„: {len(self.groups['balance'])}åªé¹° ({self.group_config['balance']['ratio']*100:.1f}%)")
        print(f"  ç²¾è‹±ç»„: {len(self.groups['elite'])}åªé¹° ({self.group_config['elite']['ratio']*100:.1f}%)")
    
    def _initialize_groups(self):
        """åˆå§‹åŒ–å„ç»„åˆ†é…"""
        indices = list(range(self.population_size))
        random.shuffle(indices)
        
        self.groups = {}
        start_idx = 0
        
        for group_name, config in self.group_config.items():
            group_size = max(self.min_group_size, int(self.population_size * config['ratio']))
            end_idx = min(start_idx + group_size, self.population_size)
            self.groups[group_name] = indices[start_idx:end_idx]
            start_idx = end_idx
        
        # ç¡®ä¿æ‰€æœ‰ä¸ªä½“éƒ½è¢«åˆ†é…
        if start_idx < self.population_size:
            self.groups['exploration'].extend(indices[start_idx:])
    
    def assign_eagles(self, population: List[Solution]):
        """åŠ¨æ€åˆ†é…é¹°åˆ°å„ç»„"""
        self.population = population
        
        # åŸºäºè§£è´¨é‡é‡æ–°åˆ†é…
        self._quality_based_assignment()
        
        # æ›´æ–°ç»„æ€§èƒ½
        self._update_group_performance()
    
    def _quality_based_assignment(self):
        """åŸºäºè§£è´¨é‡çš„åŠ¨æ€åˆ†é…"""
        if not hasattr(self, 'population') or not self.population:
            return
        
        # è®¡ç®—è§£çš„ç»¼åˆè´¨é‡åˆ†æ•°
        quality_scores = []
        for sol in self.population:
            # å½’ä¸€åŒ–ç›®æ ‡å€¼
            makespan_norm = sol.makespan / max(s.makespan for s in self.population)
            tardiness_norm = sol.total_tardiness / max(max(s.total_tardiness for s in self.population), 1)
            quality = 1.0 / (1.0 + 0.5 * makespan_norm + 0.5 * tardiness_norm)
            quality_scores.append(quality)
        
        # æŒ‰è´¨é‡æ’åº
        sorted_indices = sorted(range(len(self.population)), 
                              key=lambda i: quality_scores[i], reverse=True)
        
        # é‡æ–°åˆ†é…
        self.groups = {}
        start_idx = 0
        
        # ç²¾è‹±ç»„ï¼šæœ€ä¼˜çš„10%
        elite_size = max(self.min_group_size, int(self.population_size * self.group_config['elite']['ratio']))
        self.groups['elite'] = sorted_indices[start_idx:start_idx + elite_size]
        start_idx += elite_size
        
        # å¼€å‘ç»„ï¼šæ¬¡ä¼˜çš„25%
        exploit_size = max(self.min_group_size, int(self.population_size * self.group_config['exploitation']['ratio']))
        self.groups['exploitation'] = sorted_indices[start_idx:start_idx + exploit_size]
        start_idx += exploit_size
        
        # å¹³è¡¡ç»„ï¼šä¸­ç­‰çš„20%
        balance_size = max(self.min_group_size, int(self.population_size * self.group_config['balance']['ratio']))
        self.groups['balance'] = sorted_indices[start_idx:start_idx + balance_size]
        start_idx += balance_size
        
        # æ¢ç´¢ç»„ï¼šå…¶ä½™çš„45%
        self.groups['exploration'] = sorted_indices[start_idx:]
    
    def get_group(self, group_name: str) -> List[int]:
        """è·å–æŒ‡å®šç»„çš„é¹°ç´¢å¼•"""
        return self.groups.get(group_name, [])
    
    def get_group_solutions(self, group_name: str) -> List[Solution]:
        """è·å–æŒ‡å®šç»„çš„è§£"""
        if not hasattr(self, 'population'):
            return []
        
        indices = self.get_group(group_name)
        return [self.population[i] for i in indices if i < len(self.population)]
    
    def get_performance_metrics(self) -> List[float]:
        """è·å–å„ç»„æ€§èƒ½æŒ‡æ ‡ï¼ˆ20ç»´å‘é‡ï¼‰"""
        metrics = []
        
        for group_name in ['exploration', 'exploitation', 'balance', 'elite']:
            perf = self.group_performance[group_name]
            group_metrics = [
                perf.improvement_count / 100.0,      # æ”¹è¿›æ¬¡æ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
                min(perf.average_quality, 1.0),      # å¹³å‡è´¨é‡
                min(perf.diversity_score, 1.0),      # å¤šæ ·æ€§åˆ†æ•°
                min(perf.convergence_rate, 1.0),     # æ”¶æ•›ç‡
                min(perf.success_rate, 1.0)          # æˆåŠŸç‡
            ]
            metrics.extend(group_metrics)
        
        return metrics
    
    def _update_group_performance(self):
        """æ›´æ–°å„ç»„æ€§èƒ½æŒ‡æ ‡"""
        if not hasattr(self, 'population'):
            return
        
        for group_name, indices in self.groups.items():
            if not indices:
                continue
                
            group_solutions = [self.population[i] for i in indices if i < len(self.population)]
            if not group_solutions:
                continue
            
            perf = self.group_performance[group_name]
            
            # è®¡ç®—å¹³å‡è´¨é‡
            makespans = [sol.makespan for sol in group_solutions]
            tardiness = [sol.total_tardiness for sol in group_solutions]
            
            if makespans and tardiness:
                avg_makespan = np.mean(makespans)
                avg_tardiness = np.mean(tardiness)
                perf.average_quality = 1.0 / (1.0 + avg_makespan + avg_tardiness)
                
                # è®¡ç®—å¤šæ ·æ€§åˆ†æ•°
                makespan_std = np.std(makespans) if len(makespans) > 1 else 0
                tardiness_std = np.std(tardiness) if len(tardiness) > 1 else 0
                perf.diversity_score = (makespan_std + tardiness_std) / (avg_makespan + avg_tardiness + 1e-6)
                
                # æ›´æ–°å†å²è®°å½•
                self.performance_history[group_name].append(perf.average_quality)
                
                # è®¡ç®—æ”¶æ•›ç‡
                if len(self.performance_history[group_name]) >= 3:
                    recent_qualities = list(self.performance_history[group_name])[-3:]
                    perf.convergence_rate = (recent_qualities[-1] - recent_qualities[0]) / max(recent_qualities[0], 1e-6)
    
    def enhance_exploration(self):
        """å¼ºåŒ–å…¨å±€æ¢ç´¢"""
        # å¢åŠ æ¢ç´¢ç»„æ¯”ä¾‹
        self._adjust_group_ratio('exploration', 0.1)
        
        # æé«˜æ¢ç´¢ç»„çš„æ··æ²Œå¼ºåº¦
        for idx in self.groups['exploration']:
            if hasattr(self, 'population') and idx < len(self.population):
                self._apply_chaotic_perturbation(idx, intensity=0.8)
        
        print("ğŸ” æ‰§è¡Œç­–ç•¥ï¼šå¼ºåŒ–å…¨å±€æ¢ç´¢")
    
    def enhance_exploitation(self):
        """å¼ºåŒ–å±€éƒ¨å¼€å‘"""
        # å¢åŠ å¼€å‘ç»„å’Œç²¾è‹±ç»„æ¯”ä¾‹
        self._adjust_group_ratio('exploitation', 0.08)
        self._adjust_group_ratio('elite', 0.05)
        
        # å¯¹å¼€å‘ç»„åº”ç”¨ç²¾ç»†æœç´¢
        for idx in self.groups['exploitation']:
            if hasattr(self, 'population') and idx < len(self.population):
                self._apply_local_refinement(idx)
        
        print("ğŸ¯ æ‰§è¡Œç­–ç•¥ï¼šå¼ºåŒ–å±€éƒ¨å¼€å‘")
    
    def balance_search(self):
        """å¹³è¡¡æœç´¢"""
        # è°ƒæ•´å„ç»„æ¯”ä¾‹è¶‹å‘å¹³è¡¡
        target_ratios = {'exploration': 0.4, 'exploitation': 0.3, 'balance': 0.2, 'elite': 0.1}
        for group_name, ratio in target_ratios.items():
            self._adjust_group_ratio(group_name, 0.02, target_ratio=ratio)
        
        # å¹³è¡¡ç»„æ‰§è¡Œé€‚ä¸­å¼ºåº¦çš„æœç´¢
        for idx in self.groups['balance']:
            if hasattr(self, 'population') and idx < len(self.population):
                self._apply_balanced_search(idx)
        
        print("âš–ï¸ æ‰§è¡Œç­–ç•¥ï¼šå¹³è¡¡æœç´¢")
    
    def diversity_rescue(self):
        """å¤šæ ·æ€§æ•‘æ´ç­–ç•¥ - å¢å¼ºç‰ˆ"""
        print("ğŸ­ æ‰§è¡Œç­–ç•¥ï¼šå¤šæ ·æ€§æ•‘æ´", end="")
        
        # åˆ†æå½“å‰ç§ç¾¤å¤šæ ·æ€§
        diversity_metrics = self._analyze_diversity()
        
        # æ ¹æ®å¤šæ ·æ€§æƒ…å†µé€‰æ‹©æ•‘æ´ç­–ç•¥
        if diversity_metrics['makespan_cv'] < 0.1 and diversity_metrics['tardiness_cv'] < 0.1:
            # å¤šæ ·æ€§æä½ï¼Œå¤§å¹…åº¦æ•‘æ´
            affected_groups = ['exploration', 'balance', 'elite']
            rescue_intensity = 0.8  # 80%çš„ä¸ªä½“å‚ä¸æ•‘æ´
        elif diversity_metrics['makespan_cv'] < 0.2 or diversity_metrics['tardiness_cv'] < 0.2:
            # å¤šæ ·æ€§è¾ƒä½ï¼Œä¸­ç­‰æ•‘æ´
            affected_groups = ['balance', 'elite']
            rescue_intensity = 0.6  # 60%çš„ä¸ªä½“å‚ä¸æ•‘æ´
        else:
            # å¤šæ ·æ€§å°šå¯ï¼Œè½»åº¦æ•‘æ´
            affected_groups = ['elite']
            rescue_intensity = 0.4  # 40%çš„ä¸ªä½“å‚ä¸æ•‘æ´
        
        print(f" (å½±å“ç»„: {affected_groups}, å¼ºåº¦: {rescue_intensity:.0%})")
        
        # å¯¹é€‰å®šç»„è¿›è¡Œå¤šæ ·æ€§æ³¨å…¥
        for group_name in affected_groups:
            group_indices = self.groups[group_name]
            n_rescue = max(1, int(len(group_indices) * rescue_intensity))
            
            # éšæœºé€‰æ‹©éœ€è¦æ•‘æ´çš„ä¸ªä½“
            rescue_indices = random.sample(group_indices, min(n_rescue, len(group_indices)))
            
            for idx in rescue_indices:
                if idx < len(self.population):
                    # ç”Ÿæˆå¤šæ ·åŒ–çš„æ–°ä¸ªä½“
                    self.population[idx] = self._generate_diverse_individual()
        
        # æ›´æ–°ç»„æ€§èƒ½ç»Ÿè®¡
        self._update_group_performance()
    
    def _analyze_diversity(self) -> Dict:
        """åˆ†æç§ç¾¤å¤šæ ·æ€§"""
        if not self.population:
            return {'makespan_cv': 0.0, 'tardiness_cv': 0.0}
        
        makespans = [sol.makespan for sol in self.population]
        tardiness = [sol.total_tardiness for sol in self.population]
        
        # è®¡ç®—å˜å¼‚ç³»æ•°
        makespan_cv = np.std(makespans) / max(np.mean(makespans), 1e-6)
        tardiness_cv = np.std(tardiness) / max(np.mean(tardiness), 1e-6)
        
        return {
            'makespan_cv': makespan_cv,
            'tardiness_cv': tardiness_cv,
            'makespan_range': max(makespans) - min(makespans),
            'tardiness_range': max(tardiness) - min(tardiness)
        }
    
    def _generate_diverse_individual(self) -> 'Solution':
        """ç”Ÿæˆå¤šæ ·åŒ–çš„ä¸ªä½“"""
        # ä½¿ç”¨å¢å¼ºçš„éšæœºç”Ÿæˆç­–ç•¥
        from problem.mo_dhfsp import Solution
        import random
        
        # éšæœºå·¥å‚åˆ†é…ï¼ˆå€¾å‘äºå¹³è¡¡åˆ†é…ï¼‰
        factory_assignment = []
        for job_id in range(self.n_jobs):
            # é€‰æ‹©è´Ÿè½½è¾ƒè½»çš„å·¥å‚
            factory_loads = [0] * self.n_factories
            for assigned_job, factory in enumerate(factory_assignment):
                factory_loads[factory] += 1
            
            # 80%æ¦‚ç‡é€‰æ‹©è´Ÿè½½æœ€è½»çš„å·¥å‚ï¼Œ20%æ¦‚ç‡éšæœºé€‰æ‹©
            if random.random() < 0.8:
                min_load = min(factory_loads)
                lightest_factories = [f for f, load in enumerate(factory_loads) if load == min_load]
                selected_factory = random.choice(lightest_factories)
            else:
                selected_factory = random.randint(0, self.n_factories - 1)
            
            factory_assignment.append(selected_factory)
        
        # æ„å»ºä½œä¸šåºåˆ—
        job_sequences = [[] for _ in range(self.n_factories)]
        for job_id, factory_id in enumerate(factory_assignment):
            job_sequences[factory_id].append(job_id)
        
        # éšæœºæ‰“ä¹±å„å·¥å‚å†…çš„ä½œä¸šé¡ºåº
        for factory_id in range(self.n_factories):
            random.shuffle(job_sequences[factory_id])
        
        return Solution(factory_assignment, job_sequences)
    
    def elite_enhancement(self):
        """ç²¾è‹±å¼ºåŒ–"""
        # æ‰©å¤§ç²¾è‹±ç»„
        self._adjust_group_ratio('elite', 0.05)
        
        # å¯¹ç²¾è‹±ç»„åº”ç”¨é«˜å¼ºåº¦å±€éƒ¨æœç´¢
        for idx in self.groups['elite']:
            if hasattr(self, 'population') and idx < len(self.population):
                self._apply_elite_optimization(idx)
        
        print("ğŸ‘‘ æ‰§è¡Œç­–ç•¥ï¼šç²¾è‹±å¼ºåŒ–")
    
    def redistribute_resources(self):
        """èµ„æºé‡åˆ†é…"""
        # åŸºäºæ€§èƒ½é‡æ–°åˆ†é…èµ„æº
        performance_scores = {}
        for group_name, perf in self.group_performance.items():
            score = 0.4 * perf.average_quality + 0.3 * perf.success_rate + 0.3 * perf.convergence_rate
            performance_scores[group_name] = score
        
        # å¥–åŠ±è¡¨ç°å¥½çš„ç»„ï¼Œå‡å°‘è¡¨ç°å·®çš„ç»„
        total_score = sum(performance_scores.values())
        if total_score > 0:
            for group_name, score in performance_scores.items():
                ratio_adjustment = (score / total_score - 0.25) * 0.1  # æœŸæœ›å€¼0.25ï¼Œè°ƒæ•´å¹…åº¦10%
                self._adjust_group_ratio(group_name, ratio_adjustment)
        
        print("ğŸ”„ æ‰§è¡Œç­–ç•¥ï¼šèµ„æºé‡åˆ†é…")
    
    def _adjust_group_ratio(self, group_name: str, adjustment: float, target_ratio: Optional[float] = None):
        """è°ƒæ•´ç»„æ¯”ä¾‹"""
        if group_name not in self.groups:
            return
        
        current_size = len(self.groups[group_name])
        
        if target_ratio is not None:
            target_size = max(self.min_group_size, int(self.population_size * target_ratio))
        else:
            adjustment_size = max(-current_size + self.min_group_size, 
                                int(self.population_size * adjustment))
            target_size = max(self.min_group_size, current_size + adjustment_size)
        
        target_size = min(target_size, self.population_size - 3 * self.min_group_size)  # ç¡®ä¿å…¶ä»–ç»„æœ‰ç©ºé—´
        
        if target_size != current_size:
            self._resize_group(group_name, target_size)
    
    def _resize_group(self, group_name: str, target_size: int):
        """è°ƒæ•´ç»„å¤§å°"""
        current_size = len(self.groups[group_name])
        
        if target_size > current_size:
            # éœ€è¦å¢åŠ æˆå‘˜
            needed = target_size - current_size
            # ä»å…¶ä»–ç»„å€Ÿè°ƒæˆå‘˜
            available_indices = []
            for other_group, indices in self.groups.items():
                if other_group != group_name and len(indices) > self.min_group_size:
                    available_indices.extend(indices[:len(indices) - self.min_group_size])
            
            random.shuffle(available_indices)
            to_transfer = available_indices[:needed]
            
            # æ‰§è¡Œè½¬ç§»
            for idx in to_transfer:
                for other_group, indices in self.groups.items():
                    if idx in indices:
                        indices.remove(idx)
                        break
                self.groups[group_name].append(idx)
                
        elif target_size < current_size:
            # éœ€è¦å‡å°‘æˆå‘˜
            to_remove = current_size - target_size
            random.shuffle(self.groups[group_name])
            removed_indices = self.groups[group_name][:to_remove]
            self.groups[group_name] = self.groups[group_name][to_remove:]
            
            # å°†ç§»é™¤çš„æˆå‘˜åˆ†é…åˆ°å…¶ä»–ç»„
            other_groups = [g for g in self.groups.keys() if g != group_name]
            for idx in removed_indices:
                target_group = random.choice(other_groups)
                self.groups[target_group].append(idx)
    
    def _apply_chaotic_perturbation(self, eagle_idx: int, intensity: float = 0.5):
        """åº”ç”¨æ··æ²Œæ‰°åŠ¨"""
        if not hasattr(self, 'population') or eagle_idx >= len(self.population):
            return
        
        solution = self.population[eagle_idx]
        
        # è·å–æ··æ²Œå€¼
        chaos_values = self.chaos_maps.get_chaos_values(self.n_jobs)
        
        # éšæœºé‡åˆ†é…ä¸€äº›ä½œä¸šçš„å·¥å‚
        n_perturbations = max(1, int(intensity * self.n_jobs * 0.3))
        jobs_to_perturb = random.sample(range(self.n_jobs), min(n_perturbations, self.n_jobs))
        
        for i, job_id in enumerate(jobs_to_perturb):
            if chaos_values[i % len(chaos_values)] > 0.7:
                new_factory = random.randint(0, self.n_factories - 1)
                old_factory = solution.factory_assignment[job_id]
                
                if new_factory != old_factory:
                    # æ›´æ–°å·¥å‚åˆ†é…
                    solution.factory_assignment[job_id] = new_factory
                    
                    # æ›´æ–°ä½œä¸šåºåˆ—
                    if job_id in solution.job_sequences[old_factory]:
                        solution.job_sequences[old_factory].remove(job_id)
                    solution.job_sequences[new_factory].append(job_id)
    
    def _apply_local_refinement(self, eagle_idx: int):
        """åº”ç”¨å±€éƒ¨ç²¾ç‚¼"""
        if not hasattr(self, 'population') or eagle_idx >= len(self.population):
            return
        
        solution = self.population[eagle_idx]
        
        # å°è¯•ä½œä¸šäº¤æ¢ä¼˜åŒ–
        for _ in range(3):
            factory_id = random.randint(0, self.n_factories - 1)
            jobs = solution.job_sequences[factory_id]
            
            if len(jobs) >= 2:
                i, j = random.sample(range(len(jobs)), 2)
                # ä¸´æ—¶äº¤æ¢å¹¶è¯„ä¼°
                jobs[i], jobs[j] = jobs[j], jobs[i]
    
    def _apply_balanced_search(self, eagle_idx: int):
        """åº”ç”¨å¹³è¡¡æœç´¢"""
        if not hasattr(self, 'population') or eagle_idx >= len(self.population):
            return
        
        # ç»“åˆæ¢ç´¢å’Œå¼€å‘çš„ä¸­ç­‰å¼ºåº¦æœç´¢
        if random.random() < 0.5:
            self._apply_chaotic_perturbation(eagle_idx, intensity=0.3)
        else:
            self._apply_local_refinement(eagle_idx)
    
    def _apply_elite_optimization(self, eagle_idx: int):
        """åº”ç”¨ç²¾è‹±ä¼˜åŒ–"""
        if not hasattr(self, 'population') or eagle_idx >= len(self.population):
            return
        
        # å¯¹ç²¾è‹±è§£åº”ç”¨å¤šç§å±€éƒ¨æœç´¢ç®—å­
        for _ in range(5):
            self._apply_local_refinement(eagle_idx)
    
    def get_group_statistics(self) -> Dict:
        """è·å–åˆ†ç»„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        for group_name, indices in self.groups.items():
            perf = self.group_performance[group_name]
            stats[group_name] = {
                'size': len(indices),
                'ratio': len(indices) / self.population_size,
                'average_quality': perf.average_quality,
                'diversity_score': perf.diversity_score,
                'convergence_rate': perf.convergence_rate,
                'success_rate': perf.success_rate
            }
        
        return stats 