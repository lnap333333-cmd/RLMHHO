#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
 
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
 
 
 
 
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
 
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ
ä¸»ä½“ç®—æ³•å…³é”®å‚æ•°çš„æ•æ„Ÿæ€§åˆ†æå’Œæœ€ä¼˜å‚æ•°é€‰æ‹©å®éªŒ
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Any
from itertools import product
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ParameterTuningExperiment:
    """RL-Chaotic-HHOå‚æ•°è°ƒä¼˜å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/parameter_tuning"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # æµ‹è¯•é—®é¢˜é…ç½®ï¼ˆå®Œå…¨å¼‚æ„ï¼‰
        self.test_problems = self._generate_heterogeneous_test_problems()
        
        # å…³é”®å‚æ•°å®šä¹‰å’ŒèŒƒå›´
        self.parameter_ranges = {
            'max_iterations': [50, 80, 100, 120, 150],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
            'population_size_factor': [0.8, 1.0, 1.2, 1.5, 2.0],  # ç§ç¾¤è§„æ¨¡å› å­
            'energy_decay_rate': [1.5, 2.0, 2.5, 3.0],  # èƒ½é‡è¡°å‡ç‡
            'chaos_influence': [0.3, 0.5, 0.7, 0.9],  # æ··æ²Œå½±å“ç¨‹åº¦
            'local_search_prob': [0.1, 0.2, 0.3, 0.4, 0.5],  # å±€éƒ¨æœç´¢æ¦‚ç‡
            'pareto_size_limit': [30, 50, 80, 100],  # å¸•ç´¯æ‰˜å‰æ²¿å¤§å°é™åˆ¶
            'rl_learning_rate': [0.01, 0.05, 0.1, 0.2],  # å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡
            'exploration_decay': [0.95, 0.97, 0.99]  # æ¢ç´¢è¡°å‡ç‡
        }
        
        # é»˜è®¤åŸºå‡†å‚æ•°
        self.baseline_params = {
            'max_iterations': 100,
            'population_size_factor': 1.0,
            'energy_decay_rate': 2.0,
            'chaos_influence': 0.5,
            'local_search_prob': 0.3,
            'pareto_size_limit': 50,
            'rl_learning_rate': 0.1,
            'exploration_decay': 0.97
        }
        
    def _generate_heterogeneous_test_problems(self) -> List[Dict]:
        """ç”Ÿæˆå®Œå…¨å¼‚æ„çš„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å°è§„æ¨¡å¼‚æ„20Ã—3Ã—3',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 2],  # å·¥å‚0
                1: [2, 3, 3],  # å·¥å‚1  
                2: [2, 3, 4]   # å·¥å‚2
            },
            'processing_time_range': [1, 10],
            'urgency_range': [0.1, 0.9]
        })
        
        # ä¸­è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'ä¸­è§„æ¨¡å¼‚æ„50Ã—4Ã—3',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 3, 2],  # å·¥å‚0
                1: [3, 4, 3],  # å·¥å‚1
                2: [3, 5, 3],  # å·¥å‚2
                3: [4, 4, 4]   # å·¥å‚3
            },
            'processing_time_range': [1, 15],
            'urgency_range': [0.1, 0.9]
        })
        
        # å¤§è§„æ¨¡å¼‚æ„é—®é¢˜
        problems.append({
            'name': 'å¤§è§„æ¨¡å¼‚æ„100Ã—5Ã—3',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'heterogeneous_machines': {
                0: [2, 2, 3],  # å·¥å‚0
                1: [3, 3, 4],  # å·¥å‚1
                2: [3, 4, 4],  # å·¥å‚2
                3: [4, 3, 5],  # å·¥å‚3
                4: [3, 3, 4]   # å·¥å‚4
            },
            'processing_time_range': [1, 20],
            'urgency_range': [0.1, 0.9]
        })
        
        return problems
        
    def run_complete_parameter_tuning(self):
        """è¿è¡Œå®Œæ•´çš„å‚æ•°è°ƒä¼˜å®éªŒ"""
        print("ğŸ”§ RL-Chaotic-HHOç®—æ³•å®Œæ•´å‚æ•°è°ƒä¼˜å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š ç¬¬ä¸€é˜¶æ®µ: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        sensitivity_results = self._single_parameter_sensitivity_analysis()
        
        # 2. å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ
        print("\nğŸ”„ ç¬¬äºŒé˜¶æ®µ: å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ")
        interaction_results = self._parameter_interaction_analysis()
        
        # 3. å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–
        print("\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µ: å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–")
        grid_search_results = self._grid_search_optimization()
        
        # 4. æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ
        print("\nâœ… ç¬¬å››é˜¶æ®µ: æœ€ä¼˜å‚æ•°éªŒè¯å®éªŒ")
        validation_results = self._validate_optimal_parameters(grid_search_results)
        
        # 5. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
        self._generate_tuning_report(
            sensitivity_results, 
            interaction_results, 
            grid_search_results, 
            validation_results, 
            timestamp
        )
        
        print(f"\nğŸ‰ å‚æ•°è°ƒä¼˜å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        return validation_results['optimal_params']
    
    def _single_parameter_sensitivity_analysis(self) -> Dict:
        """å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ"""
        print("  åˆ†ææ¯ä¸ªå‚æ•°å¯¹ç®—æ³•æ€§èƒ½çš„ç‹¬ç«‹å½±å“...")
        
        sensitivity_results = {}
        
        for param_name, param_values in self.parameter_ranges.items():
            print(f"    æ­£åœ¨åˆ†æå‚æ•°: {param_name}")
            
            param_results = []
            
            for param_value in param_values:
                # è®¾ç½®æµ‹è¯•å‚æ•°
                test_params = self.baseline_params.copy()
                test_params[param_name] = param_value
                
                # åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šè¿è¡Œ
                problem_scores = []
                for problem_config in self.test_problems:
                    score = self._evaluate_parameter_setting(test_params, problem_config)
                    problem_scores.append(score)
                
                # è®¡ç®—å¹³å‡æ€§èƒ½
                avg_score = np.mean(problem_scores)
                std_score = np.std(problem_scores)
                
                param_results.append({
                    'value': param_value,
                    'avg_score': avg_score,
                    'std_score': std_score,
                    'problem_scores': problem_scores
                })
            
            sensitivity_results[param_name] = param_results
            
            # ç»˜åˆ¶æ•æ„Ÿæ€§å›¾
            self._plot_parameter_sensitivity(param_name, param_results)
        
        return sensitivity_results
    
    def _parameter_interaction_analysis(self) -> Dict:
        """å…³é”®å‚æ•°äº¤äº’ä½œç”¨åˆ†æ"""
        print("  åˆ†æå…³é”®å‚æ•°ç»„åˆçš„äº¤äº’æ•ˆåº”...")
        
        # åŸºäºæ•æ„Ÿæ€§åˆ†æé€‰æ‹©æœ€å…³é”®çš„å‚æ•°ç»„åˆ
        key_interactions = [
            ('max_iterations', 'population_size_factor'),
            ('energy_decay_rate', 'chaos_influence'),
            ('local_search_prob', 'rl_learning_rate'),
            ('max_iterations', 'energy_decay_rate')
        ]
        
        interaction_results = {}
        
        for param1, param2 in key_interactions:
            print(f"    åˆ†æå‚æ•°äº¤äº’: {param1} Ã— {param2}")
            
            # è·å–å‚æ•°èŒƒå›´ï¼ˆé€‰æ‹©å…³é”®å€¼ï¼‰
            values1 = self.parameter_ranges[param1][::2]  # æ¯éš”ä¸€ä¸ªå–å€¼
            values2 = self.parameter_ranges[param2][::2]
            
            interaction_matrix = []
            
            for val1 in values1:
                row_results = []
                for val2 in values2:
                    # è®¾ç½®æµ‹è¯•å‚æ•°
                    test_params = self.baseline_params.copy()
                    test_params[param1] = val1
                    test_params[param2] = val2
                    
                    # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šå¿«é€Ÿè¯„ä¼°
                    score = self._evaluate_parameter_setting(
                        test_params, 
                        self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                        runs=1  # å‡å°‘è¿è¡Œæ¬¡æ•°æé«˜é€Ÿåº¦
                    )
                    row_results.append(score)
                
                interaction_matrix.append(row_results)
            
            interaction_results[f"{param1}_{param2}"] = {
                'param1_values': values1,
                'param2_values': values2,
                'score_matrix': interaction_matrix
            }
            
            # ç»˜åˆ¶äº¤äº’çƒ­åŠ›å›¾
            self._plot_parameter_interaction(param1, param2, values1, values2, interaction_matrix)
        
        return interaction_results
    
    def _grid_search_optimization(self) -> Dict:
        """å¤šå‚æ•°ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        print("  è¿›è¡Œç²¾ç»†åŒ–ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ...")
        
        # åŸºäºå‰é¢åˆ†æç»“æœç¼©å°æœç´¢èŒƒå›´
        refined_ranges = {
            'max_iterations': [80, 100, 120],
            'population_size_factor': [1.0, 1.2, 1.5],
            'energy_decay_rate': [2.0, 2.5],
            'chaos_influence': [0.5, 0.7],
            'local_search_prob': [0.2, 0.3, 0.4],
            'rl_learning_rate': [0.05, 0.1]
        }
        
        # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
        param_names = list(refined_ranges.keys())
        param_combinations = list(product(*refined_ranges.values()))
        
        print(f"    æ€»è®¡éœ€è¦æµ‹è¯• {len(param_combinations)} ä¸ªå‚æ•°ç»„åˆ")
        
        best_score = float('inf')
        best_params = None
        all_results = []
        
        for i, param_combo in enumerate(param_combinations):
            if i % 10 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(param_combinations)}")
            
            # æ„å»ºå‚æ•°å­—å…¸
            test_params = self.baseline_params.copy()
            for param_name, param_value in zip(param_names, param_combo):
                test_params[param_name] = param_value
            
            # åœ¨ä¸­è§„æ¨¡é—®é¢˜ä¸Šè¯„ä¼°
            score = self._evaluate_parameter_setting(
                test_params, 
                self.test_problems[1],  # ä¸­è§„æ¨¡é—®é¢˜
                runs=1
            )
            
            all_results.append({
                'params': test_params.copy(),
                'score': score
            })
            
            if score < best_score:
                best_score = score
                best_params = test_params.copy()
        
        return {
            'best_params': best_params,
            'best_score': best_score,
            'all_results': all_results
        }
    
    def _validate_optimal_parameters(self, grid_search_results: Dict) -> Dict:
        """éªŒè¯æœ€ä¼˜å‚æ•°"""
        print("  åœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸ŠéªŒè¯æœ€ä¼˜å‚æ•°æ€§èƒ½...")
        
        optimal_params = grid_search_results['best_params']
        
        validation_results = {
            'optimal_params': optimal_params,
            'baseline_comparison': {},
            'problem_performance': {}
        }
        
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            print(f"    éªŒè¯é—®é¢˜: {problem_name}")
            
            # æœ€ä¼˜å‚æ•°æ€§èƒ½
            optimal_score = self._evaluate_parameter_setting(
                optimal_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # åŸºå‡†å‚æ•°æ€§èƒ½
            baseline_score = self._evaluate_parameter_setting(
                self.baseline_params, 
                problem_config, 
                runs=3,
                detailed=True
            )
            
            # è®¡ç®—æ”¹è¿›ç‡
            improvement = ((baseline_score['weighted_avg'] - optimal_score['weighted_avg']) / 
                          baseline_score['weighted_avg'] * 100)
            
            validation_results['problem_performance'][problem_name] = {
                'optimal': optimal_score,
                'baseline': baseline_score,
                'improvement_percent': improvement
            }
        
        return validation_results
    
    def _evaluate_parameter_setting(self, params: Dict, problem_config: Dict, 
                                   runs: int = 1, detailed: bool = False) -> float:
        """è¯„ä¼°ç‰¹å®šå‚æ•°è®¾ç½®çš„æ€§èƒ½"""
        try:
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            problem = MO_DHFSP_Problem(problem_data)
            
            scores = []
            detailed_results = []
            
            for run in range(runs):
                # è½¬æ¢å‚æ•°æ ¼å¼
                algorithm_params = self._convert_params_for_algorithm(params)
                
                # åˆ›å»ºä¼˜åŒ–å™¨
                optimizer = RL_ChaoticHHO_Optimizer(problem, **algorithm_params)
                
                # è¿è¡Œä¼˜åŒ–
                start_time = time.time()
                pareto_solutions, convergence_data = optimizer.optimize()
                runtime = time.time() - start_time
                
                if pareto_solutions:
                    # è®¡ç®—åŠ æƒç›®æ ‡å‡½æ•°å€¼
                    weighted_scores = [0.55 * sol.makespan + 0.45 * sol.total_tardiness 
                                     for sol in pareto_solutions]
                    best_score = min(weighted_scores)
                    avg_score = np.mean(weighted_scores)
                    
                    scores.append(best_score)
                    
                    if detailed:
                        detailed_results.append({
                            'best_weighted': best_score,
                            'avg_weighted': avg_score,
                            'best_makespan': min(sol.makespan for sol in pareto_solutions),
                            'best_tardiness': min(sol.total_tardiness for sol in pareto_solutions),
                            'pareto_size': len(pareto_solutions),
                            'runtime': runtime
                        })
                else:
                    scores.append(float('inf'))
                    if detailed:
                        detailed_results.append({
                            'best_weighted': float('inf'),
                            'avg_weighted': float('inf'),
                            'best_makespan': float('inf'),
                            'best_tardiness': float('inf'),
                            'pareto_size': 0,
                            'runtime': runtime
                        })
            
            if detailed:
                return {
                    'weighted_avg': np.mean([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'weighted_std': np.std([r['best_weighted'] for r in detailed_results if r['best_weighted'] != float('inf')]),
                    'detailed_runs': detailed_results
                }
            else:
                valid_scores = [s for s in scores if s != float('inf')]
                return np.mean(valid_scores) if valid_scores else float('inf')
                
        except Exception as e:
            print(f"    è­¦å‘Š: å‚æ•°è¯„ä¼°å¤±è´¥ - {str(e)}")
            return float('inf')
    
    def _convert_params_for_algorithm(self, params: Dict) -> Dict:
        """å°†è°ƒä¼˜å‚æ•°è½¬æ¢ä¸ºç®—æ³•å‚æ•°æ ¼å¼"""
        algorithm_params = {
            'max_iterations': params['max_iterations']
        }
        
        # å…¶ä»–å‚æ•°éœ€è¦åœ¨RL_ChaoticHHO_Optimizerä¸­å®ç°æ”¯æŒ
        # è¿™é‡Œåªæ¼”ç¤ºæ ¸å¿ƒå‚æ•°
        
        return algorithm_params
    
    def _generate_problem_data(self, config: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ•°æ®"""
        generator = DataGenerator(seed=42)
        
        # è®¡ç®—å¹³å‡æœºå™¨é…ç½®
        machines_per_stage = []
        for stage in range(config['n_stages']):
            stage_machines = [config['heterogeneous_machines'][f]['stages'][stage] 
                            for f in range(config['n_factories'])]
            avg_machines = int(np.mean(stage_machines))
            machines_per_stage.append(max(1, avg_machines))
        
        # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
        problem_data = generator.generate_problem(
            n_jobs=config['n_jobs'],
            n_factories=config['n_factories'],
            n_stages=config['n_stages'],
            machines_per_stage=machines_per_stage,
            processing_time_range=config['processing_time_range'],
            due_date_tightness=1.5
        )
        
        # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®
        problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
        
        # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
        urgencies = [np.random.uniform(config['urgency_range'][0], config['urgency_range'][1]) 
                    for _ in range(config['n_jobs'])]
        problem_data['urgencies'] = urgencies
        
        return problem_data
    
    def _plot_parameter_sensitivity(self, param_name: str, results: List[Dict]):
        """ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§å›¾"""
        values = [r['value'] for r in results]
        scores = [r['avg_score'] for r in results]
        stds = [r['std_score'] for r in results]
        
        plt.figure(figsize=(10, 6))
        plt.errorbar(values, scores, yerr=stds, marker='o', capsize=5, capthick=2)
        plt.xlabel(f'{param_name}')
        plt.ylabel('åŠ æƒç›®æ ‡å‡½æ•°å€¼')
        plt.title(f'{param_name} å‚æ•°æ•æ„Ÿæ€§åˆ†æ')
        plt.grid(True, alpha=0.3)
        
        filename = f"{self.results_dir}/sensitivity_{param_name}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _plot_parameter_interaction(self, param1: str, param2: str, 
                                  values1: List, values2: List, matrix: List[List]):
        """ç»˜åˆ¶å‚æ•°äº¤äº’çƒ­åŠ›å›¾"""
        plt.figure(figsize=(10, 8))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(matrix, 
                   xticklabels=[f'{v:.2f}' for v in values2],
                   yticklabels=[f'{v:.2f}' for v in values1],
                   annot=True, fmt='.2f', cmap='viridis_r')
        
        plt.xlabel(param2)
        plt.ylabel(param1)
        plt.title(f'{param1} Ã— {param2} å‚æ•°äº¤äº’åˆ†æ')
        
        filename = f"{self.results_dir}/interaction_{param1}_{param2}.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
    
    def _generate_tuning_report(self, sensitivity_results: Dict, interaction_results: Dict,
                              grid_search_results: Dict, validation_results: Dict, timestamp: str):
        """ç”Ÿæˆå‚æ•°è°ƒä¼˜å®Œæ•´æŠ¥å‘Š"""
        filename = f"{self.results_dir}/parameter_tuning_report_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒæŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("å®éªŒæ¦‚è¿°:\n")
            f.write("- ä¸»ä½“ç®—æ³•: RL-Chaotic-HHO (åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–)\n")
            f.write("- æµ‹è¯•é—®é¢˜: å®Œå…¨å¼‚æ„æœºå™¨é…ç½®çš„MO-DHFSPé—®é¢˜\n")
            f.write("- ä¼˜åŒ–ç›®æ ‡: æœ€å°åŒ–åŠ æƒç›®æ ‡å‡½æ•° (0.55Ã—å®Œå·¥æ—¶é—´ + 0.45Ã—æ€»æ‹–æœŸ)\n")
            f.write("- å®éªŒæ–¹æ³•: å•å‚æ•°æ•æ„Ÿæ€§åˆ†æ + å‚æ•°äº¤äº’åˆ†æ + ç½‘æ ¼æœç´¢ä¼˜åŒ–\n\n")
            
            # å…³é”®å‚æ•°è¯´æ˜
            f.write("å…³é”®å‚æ•°è¯´æ˜åŠé‡è¦æ€§:\n")
            f.write("-" * 40 + "\n")
            
            parameter_importance = {
                'max_iterations': 'æœ€å¤§è¿­ä»£æ¬¡æ•° - æ§åˆ¶æœç´¢æ·±åº¦å’Œæ”¶æ•›ç²¾åº¦',
                'population_size_factor': 'ç§ç¾¤è§„æ¨¡å› å­ - å½±å“æœç´¢å¹¿åº¦å’Œå¤šæ ·æ€§',
                'energy_decay_rate': 'èƒ½é‡è¡°å‡ç‡ - æ§åˆ¶æ¢ç´¢/å¼€å‘å¹³è¡¡',
                'chaos_influence': 'æ··æ²Œå½±å“ç¨‹åº¦ - å¢å¼ºç§ç¾¤å¤šæ ·æ€§é¿å…æ—©ç†Ÿ',
                'local_search_prob': 'å±€éƒ¨æœç´¢æ¦‚ç‡ - æé«˜è§£çš„å±€éƒ¨æœ€ä¼˜æ€§',
                'pareto_size_limit': 'å¸•ç´¯æ‰˜å‰æ²¿å¤§å° - å¹³è¡¡è§£é›†è´¨é‡å’Œè®¡ç®—æ•ˆç‡',
                'rl_learning_rate': 'å¼ºåŒ–å­¦ä¹ å­¦ä¹ ç‡ - æ§åˆ¶ç­–ç•¥é€‚åº”é€Ÿåº¦',
                'exploration_decay': 'æ¢ç´¢è¡°å‡ç‡ - è°ƒèŠ‚RLæ¢ç´¢ç­–ç•¥'
            }
            
            for param, desc in parameter_importance.items():
                f.write(f"â€¢ {param}: {desc}\n")
            f.write("\n")
            
            # åŸºå‡†å‚æ•°
            f.write("åŸºå‡†å‚æ•°è®¾ç½®:\n")
            f.write("-" * 20 + "\n")
            for param, value in self.baseline_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æœ€ä¼˜å‚æ•°
            f.write("ä¼˜åŒ–åæœ€ä¼˜å‚æ•°:\n")
            f.write("-" * 20 + "\n")
            optimal_params = validation_results['optimal_params']
            for param, value in optimal_params.items():
                f.write(f"â€¢ {param}: {value}\n")
            f.write("\n")
            
            # æ€§èƒ½æ”¹è¿›ç»“æœ
            f.write("å‚æ•°ä¼˜åŒ–æ•ˆæœ:\n")
            f.write("-" * 20 + "\n")
            for problem_name, results in validation_results['problem_performance'].items():
                improvement = results['improvement_percent']
                f.write(f"â€¢ {problem_name}: æ”¹è¿› {improvement:.2f}%\n")
            f.write("\n")
            
            # å‚æ•°é€‰æ‹©ç†ç”±
            f.write("æœ€ä¼˜å‚æ•°é€‰æ‹©ç†ç”±:\n")
            f.write("-" * 25 + "\n")
            f.write("1. max_iterations: åŸºäºæ”¶æ•›æ›²çº¿åˆ†æï¼Œåœ¨ä¿è¯æ”¶æ•›è´¨é‡çš„å‰æä¸‹å¹³è¡¡è®¡ç®—æ—¶é—´\n")
            f.write("2. population_size_factor: è€ƒè™‘é—®é¢˜è§„æ¨¡å¤æ‚åº¦ï¼Œç¡®ä¿ç§ç¾¤å¤šæ ·æ€§\n")
            f.write("3. energy_decay_rate: æ ¹æ®æ•æ„Ÿæ€§åˆ†æï¼Œé€‰æ‹©æœ€ä½³æ¢ç´¢/å¼€å‘å¹³è¡¡ç‚¹\n")
            f.write("4. chaos_influence: åŸºäºå¤šæ ·æ€§æŒ‡æ ‡ï¼Œé€‰æ‹©é€‚ä¸­çš„æ··æ²Œæ‰°åŠ¨å¼ºåº¦\n")
            f.write("5. local_search_prob: æƒè¡¡å±€éƒ¨æ”¹è¿›æ•ˆæœå’Œè®¡ç®—å¼€é”€\n")
            f.write("6. å…¶ä»–å‚æ•°: åŸºäºå‚æ•°äº¤äº’åˆ†æå’Œç½‘æ ¼æœç´¢ç»“æœç¡®å®š\n\n")
            
            f.write("å®éªŒç»“è®º:\n")
            f.write("-" * 15 + "\n")
            f.write("é€šè¿‡ç³»ç»ŸåŒ–çš„å‚æ•°è°ƒä¼˜å®éªŒï¼ŒæˆåŠŸæ‰¾åˆ°äº†RL-Chaotic-HHOç®—æ³•çš„\n")
            f.write("æœ€ä¼˜å‚æ•°ç»„åˆï¼Œåœ¨æ‰€æœ‰æµ‹è¯•é—®é¢˜ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚\n")
            f.write("å‚æ•°ä¼˜åŒ–çš„å…³é”®åœ¨äºå¹³è¡¡ç®—æ³•çš„æ¢ç´¢å’Œå¼€å‘èƒ½åŠ›ï¼Œå¹¶å……åˆ†\n")
            f.write("åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ··æ²Œæ˜ å°„çš„ååŒæ•ˆåº”ã€‚\n")
            
        print(f"  å‚æ•°è°ƒä¼˜æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHOç®—æ³•å‚æ•°è°ƒä¼˜å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ParameterTuningExperiment()
    
    # è¿è¡Œå®Œæ•´å‚æ•°è°ƒä¼˜
    optimal_params = experiment.run_complete_parameter_tuning()
    
    print("\nâœ… å®éªŒå®Œæˆï¼")
    print(f"æœ€ä¼˜å‚æ•°ç»„åˆ: {optimal_params}")

if __name__ == "__main__":
    main() 
 
 
 
 
 
 
 
 