#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
 
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
 
 
 
 
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
 
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒæ–¹æ¡ˆ
RL-Chaotic-HHO vs å…¶ä»–ä¸»æµå¤šç›®æ ‡ç®—æ³•åœ¨å®Œå…¨å¼‚æ„MO-DHFSPé—®é¢˜ä¸Šçš„æ€§èƒ½å¯¹æ¯”
"""

import os
import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple, Any
import pandas as pd

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.mosa import MOSA_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

class ComprehensiveComparisonExperiment:
    """å®Œæ•´ç®—æ³•å¯¹æ¯”å®éªŒç±»"""
    
    def __init__(self):
        self.results_dir = "results/comprehensive_comparison"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†
        self.test_problems = self._generate_comprehensive_test_suite()
        
        # ç®—æ³•é…ç½®
        self.algorithms = self._setup_algorithm_configurations()
        
    def _generate_comprehensive_test_suite(self) -> List[Dict]:
        """ç”Ÿæˆå…¨é¢çš„å®Œå…¨å¼‚æ„æµ‹è¯•é—®é¢˜é›†"""
        problems = []
        
        # å°è§„æ¨¡é—®é¢˜é›† (20ä½œä¸š)
        small_problems = [
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—3',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 2], 1: [2, 3, 3], 2: [2, 3, 4]},
                'complexity': 'low'
            },
            {
                'name': 'å°è§„æ¨¡20Ã—3Ã—4',
                'n_jobs': 20, 'n_factories': 3, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 2], 1: [2, 3, 3, 2], 2: [3, 4, 4, 2]},
                'complexity': 'low'
            }
        ]
        
        # ä¸­è§„æ¨¡é—®é¢˜é›† (50ä½œä¸š)
        medium_problems = [
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—3',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 3, 2], 1: [3, 4, 3], 2: [3, 5, 3], 3: [4, 4, 4]},
                'complexity': 'medium'
            },
            {
                'name': 'ä¸­è§„æ¨¡50Ã—4Ã—4',
                'n_jobs': 50, 'n_factories': 4, 'n_stages': 4,
                'heterogeneous_machines': {0: [2, 2, 3, 2], 1: [3, 3, 4, 3], 2: [3, 4, 4, 3], 3: [3, 3, 4, 3]},
                'complexity': 'medium'
            }
        ]
        
        # å¤§è§„æ¨¡é—®é¢˜é›† (100ä½œä¸š)
        large_problems = [
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—3',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 3,
                'heterogeneous_machines': {0: [2, 2, 3], 1: [3, 3, 4], 2: [3, 4, 4], 3: [4, 3, 5], 4: [3, 3, 4]},
                'complexity': 'high'
            },
            {
                'name': 'å¤§è§„æ¨¡100Ã—5Ã—4',
                'n_jobs': 100, 'n_factories': 5, 'n_stages': 4,
                'heterogeneous_machines': {0: [1, 2, 2, 1], 1: [2, 3, 3, 2], 2: [2, 3, 4, 2], 3: [3, 4, 3, 2], 4: [2, 3, 4, 2]},
                'complexity': 'high'
            }
        ]
        
        # è¶…å¤§è§„æ¨¡é—®é¢˜é›† (200ä½œä¸š)
        extra_large_problems = [
            {
                'name': 'è¶…å¤§è§„æ¨¡200Ã—6Ã—3',
                'n_jobs': 200, 'n_factories': 6, 'n_stages': 3,
                'heterogeneous_machines': {0: [3, 3, 4], 1: [4, 4, 5], 2: [4, 5, 5], 3: [5, 4, 6], 4: [4, 4, 5], 5: [3, 4, 5]},
                'complexity': 'very_high'
            }
        ]
        
        problems.extend(small_problems)
        problems.extend(medium_problems) 
        problems.extend(large_problems)
        problems.extend(extra_large_problems)
        
        return problems
    
    def _setup_algorithm_configurations(self) -> Dict:
        """è®¾ç½®ç®—æ³•é…ç½®"""
        return {
            'RL-Chaotic-HHO': {
                'class': RL_ChaoticHHO_Optimizer,
                'name': 'RL-Chaotic-HHO',
                'description': 'åŸºäºå¼ºåŒ–å­¦ä¹ åè°ƒçš„æ··æ²Œå“ˆé‡Œæ–¯é¹°ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 80},
                    'medium': {'max_iterations': 100}, 
                    'large': {'max_iterations': 120},
                    'very_large': {'max_iterations': 150}
                }
            },
            'NSGA-II': {
                'class': NSGA2_Optimizer,
                'name': 'NSGA-II',
                'description': 'éæ”¯é…æ’åºé—ä¼ ç®—æ³•II',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'medium': {'population_size': 80, 'max_generations': 100, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'large': {'population_size': 100, 'max_generations': 120, 'crossover_prob': 0.9, 'mutation_prob': 0.1},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'crossover_prob': 0.9, 'mutation_prob': 0.1}
                }
            },
            'MOEA/D': {
                'class': MOEAD_Optimizer,
                'name': 'MOEA/D',
                'description': 'åŸºäºåˆ†è§£çš„å¤šç›®æ ‡è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'neighbor_size': 10},
                    'medium': {'population_size': 80, 'max_generations': 100, 'neighbor_size': 15},
                    'large': {'population_size': 100, 'max_generations': 120, 'neighbor_size': 20},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'neighbor_size': 25}
                }
            },
            'MOPSO': {
                'class': MOPSO_Optimizer,
                'name': 'MOPSO',
                'description': 'å¤šç›®æ ‡ç²’å­ç¾¤ä¼˜åŒ–ç®—æ³•',
                'params': {
                    'small': {'swarm_size': 60, 'max_iterations': 80, 'archive_size': 90},
                    'medium': {'swarm_size': 80, 'max_iterations': 100, 'archive_size': 120},
                    'large': {'swarm_size': 100, 'max_iterations': 120, 'archive_size': 150},
                    'very_large': {'swarm_size': 120, 'max_iterations': 150, 'archive_size': 180}
                }
            },
            'MODE': {
                'class': MODE_Optimizer,
                'name': 'MODE',
                'description': 'å¤šç›®æ ‡å·®åˆ†è¿›åŒ–ç®—æ³•',
                'params': {
                    'small': {'population_size': 60, 'max_generations': 80, 'F': 0.5, 'CR': 0.9},
                    'medium': {'population_size': 80, 'max_generations': 100, 'F': 0.5, 'CR': 0.9},
                    'large': {'population_size': 100, 'max_generations': 120, 'F': 0.5, 'CR': 0.9},
                    'very_large': {'population_size': 120, 'max_generations': 150, 'F': 0.5, 'CR': 0.9}
                }
            },
            'MOSA': {
                'class': MOSA_Optimizer,
                'name': 'MOSA',
                'description': 'å¤šç›®æ ‡æ¨¡æ‹Ÿé€€ç«ç®—æ³•',
                'params': {
                    'small': {'max_iterations': 800, 'initial_temperature': 500, 'cooling_rate': 0.98, 'neighborhood_size': 10},
                    'medium': {'max_iterations': 1000, 'initial_temperature': 800, 'cooling_rate': 0.98, 'neighborhood_size': 12},
                    'large': {'max_iterations': 1200, 'initial_temperature': 1000, 'cooling_rate': 0.98, 'neighborhood_size': 15},
                    'very_large': {'max_iterations': 1500, 'initial_temperature': 1200, 'cooling_rate': 0.98, 'neighborhood_size': 18}
                }
            }
        }
    
    def run_comprehensive_comparison(self):
        """è¿è¡Œå®Œæ•´çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("=" * 80)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ€»ä½“å®éªŒç»“æœ
        all_results = {}
        
        # å¯¹æ¯ä¸ªæµ‹è¯•é—®é¢˜è¿è¡Œå¯¹æ¯”å®éªŒ
        for problem_config in self.test_problems:
            problem_name = problem_config['name']
            complexity = problem_config['complexity']
            
            print(f"\nğŸ§ª æµ‹è¯•é—®é¢˜: {problem_name} (å¤æ‚åº¦: {complexity})")
            print("-" * 60)
            
            # ç”Ÿæˆé—®é¢˜æ•°æ®
            problem_data = self._generate_problem_data(problem_config)
            
            # è¿è¡Œæ‰€æœ‰ç®—æ³•
            problem_results = {}
            for alg_name, alg_config in self.algorithms.items():
                print(f"  è¿è¡Œç®—æ³•: {alg_name}")
                
                # è·å–å¯¹åº”å¤æ‚åº¦çš„å‚æ•°
                scale_key = self._get_scale_key(complexity)
                params = alg_config['params'][scale_key]
                
                # è¿è¡Œç®—æ³•
                result = self._run_algorithm_experiment(
                    problem_data, 
                    alg_config['class'], 
                    params,
                    runs=5  # æ¯ä¸ªç®—æ³•è¿è¡Œ5æ¬¡
                )
                
                problem_results[alg_name] = result
                
                print(f"    æœ€ä¼˜åŠ æƒç›®æ ‡: {result['best_weighted']:.2f}")
                print(f"    å¹³å‡è¿è¡Œæ—¶é—´: {result['avg_runtime']:.2f}s")
            
            all_results[problem_name] = problem_results
            
            # ç»˜åˆ¶è¯¥é—®é¢˜çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”
            self._plot_pareto_comparison(problem_results, problem_name, timestamp)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self._generate_comprehensive_report(all_results, timestamp)
        
        # ç»˜åˆ¶ç»¼åˆæ€§èƒ½å›¾è¡¨
        self._plot_comprehensive_performance(all_results, timestamp)
        
        print(f"\nğŸ‰ å®Œæ•´å¯¹æ¯”å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.results_dir}/")
        
        return all_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¯åŠ¨å®Œæ•´çš„å¤šç›®æ ‡ç®—æ³•å¯¹æ¯”å®éªŒ")
    
    # åˆ›å»ºå®éªŒå®ä¾‹
    experiment = ComprehensiveComparisonExperiment()
    
    # è¿è¡Œå®Œæ•´å¯¹æ¯”å®éªŒ
    results = experiment.run_comprehensive_comparison()
    
    print("\nâœ… æ‰€æœ‰å®éªŒå®Œæˆï¼")

if __name__ == "__main__":
    main() 
 
 
 
 
 
 
 
 