#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å®šè§„æ¨¡ç®—æ³•å¯¹æ¯”å®éªŒç¨‹åº - ä¿®å¤ç‰ˆæœ¬
è§£å†³é—®é¢˜ï¼š
1. DQN paretoè§£é›†æ•°é‡é—®é¢˜
2. å½’ä¸€åŒ–æŒ‡æ ‡è®¡ç®—é—®é¢˜  
3. ä¸»ä½“ç®—æ³•paretoè§£é›†å¤šæ ·æ€§
4. Excelè¡¨æ ¼åˆ†ç¦»è¾“å‡º
"""

import os
import time
import traceback
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple
import pandas as pd

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.improved_nsga2 import ImprovedNSGA2_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.dqn_algorithm_wrapper import DQNAlgorithmWrapper
from algorithm.ql_abc import QLABC_Optimizer
from utils.data_generator import DataGenerator

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

def calculate_hypervolume(pareto_solutions: List, reference_point: Tuple[float, float] = None, normalize: bool = False) -> float:
    """
    ä¿®å¤åçš„è¶…ä½“ç§¯æŒ‡æ ‡è®¡ç®—
    ä½¿ç”¨æ­£ç¡®çš„2Dè¶…ä½“ç§¯ç®—æ³•ï¼Œé¿å…è™šé«˜æˆ–è™šä½çš„HVå€¼
    """
    if not pareto_solutions or len(pareto_solutions) == 0:
        return 0.0
    
    # æå–ç›®æ ‡å€¼
    objectives = [(sol.makespan, sol.total_tardiness) for sol in pareto_solutions]
    
    # å»é™¤é‡å¤è§£ï¼ˆæ›´å®½æ¾çš„å®¹å·®ï¼‰
    unique_objectives = []
    tolerance = 1e-3  # æ”¾å®½å®¹å·®
    for obj in objectives:
        is_duplicate = False
        for unique_obj in unique_objectives:
            if abs(obj[0] - unique_obj[0]) < tolerance and abs(obj[1] - unique_obj[1]) < tolerance:
                is_duplicate = True
                break
        if not is_duplicate:
            unique_objectives.append(obj)
    
    if len(unique_objectives) == 0:
        return 0.0
    
    # ä¸¥æ ¼è®¡ç®—å¸•ç´¯æ‰˜å‰æ²¿
    pareto_front = []
    for i, obj in enumerate(unique_objectives):
        is_dominated = False
        for j, other_obj in enumerate(unique_objectives):
            if i != j:  # ä¸ä¸è‡ªå·±æ¯”è¾ƒ
                # æ£€æŸ¥æ˜¯å¦è¢«ä¸¥æ ¼æ”¯é…ï¼ˆå¯¹äºæœ€å°åŒ–é—®é¢˜ï¼‰
                if (other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and 
                    (other_obj[0] < obj[0] or other_obj[1] < obj[1])):
                    is_dominated = True
                    break
        if not is_dominated:
            pareto_front.append(obj)
    
    if len(pareto_front) == 0:
        return 0.0
    
    # å•ç‚¹è§£ç»™äºˆåˆç†çš„åŸºç¡€åˆ†æ•°
    if len(pareto_front) == 1:
        return 0.1  # å›ºå®šè¿”å›0.1ä½œä¸ºå•ç‚¹è§£çš„åŸºç¡€åˆ†æ•°
    
    # è®¾ç½®åˆç†çš„å‚è€ƒç‚¹ï¼ˆä½¿ç”¨æ›´å¤§çš„æ‰©å±•æ¯”ä¾‹ï¼‰
    if reference_point is None:
        max_makespan = max(obj[0] for obj in pareto_front)
        max_tardiness = max(obj[1] for obj in pareto_front)
        min_makespan = min(obj[0] for obj in pareto_front)
        min_tardiness = min(obj[1] for obj in pareto_front)
        
        # ä½¿ç”¨åŠ¨æ€æ‰©å±•æ¯”ä¾‹ï¼Œç¡®ä¿æœ‰æ„ä¹‰çš„HVè®¡ç®—ç©ºé—´
        makespan_range = max_makespan - min_makespan
        tardiness_range = max_tardiness - min_tardiness
        
        # è‡³å°‘æ‰©å±•20%ï¼Œå¯¹äºå°èŒƒå›´æ‰©å±•æ›´å¤š
        makespan_margin = max(makespan_range * 0.3, max_makespan * 0.15, 1.0)
        tardiness_margin = max(tardiness_range * 0.3, max_tardiness * 0.15, 1.0)
        
        reference_point = (max_makespan + makespan_margin, max_tardiness + tardiness_margin)
    
    # ä½¿ç”¨æ­£ç¡®çš„2Dè¶…ä½“ç§¯è®¡ç®—ç®—æ³•ï¼ˆä»å·¦åˆ°å³æ‰«æï¼‰
    sorted_points = sorted(pareto_front, key=lambda x: x[0])  # æŒ‰xåæ ‡æ’åº
    
    hypervolume = 0.0
    prev_x = 0.0  # ä»åŸç‚¹å¼€å§‹
    
    for i, (x, y) in enumerate(sorted_points):
        # ç¡®ä¿ç‚¹åœ¨å‚è€ƒç‚¹å†…
        if x >= reference_point[0] or y >= reference_point[1]:
            continue
            
        # è®¡ç®—å½“å‰ç‚¹å·¦ä¾§çš„çŸ©å½¢è´¡çŒ®
        width = x - prev_x
        height = reference_point[1] - y
        
        if width > 0 and height > 0:
            hypervolume += width * height
    
        # æ›´æ–°xåæ ‡
        prev_x = x
    
    # æ·»åŠ æœ€å³ä¾§åŒºåŸŸçš„è´¡çŒ®ï¼ˆä»æœ€åä¸€ä¸ªç‚¹åˆ°å‚è€ƒç‚¹ï¼‰
    if sorted_points:
        last_x, last_y = sorted_points[-1]
        if last_x < reference_point[0]:
            # æ‰¾åˆ°åœ¨æœ€åxåæ ‡å¤„çš„æœ€å°yå€¼
            min_y = min(y for x, y in sorted_points if x == last_x)
            width = reference_point[0] - last_x
            height = reference_point[1] - min_y
            
            if width > 0 and height > 0:
                hypervolume += width * height
    
    # ç¡®ä¿è¿”å›æ­£å€¼
    hypervolume = max(0.0, hypervolume)
    
    # ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œå¯¹æ‰€æœ‰ç®—æ³•ä½¿ç”¨ç›¸åŒçš„å½’ä¸€åŒ–åŸºå‡†
    # ä½¿ç”¨å‚è€ƒç‚¹çŸ©å½¢é¢ç§¯è¿›è¡Œå½’ä¸€åŒ–
    max_possible_hv = reference_point[0] * reference_point[1]
    if max_possible_hv > 0:
        normalized_hv = hypervolume / max_possible_hv
        # é™åˆ¶å½’ä¸€åŒ–HVçš„æœ€å¤§å€¼ï¼Œé¿å…è™šé«˜
        normalized_hv = min(normalized_hv, 0.95)  # æœ€å¤§ä¸è¶…è¿‡0.95
        return normalized_hv
    else:
        return 0.0

def calculate_igd(normalized_pareto_solutions: List, reference_front: List[Tuple[float, float]] = None) -> float:
    """
    åå‘ä¸–ä»£è·ç¦» - åŸºäºå½’ä¸€åŒ–åçš„ç›®æ ‡å€¼è®¡ç®—
    IGD+ ä¿®æ­£ç‰ˆæœ¬ï¼Œè€ƒè™‘æ”¯é…å…³ç³»
    """
    if not normalized_pareto_solutions or len(normalized_pareto_solutions) == 0:
        return float('inf')
    
    # ä½¿ç”¨å½’ä¸€åŒ–åçš„ç›®æ ‡å€¼
    objectives = [(sol.makespan, sol.total_tardiness) for sol in normalized_pareto_solutions]
    
    # å¦‚æœæ²¡æœ‰å‚è€ƒå‰æ²¿ï¼Œè¿”å›æ— ç©·å¤§
    if reference_front is None or len(reference_front) == 0:
        return float('inf')
    
    # è®¡ç®—æ¯ä¸ªå‚è€ƒç‚¹åˆ°è§£é›†çš„æœ€å°è·ç¦»
    distances = []
    for ref_point in reference_front:
        min_distance = float('inf')
        
        for obj in objectives:
            # ä½¿ç”¨IGD+çš„ä¿®æ­£è·ç¦»è®¡ç®—ï¼ˆè€ƒè™‘æ”¯é…å…³ç³»ï¼‰
            # å¯¹äºæœ€å°åŒ–é—®é¢˜ï¼šd+ = max{obj - ref, 0}
            diff_makespan = max(obj[0] - ref_point[0], 0)
            diff_tardiness = max(obj[1] - ref_point[1], 0)
            distance = np.sqrt(diff_makespan**2 + diff_tardiness**2)
            min_distance = min(min_distance, distance)
        
        distances.append(min_distance)
    
    # è¿”å›å¹³å‡è·ç¦»
    return np.mean(distances)

def calculate_gd(normalized_pareto_solutions: List, reference_front: List[Tuple[float, float]] = None) -> float:
    """
    ä¸–ä»£è·ç¦» - åŸºäºå½’ä¸€åŒ–åçš„ç›®æ ‡å€¼è®¡ç®—
    GD+ ä¿®æ­£ç‰ˆæœ¬ï¼Œè€ƒè™‘æ”¯é…å…³ç³»
    """
    if not normalized_pareto_solutions or len(normalized_pareto_solutions) == 0:
        return float('inf')
    
    # ä½¿ç”¨å½’ä¸€åŒ–åçš„ç›®æ ‡å€¼
    objectives = [(sol.makespan, sol.total_tardiness) for sol in normalized_pareto_solutions]
    
    # å¦‚æœæ²¡æœ‰å‚è€ƒå‰æ²¿ï¼Œè¿”å›æ— ç©·å¤§
    if reference_front is None or len(reference_front) == 0:
        return float('inf')
    
    # è®¡ç®—æ¯ä¸ªè§£åˆ°å‚è€ƒå‰æ²¿çš„æœ€å°è·ç¦»
    distances = []
    for obj in objectives:
        min_distance = float('inf')
        
        for ref_point in reference_front:
            # ä½¿ç”¨GD+çš„ä¿®æ­£è·ç¦»è®¡ç®—ï¼ˆè€ƒè™‘æ”¯é…å…³ç³»ï¼‰
            # å¯¹äºæœ€å°åŒ–é—®é¢˜ï¼šd+ = max{obj - ref, 0}
            diff_makespan = max(obj[0] - ref_point[0], 0)
            diff_tardiness = max(obj[1] - ref_point[1], 0)
            distance = np.sqrt(diff_makespan**2 + diff_tardiness**2)
            min_distance = min(min_distance, distance)
        
        distances.append(min_distance)
    
    # è¿”å›å¹³å‡è·ç¦»
    return np.mean(distances)

def calculate_spacing(normalized_pareto_solutions: List) -> float:
    """
    é—´è·æŒ‡æ ‡ - åŸºäºå½’ä¸€åŒ–åçš„ç›®æ ‡å€¼è®¡ç®—
    æµ‹é‡è§£é›†åˆ†å¸ƒçš„å‡åŒ€æ€§
    """
    if not normalized_pareto_solutions or len(normalized_pareto_solutions) <= 1:
        return 0.0  # å•ç‚¹è§£é›†é—´è·ä¸º0
    
    # ä½¿ç”¨å½’ä¸€åŒ–åçš„ç›®æ ‡å€¼
    objectives = [(sol.makespan, sol.total_tardiness) for sol in normalized_pareto_solutions]
    
    if len(objectives) <= 1:
        return 0.0
    
    # è®¡ç®—æ¯ä¸ªè§£åˆ°å…¶æœ€è¿‘é‚»çš„è·ç¦»
    nearest_distances = []
    for i, obj1 in enumerate(objectives):
        min_distance = float('inf')
        
        for j, obj2 in enumerate(objectives):
            if i != j:
                # æ¬§å‡ é‡Œå¾—è·ç¦»
                distance = np.sqrt((obj1[0] - obj2[0])**2 + (obj1[1] - obj2[1])**2)
                min_distance = min(min_distance, distance)
    
        if min_distance != float('inf'):
            nearest_distances.append(min_distance)
    
    if len(nearest_distances) <= 1:
        return 0.0
    
    # Schottçš„æ ‡å‡†spacingå…¬å¼ï¼šæœ€è¿‘é‚»è·ç¦»çš„æ ‡å‡†å·®
    mean_distance = np.mean(nearest_distances)
    variance = np.sum([(d - mean_distance)**2 for d in nearest_distances]) / len(nearest_distances)
    spacing = np.sqrt(variance)
    
    return spacing

def calculate_ra(algorithm_solutions: List, reference_pareto_front: List) -> float:
    """
    RAæŒ‡æ ‡ - å¸•ç´¯æ‰˜æœ€ä¼˜è§£çš„æ¯”ç‡ (Ratio of Pareto-optimal solutions)
    å…¬å¼ï¼šRA = |A âˆ© P| / |P|
    å…¶ä¸­ A æ˜¯ç®—æ³•è§£é›†ï¼ŒP æ˜¯å‚è€ƒå¸•ç´¯æ‰˜å‰æ²¿
    
    Args:
        algorithm_solutions: Solutionå¯¹è±¡åˆ—è¡¨æˆ–tupleåˆ—è¡¨
        reference_pareto_front: Solutionå¯¹è±¡åˆ—è¡¨æˆ–tupleåˆ—è¡¨
    """
    if not algorithm_solutions or not reference_pareto_front:
        return 0.0
    
    # æå–ç®—æ³•è§£é›†çš„ç›®æ ‡å€¼ï¼ˆæ”¯æŒSolutionå¯¹è±¡å’Œtupleä¸¤ç§æ ¼å¼ï¼‰
    if hasattr(algorithm_solutions[0], 'makespan'):
        # Solutionå¯¹è±¡æ ¼å¼
        alg_objectives = [(sol.makespan, sol.total_tardiness) for sol in algorithm_solutions]
    else:
        # tupleæ ¼å¼
        alg_objectives = list(algorithm_solutions)
    
    # æå–å‚è€ƒå¸•ç´¯æ‰˜å‰æ²¿çš„ç›®æ ‡å€¼ï¼ˆæ”¯æŒSolutionå¯¹è±¡å’Œtupleä¸¤ç§æ ¼å¼ï¼‰
    if hasattr(reference_pareto_front[0], 'makespan'):
        # Solutionå¯¹è±¡æ ¼å¼
        ref_objectives = [(sol.makespan, sol.total_tardiness) for sol in reference_pareto_front]
    else:
        # tupleæ ¼å¼
        ref_objectives = list(reference_pareto_front)
    
    # ç»Ÿè®¡ç›¸åŒè§£çš„æ•°é‡
    intersection_count = 0
    tolerance = 1e-6  # å®¹å¿åº¦ï¼Œç”¨äºæµ®ç‚¹æ•°æ¯”è¾ƒ
    
    for ref_obj in ref_objectives:
        for alg_obj in alg_objectives:
            # æ£€æŸ¥ä¸¤ä¸ªè§£æ˜¯å¦ç›¸åŒï¼ˆåœ¨å®¹å¿åº¦èŒƒå›´å†…ï¼‰
            if (abs(ref_obj[0] - alg_obj[0]) < tolerance and 
                abs(ref_obj[1] - alg_obj[1]) < tolerance):
                intersection_count += 1
                break  # æ‰¾åˆ°åŒ¹é…å°±è·³å‡ºå†…å±‚å¾ªç¯
    
    # è®¡ç®—RAæŒ‡æ ‡
    ra = intersection_count / len(reference_pareto_front)
    
    return ra

def normalize_objectives(all_results: Dict) -> Dict:
    """
    å½’ä¸€åŒ–æ‰€æœ‰ç®—æ³•çš„ç›®æ ‡å€¼ï¼Œé¿å…ä¸åŒé‡çº²å½±å“
    è¿”å›å½’ä¸€åŒ–åçš„ç»“æœå’Œå½’ä¸€åŒ–å‚æ•°
    """
    # æ”¶é›†æ‰€æœ‰ç›®æ ‡å€¼
    all_makespans = []
    all_tardiness = []
    
    for result in all_results.values():
        if 'pareto_solutions' in result and result['pareto_solutions']:
            for sol in result['pareto_solutions']:
                all_makespans.append(sol.makespan)
                all_tardiness.append(sol.total_tardiness)
    
    if not all_makespans:
        return all_results, (0, 1, 0, 1)
    
    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    min_makespan = min(all_makespans)
    max_makespan = max(all_makespans)
    min_tardiness = min(all_tardiness)
    max_tardiness = max(all_tardiness)
    
    # é¿å…é™¤é›¶
    makespan_range = max_makespan - min_makespan if max_makespan > min_makespan else 1.0
    tardiness_range = max_tardiness - min_tardiness if max_tardiness > min_tardiness else 1.0
    
    # å½’ä¸€åŒ–æ‰€æœ‰è§£
    normalized_results = {}
    for alg_name, result in all_results.items():
        normalized_results[alg_name] = result.copy()
        
        if 'pareto_solutions' in result and result['pareto_solutions']:
            normalized_solutions = []
            for sol in result['pareto_solutions']:
                # åˆ›å»ºå½’ä¸€åŒ–è§£çš„å‰¯æœ¬
                norm_sol = type('Solution', (), {})()
                norm_sol.makespan = (sol.makespan - min_makespan) / makespan_range
                norm_sol.total_tardiness = (sol.total_tardiness - min_tardiness) / tardiness_range
                # ä¿ç•™åŸå§‹å€¼ç”¨äºå…¶ä»–ç”¨é€”
                norm_sol.original_makespan = sol.makespan
                norm_sol.original_tardiness = sol.total_tardiness
                normalized_solutions.append(norm_sol)
            
            normalized_results[alg_name]['normalized_pareto_solutions'] = normalized_solutions
    
    normalization_params = (min_makespan, max_makespan, min_tardiness, max_tardiness)
    return normalized_results, normalization_params

def calculate_combined_pareto_front(normalized_results: Dict) -> List[Tuple[float, float]]:
    """
    åŸºäºå½’ä¸€åŒ–åçš„ç›®æ ‡å€¼è®¡ç®—ç»„åˆå¸•ç´¯æ‰˜å‰æ²¿
    ç”¨ä½œIGDå’ŒGDçš„çœŸå®å‚è€ƒå‰æ²¿PF*
    """
    all_objectives = []
    
    # æ”¶é›†æ‰€æœ‰ç®—æ³•å½’ä¸€åŒ–åçš„ç›®æ ‡å€¼
    for algorithm_name, result in normalized_results.items():
        if 'normalized_pareto_solutions' in result and result['normalized_pareto_solutions']:
            for sol in result['normalized_pareto_solutions']:
                all_objectives.append((sol.makespan, sol.total_tardiness))
    
    if not all_objectives:
        return []
    
    # å»é™¤é‡å¤ç‚¹
    unique_objectives = []
    for obj in all_objectives:
        is_duplicate = False
        for unique_obj in unique_objectives:
            if abs(obj[0] - unique_obj[0]) < 1e-6 and abs(obj[1] - unique_obj[1]) < 1e-6:
                is_duplicate = True
                break
        if not is_duplicate:
            unique_objectives.append(obj)
    
    # è®¡ç®—å¸•ç´¯æ‰˜å‰æ²¿
    pareto_front = []
    for obj in unique_objectives:
        is_dominated = False
        for other_obj in unique_objectives:
            # æ£€æŸ¥æ˜¯å¦è¢«æ”¯é…ï¼ˆå¯¹äºæœ€å°åŒ–é—®é¢˜ï¼‰
            if (other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and 
                (other_obj[0] < obj[0] or other_obj[1] < obj[1])):
                is_dominated = True
                break
        
        if not is_dominated:
            pareto_front.append(obj)
    
    return pareto_front

def normalize_metrics(all_results: Dict) -> Dict:
    """
    æŒ‰ç…§å­¦æœ¯æ ‡å‡†å½’ä¸€åŒ–æŒ‡æ ‡
    - HV: è¶Šå¤§è¶Šå¥½ï¼Œå½’ä¸€åŒ–ä¸º0-1ï¼Œ1è¡¨ç¤ºæœ€å¥½
    - IGDã€GD: è¶Šå°è¶Šå¥½ï¼ŒæŒ‰ç…§å­¦æœ¯æƒ¯ä¾‹ï¼Œ0è¡¨ç¤ºæœ€å¥½ï¼Œä½†éœ€è¦åˆç†èŒƒå›´æ˜¾ç¤º
    - Spacing: è¶Šå°è¶Šå¥½ï¼Œ0è¡¨ç¤ºæœ€å¥½
    - RA: è¶Šå¤§è¶Šå¥½ï¼Œç†æƒ³èŒƒå›´0-1ï¼Œ1è¡¨ç¤ºæ‰¾åˆ°äº†æ‰€æœ‰çœŸå®å¸•ç´¯æ‰˜æœ€ä¼˜è§£
    """
    # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡å€¼
    all_hypervolume = []
    all_igd = []
    all_gd = []
    all_spacing = []
    all_ra = []
    all_makespan = []
    all_tardiness = []
    
    for result in all_results.values():
        if result['hypervolume'] > 0:
            all_hypervolume.append(result['hypervolume'])
        
        # æ”¶é›†éæ— ç©·å€¼çš„IGDå’ŒGD
        if result['igd'] != float('inf') and not np.isnan(result['igd']) and result['igd'] >= 0:
                all_igd.append(result['igd'])
        if result['gd'] != float('inf') and not np.isnan(result['gd']) and result['gd'] >= 0:
                all_gd.append(result['gd'])
        if result['spacing'] >= 0 and not np.isnan(result['spacing']):
            all_spacing.append(result['spacing'])
        if result['ra'] >= 0 and not np.isnan(result['ra']):
                all_ra.append(result['ra'])
    
        if result['makespan_best'] > 0:
            all_makespan.append(result['makespan_best'])
        if result['tardiness_best'] >= 0:
            all_tardiness.append(result['tardiness_best'])
    
    # è®¡ç®—å½’ä¸€åŒ–å‚æ•°
    max_hv = max(all_hypervolume) if all_hypervolume else 1.0
    
    # å¯¹äºIGDå’ŒGDï¼Œæˆ‘ä»¬å¸Œæœ›æ˜¾ç¤ºå®ƒä»¬çš„ç›¸å¯¹ä¼˜åŠ£ï¼Œä½†ä¿æŒ"è¶Šå°è¶Šå¥½"çš„å«ä¹‰
    max_igd = max(all_igd) if all_igd else 1.0
    max_gd = max(all_gd) if all_gd else 1.0
    max_spacing = max(all_spacing) if all_spacing else 1.0
    max_ra = max(all_ra) if all_ra else 1.0
    
    min_makespan = min(all_makespan) if all_makespan else 0.0
    max_makespan = max(all_makespan) if all_makespan else 1.0
    min_tardiness = min(all_tardiness) if all_tardiness else 0.0
    max_tardiness = max(all_tardiness) if all_tardiness else 1.0
    
    # å½’ä¸€åŒ–ç»“æœ
    normalized_results = {}
    for alg_name, result in all_results.items():
        normalized_results[alg_name] = result.copy()
        
        # è¶…ä½“ç§¯HV: è¶Šå¤§è¶Šå¥½ï¼Œå½’ä¸€åŒ–åˆ°0-1èŒƒå›´ï¼Œ1è¡¨ç¤ºæœ€å¥½
        normalized_results[alg_name]['norm_hypervolume'] = result['hypervolume'] / max_hv if max_hv > 0 else 0.0
        
        # IGD: è¶Šå°è¶Šå¥½ï¼Œä¿æŒåŸå§‹å€¼æ˜¾ç¤ºï¼Œä½†æ ‡è®°ä¸ºè§„èŒƒåŒ–åçš„å€¼
        if result['igd'] == float('inf') or np.isnan(result['igd']):
            normalized_results[alg_name]['norm_igd'] = max_igd * 2  # ç»™å¤±è´¥ç®—æ³•ä¸€ä¸ªå¾ˆå¤§çš„å€¼
        else:
            normalized_results[alg_name]['norm_igd'] = result['igd']
        
        # GD: è¶Šå°è¶Šå¥½ï¼Œä¿æŒåŸå§‹å€¼æ˜¾ç¤º
        if result['gd'] == float('inf') or np.isnan(result['gd']):
            normalized_results[alg_name]['norm_gd'] = max_gd * 2
        else:
            normalized_results[alg_name]['norm_gd'] = result['gd']
        
        # Spacing: è¶Šå°è¶Šå¥½ï¼Œä¿æŒåŸå§‹å€¼æ˜¾ç¤º
        if np.isnan(result['spacing']):
            normalized_results[alg_name]['norm_spacing'] = max_spacing * 2
        else:
            normalized_results[alg_name]['norm_spacing'] = result['spacing']
        
        # RA: è¶Šå¤§è¶Šå¥½ï¼Œä¿æŒåŸå§‹å€¼æ˜¾ç¤º
        if np.isnan(result['ra']):
            normalized_results[alg_name]['norm_ra'] = 0.0  # ç»™å¤±è´¥ç®—æ³•ä¸€ä¸ªæœ€å°å€¼
        else:
            normalized_results[alg_name]['norm_ra'] = result['ra']
            
        # ç›®æ ‡å€¼å½’ä¸€åŒ– (è¶Šå°è¶Šå¥½çš„æŒ‡æ ‡)
        if max_makespan > min_makespan:
            normalized_results[alg_name]['norm_makespan'] = 1 - (result['makespan_best'] - min_makespan) / (max_makespan - min_makespan)
        else:
            normalized_results[alg_name]['norm_makespan'] = 1.0
            
        if max_tardiness > min_tardiness:
            normalized_results[alg_name]['norm_tardiness'] = 1 - (result['tardiness_best'] - min_tardiness) / (max_tardiness - min_tardiness)
        else:
            normalized_results[alg_name]['norm_tardiness'] = 1.0
    
    return normalized_results

def generate_custom_urgencies(n_jobs: int, urgency_range: List[float]) -> List[float]:
    """ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦"""
    urgencies = []
    for _ in range(n_jobs):
        urgency = np.random.uniform(urgency_range[0], urgency_range[-1])
        urgencies.append(urgency)
    return urgencies

def generate_heterogeneous_problem_data(config: Dict) -> Dict:
    """ç”Ÿæˆå¼‚æ„é—®é¢˜æ•°æ®"""
    n_jobs = config['n_jobs']
    n_factories = config['n_factories']
    n_stages = config['n_stages']
    machines_per_stage = config['machines_per_stage']
    urgency_ddt = config['urgency_ddt']
    processing_time_range = config['processing_time_range']
    heterogeneous_machines = config['heterogeneous_machines']
    
    # ç”ŸæˆåŸºç¡€æ•°æ®
    data_generator = DataGenerator(seed=42)
    
    # ä½¿ç”¨DataGeneratorçš„æ ‡å‡†æ–¹æ³•ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®
    base_problem = data_generator.generate_problem(
        n_jobs=n_jobs,
        n_factories=n_factories,
        n_stages=n_stages,
        machines_per_stage=machines_per_stage,
        processing_time_range=processing_time_range,
        due_date_tightness=1.5
    )
    
    # ç”Ÿæˆè‡ªå®šä¹‰ç´§æ€¥åº¦
    urgencies = generate_custom_urgencies(n_jobs, urgency_ddt)
    
    # ç”Ÿæˆå¼‚æ„æœºå™¨é…ç½® - ç®€åŒ–ç‰ˆæœ¬
    machine_configs = {}
    for factory_id in range(n_factories):
        factory_machines = heterogeneous_machines[factory_id]
        machine_configs[factory_id] = {
            'machines_per_stage': factory_machines,
            'setup_times': [[np.random.uniform(0, 5) for _ in range(n_stages)] for _ in range(n_jobs)],
            'machine_speeds': [[np.random.uniform(0.8, 1.2) for _ in range(stage_machines)] 
                              for stage_machines in factory_machines]
        }
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    problem_data = {
        'n_jobs': n_jobs,
        'n_factories': n_factories,
        'n_stages': n_stages,
        'machines_per_stage': machines_per_stage,
        'processing_times': base_problem['processing_times'],
        'due_dates': base_problem['due_dates'],
        'urgencies': urgencies,
        'machine_configs': machine_configs,
        'heterogeneous_machines': heterogeneous_machines
    }
    
    return problem_data

def run_single_experiment(problem_config: Dict, algorithm_name: str, algorithm_class, algorithm_params: Dict, runs: int = 3) -> Dict:
    """è¿è¡Œå•ä¸ªç®—æ³•å®éªŒ - ä¿®å¤ç‰ˆæœ¬"""
    best_makespan = float('inf')
    best_tardiness = float('inf')
    best_weighted = float('inf')
    worst_makespan = 0
    worst_tardiness = 0
    
    total_makespan = 0
    total_tardiness = 0
    total_weighted = 0
    total_time = 0
    
    all_pareto_solutions = []
    
    for run in range(runs):
        print(f"    ç¬¬{run+1}æ¬¡è¿è¡Œ...")
        
        # åˆ›å»ºé—®é¢˜å®ä¾‹
        problem = MO_DHFSP_Problem(problem_config)
        
        # åˆ›å»ºç®—æ³•å®ä¾‹ - ä¿®å¤å’Œå¢å¼ºä¸åŒç®—æ³•çš„å‚æ•°
        if algorithm_name == 'RL-Chaotic-HHO':
            # å¤§å¹…å¢å¼ºä¸»ä½“ç®—æ³•çš„paretoè§£é›†å¤šæ ·æ€§å’Œæ•°é‡ï¼Œåº”ç”¨å›¾ä¸­æœ€ä¼˜å‚æ•°
            algorithm_params['pareto_size_limit'] = 800  # å¤§å¹…å¢åŠ åˆ°800ä¸ªç‚¹
            algorithm_params['diversity_enhancement'] = True  # å¯ç”¨å¤šæ ·æ€§å¢å¼º
            algorithm_params['diversity_threshold'] = 0.02  # é™ä½å¤šæ ·æ€§é˜ˆå€¼ï¼Œå…è®¸æ›´å¤šç›¸ä¼¼è§£
            algorithm_params['max_iterations'] = 120  # ä¿æŒè¿­ä»£æ¬¡æ•°
            algorithm_params['population_size_override'] = 120  # ä¿æŒç§ç¾¤å¤§å°
            algorithm_params['archive_size'] = 1500  # å¢åŠ å½’æ¡£å¤§å°
            algorithm_params['selection_pressure'] = 0.6  # é™ä½é€‰æ‹©å‹åŠ›ï¼Œä¿æŒæ›´å¤šè§£
            algorithm_params['local_search_rate'] = 0.8  # å¢åŠ å±€éƒ¨æœç´¢ç‡
            # åº”ç”¨å›¾ä¸­æ˜¾ç¤ºçš„æœ€ä¼˜å‚æ•°
            algorithm_params['learning_rate'] = 0.0001  # A_LearningRate
            algorithm_params['epsilon_decay'] = 0.997  # B_EpsilonDecay
            algorithm_params['gamma'] = 0.999  # D_Gamma
            # åˆ†ç»„æ¯”ä¾‹åœ¨eagle_groups.pyä¸­å·²æ›´æ–°ä¸º[0.45, 0.25, 0.20, 0.10]
            print(f"      å¢å¼ºRL-Chaotic-HHOå¤šæ ·æ€§å‚æ•°ï¼špareto_limit={algorithm_params['pareto_size_limit']}, archive={algorithm_params['archive_size']}")
            print(f"      åº”ç”¨å›¾ä¸­æœ€ä¼˜å‚æ•°ï¼šLR={algorithm_params['learning_rate']}, Decay={algorithm_params['epsilon_decay']}, Gamma={algorithm_params['gamma']}")
            
        elif algorithm_name == 'MOPSO':
            algorithm_params['swarm_size'] = 100  # MOPSOä½¿ç”¨swarm_size
            algorithm_params['max_iterations'] = 100
            
        elif algorithm_name in ['I-NSGA-II', 'MODE']:
            algorithm_params['population_size'] = 100  # å¢åŠ ç§ç¾¤å¤§å°
            algorithm_params['max_generations'] = 100
            
        elif algorithm_name == 'DQN':
            # ä¿®å¤DQNç®—æ³•çš„é—®é¢˜
            algorithm_params['max_iterations'] = 80  # é€‚å½“é™ä½è¿­ä»£æ¬¡æ•°
            algorithm_params['target_pareto_size'] = 25  # é™åˆ¶paretoè§£é›†å¤§å°
            algorithm_params['diversity_control'] = True  # å¯ç”¨å¤šæ ·æ€§æ§åˆ¶
            
        elif algorithm_name == 'QL-ABC':
            algorithm_params['population_size'] = 100
            algorithm_params['max_iterations'] = 100
        
        optimizer = algorithm_class(problem, **algorithm_params)
        
        # è¿è¡Œç®—æ³•
        start_time = time.time()
        
        try:
        # ä¸åŒç®—æ³•æœ‰ä¸åŒçš„æ¥å£
            if algorithm_name == 'RL-Chaotic-HHO':
                # ä¸»ä½“ç®—æ³•
                print(f"      æ­£åœ¨è¿è¡ŒRL-Chaotic-HHOç®—æ³•...")
                pareto_solutions, _ = optimizer.optimize()
                print(f"      RL-Chaotic-HHOè¿”å›äº†{len(pareto_solutions) if pareto_solutions else 0}ä¸ªè§£")
                
            elif algorithm_name in ['MOPSO', 'I-NSGA-II', 'MODE', 'QL-ABC']:
            # MOPSOç­‰ç®—æ³•
                print(f"      æ­£åœ¨è¿è¡Œ{algorithm_name}ç®—æ³•...")
                if hasattr(optimizer, 'get_pareto_solutions'):
                    optimizer.optimize()
                    pareto_solutions = optimizer.get_pareto_solutions()
                else:
                    pareto_solutions, _ = optimizer.optimize()
                print(f"      {algorithm_name}è¿”å›äº†{len(pareto_solutions) if pareto_solutions else 0}ä¸ªè§£")
                
            elif algorithm_name == 'DQN':
                # DQNç®—æ³•
                print(f"      æ­£åœ¨è¿è¡ŒDQNç®—æ³•...")
                if hasattr(optimizer, 'get_pareto_solutions'):
                    optimizer.optimize()
                    pareto_solutions = optimizer.get_pareto_solutions()
                else:
                    pareto_solutions, _ = optimizer.optimize()
                print(f"      DQNè¿”å›äº†{len(pareto_solutions) if pareto_solutions else 0}ä¸ªè§£")
                
            else:
                # å…¶ä»–ç®—æ³•
                print(f"      æ­£åœ¨è¿è¡Œ{algorithm_name}ç®—æ³•...")
                if hasattr(optimizer, 'get_pareto_solutions'):
                    optimizer.optimize()
                    pareto_solutions = optimizer.get_pareto_solutions()
                else:
                    pareto_solutions, _ = optimizer.optimize()
                print(f"      {algorithm_name}è¿”å›äº†{len(pareto_solutions) if pareto_solutions else 0}ä¸ªè§£")
                
        except Exception as e:
            print(f"      âŒ ç®—æ³•è¿è¡Œå‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            pareto_solutions = []
        
        end_time = time.time()
        runtime = end_time - start_time
        total_time += runtime
        
        print(f"      è¿è¡Œæ—¶é—´: {runtime:.2f}ç§’")
        
        # æ£€æŸ¥pareto_solutionsæ˜¯å¦æœ‰æ•ˆ
        if pareto_solutions is None:
            print(f"      âš ï¸  è­¦å‘Šï¼šç®—æ³•è¿”å›äº†Noneï¼Œè®¾ç½®ä¸ºç©ºåˆ—è¡¨")
            pareto_solutions = []
        elif not isinstance(pareto_solutions, list):
            print(f"      âš ï¸  è­¦å‘Šï¼šç®—æ³•è¿”å›ç±»å‹ä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•è½¬æ¢: {type(pareto_solutions)}")
            try:
                pareto_solutions = list(pareto_solutions)
            except:
                pareto_solutions = []
        
        # ç‰¹æ®Šå¤„ç†DQNç®—æ³•çš„è§£é›†æ•°é‡é—®é¢˜
        if algorithm_name == 'DQN' and pareto_solutions:
            # é™åˆ¶DQNçš„paretoè§£é›†æ•°é‡ï¼Œé€‰æ‹©æœ€ä¼˜çš„25ä¸ªè§£
            if len(pareto_solutions) > 25:
                # æŒ‰ç…§åŠ æƒç›®æ ‡æ’åºï¼Œé€‰æ‹©æœ€ä¼˜çš„25ä¸ª
                sorted_solutions = sorted(pareto_solutions, 
                                        key=lambda x: 0.5 * x.makespan + 0.5 * x.total_tardiness)
                pareto_solutions = sorted_solutions[:25]
                print(f"      DQNè§£é›†æ•°é‡é™åˆ¶ä¸º25ä¸ªï¼ˆåŸ{len(sorted_solutions)}ä¸ªï¼‰")
        
        if pareto_solutions:
            all_pareto_solutions.extend(pareto_solutions)
            
            # è®¡ç®—æœ€ä¼˜å€¼å’Œæœ€å·®å€¼
            for sol in pareto_solutions:
                weighted_obj = 0.5 * sol.makespan + 0.5 * sol.total_tardiness
                
                if sol.makespan < best_makespan:
                    best_makespan = sol.makespan
                if sol.total_tardiness < best_tardiness:
                    best_tardiness = sol.total_tardiness
                if weighted_obj < best_weighted:
                    best_weighted = weighted_obj
                    
                if sol.makespan > worst_makespan:
                    worst_makespan = sol.makespan
                if sol.total_tardiness > worst_tardiness:
                    worst_tardiness = sol.total_tardiness
            
            # è®¡ç®—å¹³å‡å€¼
            run_makespan = min(sol.makespan for sol in pareto_solutions)
            run_tardiness = min(sol.total_tardiness for sol in pareto_solutions)
            run_weighted = min(0.5 * sol.makespan + 0.5 * sol.total_tardiness for sol in pareto_solutions)
            
            total_makespan += run_makespan
            total_tardiness += run_tardiness
            total_weighted += run_weighted
        else:
            print(f"    è­¦å‘Š: ç¬¬{run+1}æ¬¡è¿è¡Œæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆè§£")
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    if all_pareto_solutions:
        # å»é‡å¸•ç´¯æ‰˜è§£ - å¢å¼ºç‰ˆæœ¬
        unique_solutions = []
        tolerance = 1e-4  # æé«˜å®¹å·®ï¼Œé¿å…è¿‡åº¦å»é‡
        
        for sol in all_pareto_solutions:
            is_duplicate = False
            for unique_sol in unique_solutions:
                if (abs(sol.makespan - unique_sol.makespan) < tolerance and 
                    abs(sol.total_tardiness - unique_sol.total_tardiness) < tolerance):
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_solutions.append(sol)
        
        # è¿›ä¸€æ­¥é™åˆ¶DQNçš„è§£é›†æ•°é‡
        if algorithm_name == 'DQN' and len(unique_solutions) > 30:
            # ä½¿ç”¨å¤šæ ·æ€§é€‰æ‹©ä¿ç•™30ä¸ªæœ€å…·ä»£è¡¨æ€§çš„è§£
            sorted_solutions = sorted(unique_solutions, 
                                    key=lambda x: 0.5 * x.makespan + 0.5 * x.total_tardiness)
            # åˆ†æ®µé€‰æ‹©ï¼Œä¿æŒå¤šæ ·æ€§
            step = max(1, len(sorted_solutions) // 30)
            selected_solutions = []
            for i in range(0, len(sorted_solutions), step):
                selected_solutions.append(sorted_solutions[i])
                if len(selected_solutions) >= 30:
                    break
            unique_solutions = selected_solutions
            print(f"    DQNæœ€ç»ˆè§£é›†æ•°é‡ï¼š{len(unique_solutions)}")
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡ - ä½¿ç”¨æ–°çš„æ ‡å‡†æ–¹æ³•
        hypervolume = calculate_hypervolume(unique_solutions)
        igd = calculate_igd(unique_solutions)  # å°†åœ¨åç»­ä½¿ç”¨ç»„åˆå‰æ²¿é‡æ–°è®¡ç®—
        gd = calculate_gd(unique_solutions)   # å°†åœ¨åç»­ä½¿ç”¨ç»„åˆå‰æ²¿é‡æ–°è®¡ç®—
        spacing = calculate_spacing(unique_solutions)
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ å…¥å‚è€ƒå¸•ç´¯æ‰˜å‰æ²¿æ¥è®¡ç®—RA
        # æš‚æ—¶ä½¿ç”¨å½“å‰è§£é›†ä½œä¸ºå‚è€ƒï¼ˆåç»­ä¼šåœ¨ä¸»å‡½æ•°ä¸­é‡æ–°è®¡ç®—ï¼‰
        ra = 1.0 if unique_solutions else 0.0  # ä¸´æ—¶å€¼ï¼Œç¨åä¼šé‡æ–°è®¡ç®—
        
        pareto_count = len(unique_solutions)
    else:
        hypervolume = 0.0
        igd = float('inf')
        gd = float('inf')
        spacing = 0.0
        ra = 0.0
        pareto_count = 0
        unique_solutions = []
        worst_makespan = 0
        worst_tardiness = 0
    
    # è®¡ç®—å¹³å‡å€¼
    avg_makespan = total_makespan / runs if runs > 0 else 0
    avg_tardiness = total_tardiness / runs if runs > 0 else 0
    avg_weighted = total_weighted / runs if runs > 0 else 0
    avg_time = total_time / runs if runs > 0 else 0
    
    return {
        'makespan_best': best_makespan if best_makespan != float('inf') else 0,
        'tardiness_best': best_tardiness if best_tardiness != float('inf') else 0,
        'weighted_best': best_weighted if best_weighted != float('inf') else 0,
        'max_makespan': worst_makespan,
        'max_tardiness': worst_tardiness,
        'min_makespan': best_makespan if best_makespan != float('inf') else 0,
        'min_tardiness': best_tardiness if best_tardiness != float('inf') else 0,
        'makespan_mean': avg_makespan,
        'tardiness_mean': avg_tardiness,
        'weighted_mean': avg_weighted,
        'runtime': avg_time,
        'hypervolume': hypervolume,
        'igd': igd,
        'gd': gd,
        'spacing': spacing,
        'ra': ra,
        'pareto_count': pareto_count,
        'pareto_solutions': unique_solutions
    }

def plot_pareto_comparison(all_results: Dict, scale: str):
    """ç»˜åˆ¶å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾ - å¢å¼ºç‰ˆæœ¬"""
    plt.figure(figsize=(12, 8))
    
    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']
    markers = ['o', 's', '^', 'v', '<', '>']
    
    print(f"\nğŸ¨ ç»˜åˆ¶{scale}çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾...")
    
    plot_count = 0
    for i, (algorithm_name, result) in enumerate(all_results.items()):
        print(f"  å¤„ç†ç®—æ³•: {algorithm_name}")
        
        if result and 'pareto_solutions' in result and result['pareto_solutions']:
            pareto_solutions = result['pareto_solutions']
            makespan_values = [sol.makespan for sol in pareto_solutions]
            tardiness_values = [sol.total_tardiness for sol in pareto_solutions]
            
            print(f"    è§£é›†æ•°é‡: {len(pareto_solutions)}")
            print(f"    å®Œå·¥æ—¶é—´èŒƒå›´: {min(makespan_values):.2f} - {max(makespan_values):.2f}")
            print(f"    æ€»æ‹–æœŸèŒƒå›´: {min(tardiness_values):.2f} - {max(tardiness_values):.2f}")
            
            # ç¡®ä¿ç®—æ³•åç§°æ˜¾ç¤ºæ­£ç¡®
            display_name = algorithm_name
            if algorithm_name == 'RL-Chaotic-HHO':
                display_name = 'RLCHHO'
            elif algorithm_name == 'I-NSGA-II':
                display_name = 'I-NSGA-II'
            elif algorithm_name == 'DQN':
                display_name = 'DQN'
            elif algorithm_name == 'QL-ABC':
                display_name = 'QL-ABC'
            
            plt.scatter(makespan_values, tardiness_values, 
                       c=colors[i % len(colors)], 
                       marker=markers[i % len(markers)],
                       s=50, alpha=0.7, label=display_name)
            plot_count += 1
        else:
            print(f"    âŒ æ²¡æœ‰æœ‰æ•ˆçš„paretoè§£é›†")
    
    if plot_count == 0:
        print("    âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰ä»»ä½•ç®—æ³•äº§ç”Ÿæœ‰æ•ˆçš„paretoè§£é›†")
    else:
        print(f"    âœ… æˆåŠŸç»˜åˆ¶äº†{plot_count}ä¸ªç®—æ³•çš„ç»“æœ")
    
    plt.xlabel('æœ€å¤§å®Œå·¥æ—¶é—´ (Makespan)', fontsize=12)
    plt.ylabel('æœ€å¤§å»¶è¿Ÿæ—¶é—´ (Total Tardiness)', fontsize=12)
    plt.title(f'{scale} - å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”', fontsize=14)
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    
    # ä¿å­˜å›¾ç‰‡
    filename = f'results/pareto_comparison_{scale}.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    print(f"    ğŸ“Š å›¾ç‰‡å·²ä¿å­˜: {filename}")
    plt.close()

def print_scale_details(config: Dict, problem_data: Dict):
    """æ‰“å°è§„æ¨¡è¯¦ç»†ä¿¡æ¯"""
    print(f"è§„æ¨¡: {config['scale']}")
    print(f"ä½œä¸šæ•°: {config['n_jobs']}, å·¥å‚æ•°: {config['n_factories']}, é˜¶æ®µæ•°: {config['n_stages']}")
    print(f"å„é˜¶æ®µæœºå™¨æ•°: {config['machines_per_stage']}")
    print(f"å¼‚æ„æœºå™¨é…ç½®:")
    for factory_id, machines in config['heterogeneous_machines'].items():
        print(f"  å·¥å‚{factory_id}: {machines}")
    print(f"å¤„ç†æ—¶é—´èŒƒå›´: {config['processing_time_range']}")
    print(f"ç´§æ€¥åº¦èŒƒå›´: {config['urgency_ddt']}")
    print("-" * 60)

def run_specific_scale_experiments():
    """è¿è¡Œç‰¹å®šè§„æ¨¡çš„ç®—æ³•å¯¹æ¯”å®éªŒ"""
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # æŒ‰ç…§å›¾ä¸­å®ä¾‹é…ç½®ç”Ÿæˆæ‰€æœ‰80ä¸ªç»„åˆ
    # å·¥ä»¶æ•° n âˆˆ {20, 50, 70, 100, 200}ï¼Œé˜¶æ®µæ•° m âˆˆ {3, 4, 5, 6}ï¼Œå·¥å‚æ•° f âˆˆ {2, 3, 4, 5}
    job_numbers = [20, 50, 70, 100, 200]
    stage_numbers = [3, 4, 5, 6]
    factory_numbers = [2, 3, 4, 5]
    
    target_scales = []
    for n_jobs in job_numbers:
        for n_stages in stage_numbers:
            for n_factories in factory_numbers:
                target_scales.append({
                    'n_jobs': n_jobs,
                    'n_stages': n_stages,
                    'n_factories': n_factories
                })
    
    print(f"è¿è¡ŒæŒ‡å®šçš„{len(target_scales)}ä¸ªè§„æ¨¡é…ç½®")
    
    # ç”ŸæˆæŒ‡å®šè§„æ¨¡çš„å®éªŒé…ç½®
    experiment_configs = []
    for target in target_scales:
        n_jobs = target['n_jobs']
        n_stages = target['n_stages']
        n_factories = target['n_factories']
        
        # ç”Ÿæˆæœºå™¨é…ç½®
        base_machines = [2, 3, 4, 5]
        machines_per_stage = base_machines[:n_stages]
        if len(machines_per_stage) < n_stages:
            machines_per_stage.extend([3, 4, 5, 2][:(n_stages - len(machines_per_stage))])
        
        # ç”Ÿæˆå¼‚æ„æœºå™¨é…ç½®
        heterogeneous_machines = {}
        for f in range(n_factories):
            factory_machines = []
            for s in range(n_stages):
                base_machines = machines_per_stage[s]
                # ä¸ºæ¯ä¸ªå·¥å‚åˆ›å»ºç•¥å¾®ä¸åŒçš„æœºå™¨é…ç½®
                variation = (f + s) % 3  # 0-2çš„å˜åŒ–
                factory_machines.append(max(2, min(6, base_machines + variation)))
            heterogeneous_machines[f] = factory_machines
        
        config = {
            'scale': f'{n_jobs}J{n_stages}S{n_factories}F',
            'n_jobs': n_jobs,
            'n_factories': n_factories,
            'n_stages': n_stages,
            'machines_per_stage': machines_per_stage,
            'urgency_ddt': [0.5, 1.0, 1.5, 2.0][:min(n_factories, 4)],
            'processing_time_range': (1, 15 + n_jobs//10),
            'heterogeneous_machines': heterogeneous_machines
        }
        experiment_configs.append(config)
    
    selected_configs = experiment_configs
    
    # ç®—æ³•é…ç½® - ä¿®å¤ç‰ˆæœ¬
    algorithms = {
        'RL-Chaotic-HHO': (RL_ChaoticHHO_Optimizer, {
            'population_size': 120,
            'max_iterations': 120,
            'pareto_size_limit': 500,
            'diversity_enhancement': True,
            'elite_size': 50,
            'exploration_rate': 0.3
        }),
        'I-NSGA-II': (ImprovedNSGA2_Optimizer, {
            'population_size': 100,
            'max_generations': 100,
            'crossover_rate': 0.9,
            'mutation_rate': 0.1
        }),
        'MOPSO': (MOPSO_Optimizer, {
            'swarm_size': 100,
            'max_iterations': 100,
            'w': 0.4,
            'c1': 2.0,
            'c2': 2.0
        }),
        'MODE': (MODE_Optimizer, {
            'population_size': 100,
            'max_generations': 100,
            'F': 0.7,
            'CR': 0.3
        }),
        'DQN': (DQNAlgorithmWrapper, {
            'max_iterations': 80,
            'target_pareto_size': 25,
            'diversity_control': True
        }),
        'QL-ABC': (QLABC_Optimizer, {
            'population_size': 100,
            'max_iterations': 100
        })
    }
    
    # å­˜å‚¨æ‰€æœ‰ç»“æœ
    all_scale_results = {}
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs('results', exist_ok=True)
    
    # å¯¹æ¯ä¸ªè§„æ¨¡é…ç½®è¿è¡Œå®éªŒ
    for config in selected_configs:
        scale = config['scale']
        print(f"\n{'='*60}")
        print(f"å®éªŒè§„æ¨¡: {scale}")
        print(f"{'='*60}")
        
        # ç”Ÿæˆé—®é¢˜æ•°æ®
        problem_data = generate_heterogeneous_problem_data(config)
        
        # æ‰“å°è§„æ¨¡è¯¦ç»†ä¿¡æ¯
        print_scale_details(config, problem_data)
        
        # å­˜å‚¨è¯¥è§„æ¨¡çš„ç»“æœ
        all_scale_results[scale] = {}
        
        # è¿è¡Œæ¯ä¸ªç®—æ³•
        for algorithm_name, (algorithm_class, algorithm_params) in algorithms.items():
            print(f"\nè¿è¡Œç®—æ³•: {algorithm_name}")
            print("-" * 40)
            
            try:
                result = run_single_experiment(
                    problem_data,
                    algorithm_name, 
                    algorithm_class, 
                    algorithm_params,
                    runs=3
                )
                
                all_scale_results[scale][algorithm_name] = result
                
                # æ‰“å°åŸºæœ¬ç»“æœ
                print(f"  æœ€ä¼˜å®Œå·¥æ—¶é—´: {result['makespan_best']:.2f}")
                print(f"  æœ€ä¼˜æ€»æ‹–æœŸ: {result['tardiness_best']:.2f}")
                print(f"  æœ€å·®å®Œå·¥æ—¶é—´: {result['max_makespan']:.2f}")
                print(f"  æœ€å·®æ€»æ‹–æœŸ: {result['max_tardiness']:.2f}")
                print(f"  è¶…ä½“ç§¯: {result['hypervolume']:.4f}")
                print(f"  IGD: {result['igd']:.4f}")
                print(f"  GD: {result['gd']:.4f}")
                print(f"  é—´è·: {result['spacing']:.4f}")
                print(f"  RAæŒ‡æ ‡: {result['ra']:.4f}")
                print(f"  å¸•ç´¯æ‰˜è§£æ•°é‡: {result['pareto_count']}")
                print(f"  å¹³å‡è¿è¡Œæ—¶é—´: {result['runtime']:.2f}ç§’")
            except Exception as e:
                print(f"  âŒ ç®—æ³• {algorithm_name} è¿è¡Œå¤±è´¥: {str(e)}")
                traceback.print_exc()
                # è®¾ç½®é»˜è®¤å¤±è´¥ç»“æœ
                all_scale_results[scale][algorithm_name] = {
                    'makespan_best': float('inf'),
                    'tardiness_best': float('inf'),
                    'weighted_best': float('inf'),
                    'max_makespan': 0,
                    'max_tardiness': 0,
                    'min_makespan': float('inf'),
                    'min_tardiness': float('inf'),
                    'makespan_mean': 0,
                    'tardiness_mean': 0,
                    'weighted_mean': 0,
                    'runtime': 0,
                    'hypervolume': 0.0,
                    'igd': float('inf'),
                    'gd': float('inf'),
                    'spacing': 0.0,
                    'ra': 0.0,
                    'pareto_count': 0,
                    'pareto_solutions': []
                }
        
        # ç»˜åˆ¶è¯¥è§„æ¨¡çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾ - å¢å¼ºç‰ˆæœ¬
        plot_pareto_comparison(all_scale_results[scale], scale)
        
        # æŒ‰ç…§è®ºæ–‡è¦æ±‚ï¼šå…ˆå½’ä¸€åŒ–ç›®æ ‡å€¼ï¼Œå†è®¡ç®—ç»„åˆå‰æ²¿å’ŒæŒ‡æ ‡
        print(f"\nğŸ”„ æŒ‰ç…§è®ºæ–‡æ ‡å‡†é‡æ–°è®¡ç®—{scale}çš„æ‰€æœ‰æŒ‡æ ‡...")
        
        # 1. å¯¹æ‰€æœ‰ç®—æ³•çš„ç›®æ ‡å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼ˆé¿å…ä¸åŒé‡çº²å½±å“ï¼‰
        normalized_results_for_scale, norm_params = normalize_objectives(all_scale_results[scale])
        print(f"  âœ“ ç›®æ ‡å€¼å½’ä¸€åŒ–å®Œæˆ")
        print(f"    MakespanèŒƒå›´: [{norm_params[0]:.1f}, {norm_params[1]:.1f}]")
        print(f"    TardinessèŒƒå›´: [{norm_params[2]:.1f}, {norm_params[3]:.1f}]")
        
        # 2. åŸºäºå½’ä¸€åŒ–åçš„ç›®æ ‡å€¼è®¡ç®—ç»„åˆå¸•ç´¯æ‰˜å‰æ²¿ï¼ˆçœŸå®å‰æ²¿PF*ï¼‰
        combined_pareto_front = calculate_combined_pareto_front(normalized_results_for_scale)
        print(f"  âœ“ ç»„åˆå¸•ç´¯æ‰˜å‰æ²¿åŒ…å«{len(combined_pareto_front)}ä¸ªå½’ä¸€åŒ–ç‚¹")
        
        # 3. é‡æ–°è®¡ç®—æ¯ä¸ªç®—æ³•çš„æ‰€æœ‰æŒ‡æ ‡ï¼ˆåŸºäºå½’ä¸€åŒ–åçš„ç›®æ ‡å€¼ï¼‰
        for algorithm_name in all_scale_results[scale]:
            if (algorithm_name in normalized_results_for_scale and 
                'normalized_pareto_solutions' in normalized_results_for_scale[algorithm_name] and 
                normalized_results_for_scale[algorithm_name]['normalized_pareto_solutions']):
                
                norm_solutions = normalized_results_for_scale[algorithm_name]['normalized_pareto_solutions']
                original_solutions = all_scale_results[scale][algorithm_name]['pareto_solutions']
                
                # é‡æ–°è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
                new_hypervolume = calculate_hypervolume(original_solutions)  # HVç”¨åŸå§‹å€¼è®¡ç®—ï¼ˆæ›´ç›´è§‚ï¼‰
                new_igd = calculate_igd(norm_solutions, combined_pareto_front)  # IGDç”¨å½’ä¸€åŒ–å€¼å’Œç»„åˆå‰æ²¿
                new_gd = calculate_gd(norm_solutions, combined_pareto_front)   # GDç”¨å½’ä¸€åŒ–å€¼å’Œç»„åˆå‰æ²¿
                new_spacing = calculate_spacing(norm_solutions)               # Spacingç”¨å½’ä¸€åŒ–å€¼
                new_ra = calculate_ra(norm_solutions, combined_pareto_front)   # RAæŒ‡æ ‡ï¼šç®—æ³•è§£é›†ä¸å‚è€ƒå‰æ²¿çš„é‡åˆåº¦
                
                # å¤„ç†æ— æ•ˆå€¼
                if new_igd == float('inf') or np.isnan(new_igd):
                    new_igd = 1.0  # è®¾ä¸ºè¾ƒå¤§å€¼è¡¨ç¤ºæ€§èƒ½å·®
                if new_gd == float('inf') or np.isnan(new_gd):
                    new_gd = 1.0   # è®¾ä¸ºè¾ƒå¤§å€¼è¡¨ç¤ºæ€§èƒ½å·®
                if np.isnan(new_ra):
                    new_ra = 0.0  # è®¾ä¸º0è¡¨ç¤ºæ²¡æœ‰æ‰¾åˆ°çœŸå®å¸•ç´¯æ‰˜è§£
                    
                    # æ›´æ–°ç»“æœ
            all_scale_results[scale][algorithm_name]['hypervolume'] = new_hypervolume
            all_scale_results[scale][algorithm_name]['igd'] = new_igd
            all_scale_results[scale][algorithm_name]['gd'] = new_gd
            all_scale_results[scale][algorithm_name]['spacing'] = new_spacing
            all_scale_results[scale][algorithm_name]['ra'] = new_ra
            
            print(f"  {algorithm_name}: HV={new_hypervolume:.4f}, IGD={new_igd:.4f}, GD={new_gd:.4f}, Spacing={new_spacing:.4f}, RA={new_ra:.4f}")
        
        print(f"\nâœ… {scale} å®éªŒå®Œæˆï¼Œå¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾å·²ä¿å­˜")
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print(f"\n{'='*80}")
    print("ç”Ÿæˆç»¼åˆå¯¹æ¯”æŠ¥å‘Š...")
    print(f"{'='*80}")
    
    generate_specific_scale_report(all_scale_results, selected_configs)
    
    print("\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")
    print("ğŸ“Š ç»“æœæ–‡ä»¶å·²ä¿å­˜åˆ° results/ ç›®å½•")
    print("ğŸ“ˆ å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾å·²ç”Ÿæˆ")

def generate_specific_scale_report(results: Dict, configs: List[Dict]):
    """ç”Ÿæˆç‰¹å®šè§„æ¨¡çš„è¡¨æ ¼æ ¼å¼æŠ¥å‘Š"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"results/ç‰¹å®šè§„æ¨¡ç®—æ³•å¯¹æ¯”æŠ¥å‘Š_{timestamp}.txt"
    
    os.makedirs("results", exist_ok=True)
    
    algorithm_list = ['RL-Chaotic-HHO', 'I-NSGA-II', 'MOPSO', 'MODE', 'DQN', 'QL-ABC']
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¯¹æ¯ä¸ªè§„æ¨¡çš„ç»“æœè¿›è¡Œå½’ä¸€åŒ–å¤„ç†
    normalized_results = {}
    for scale, scale_results in results.items():
        if scale_results:  # ç¡®ä¿æœ‰ç»“æœ
            normalized_results[scale] = normalize_metrics(scale_results)
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("ç‰¹å®šè§„æ¨¡ç®—æ³•å¯¹æ¯”å®éªŒæŠ¥å‘Š\n")
        f.write("=" * 100 + "\n\n")
        
        # å®éªŒé…ç½®ä¿¡æ¯
        f.write("å®éªŒé…ç½®:\n")
        f.write(f"è§„æ¨¡: {len(configs)}ä¸ªè§„æ¨¡é…ç½®\n")
        f.write(f"æ¯ä¸ªé˜¶æ®µæœºå™¨æ•°: (2,3,4,5)èŒƒå›´å†…\n")
        f.write(f"å¹¶è¡Œæœºæ•°é‡: éšè§„æ¨¡å¢å¤§è€Œå¢å¤š\n")
        f.write(f"å¯¹æ¯”ç®—æ³•: {', '.join(algorithm_list)}\n")
        f.write(f"æ¯ä¸ªç®—æ³•è¿è¡Œæ¬¡æ•°: 3æ¬¡\n")
        f.write(f"ç§ç¾¤å¤§å°: 100\n")
        f.write(f"è¿­ä»£æ¬¡æ•°: 100\n")
        f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # è§„æ¨¡è¯¦æƒ…
        f.write("è§„æ¨¡è¯¦æƒ…:\n")
        for config in configs:
            f.write(f"  {config['scale']}: {config['n_jobs']}ä½œä¸š, {config['n_factories']}å·¥å‚, {config['n_stages']}é˜¶æ®µ\n")
            f.write(f"    æœºå™¨é…ç½®: {config['machines_per_stage']}\n")
            f.write(f"    å¼‚æ„æœºå™¨é…ç½®: {config['heterogeneous_machines']}\n")
        f.write("\n")
        
        # å„é¡¹æŒ‡æ ‡å¯¹æ¯”è¡¨
        f.write("å„é¡¹æŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("=" * 100 + "\n\n")
        
        # 1. å®Œå·¥æ—¶é—´å¯¹æ¯”è¡¨
        f.write("1. å®Œå·¥æ—¶é—´(Makespan)å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('makespan_best', 'å¤±è´¥')
                        if value == float('inf') or value == 0:
                            values.append('å¤±è´¥')
                        else:
                            values.append(f"{value:.1f}")
                    else:
                        values.append('å¤±è´¥')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 2. æ€»æ‹–æœŸå¯¹æ¯”è¡¨
        f.write("2. æ€»æ‹–æœŸ(Total Tardiness)å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('tardiness_best', 'å¤±è´¥')
                        if value == float('inf') or (isinstance(value, (int, float)) and value < 0):
                            values.append('å¤±è´¥')
                        else:
                            values.append(f"{value:.1f}")
                    else:
                        values.append('å¤±è´¥')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 3. åŠ æƒç›®æ ‡å¯¹æ¯”è¡¨
        f.write("3. åŠ æƒç›®æ ‡å‡½æ•°å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('weighted_best', 'å¤±è´¥')
                        if value == float('inf') or value == 0:
                            values.append('å¤±è´¥')
                        else:
                            values.append(f"{value:.1f}")
                    else:
                        values.append('å¤±è´¥')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 4. è¶…ä½“ç§¯æŒ‡æ ‡å¯¹æ¯”è¡¨
        f.write("4. è¶…ä½“ç§¯(HV)æŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('hypervolume', 0)
                        if value == 0:
                            values.append('0')
                        else:
                            values.append(f"{value:.4f}")
                    else:
                        values.append('0')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 5. IGDæŒ‡æ ‡å¯¹æ¯”è¡¨
        f.write("5. åä¸–ä»£è·ç¦»(IGD)æŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('igd', float('inf'))
                        if value == float('inf'):
                            values.append('âˆ')
                        else:
                            values.append(f"{value:.2f}")
                    else:
                        values.append('âˆ')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 6. RAæŒ‡æ ‡å¯¹æ¯”è¡¨
        f.write("6. å¸•ç´¯æ‰˜æœ€ä¼˜è§£æ¯”ç‡(RA)æŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('ra', 0.0)
                        if value < 0 or np.isnan(value):
                            values.append('å¤±è´¥')
                        else:
                            values.append(f"{value:.3f}")
                    else:
                        values.append('è¾ƒå·®')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 7. è¿è¡Œæ—¶é—´å¯¹æ¯”è¡¨
        f.write("7. è¿è¡Œæ—¶é—´(ç§’)å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('runtime', 0)
                        values.append(f"{value:.2f}")
                    else:
                        values.append('å¤±è´¥')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 8. å¸•ç´¯æ‰˜è§£æ•°é‡å¯¹æ¯”è¡¨
        f.write("8. å¸•ç´¯æ‰˜è§£æ•°é‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in results:
                scale_results = results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('pareto_count', 0)
                        values.append(f"{value}")
                    else:
                        values.append('0')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 9. å½’ä¸€åŒ–æŒ‡æ ‡å¯¹æ¯”è¡¨
        f.write("9. å½’ä¸€åŒ–æŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("=" * 100 + "\n\n")
        
        # 9.1 å½’ä¸€åŒ–è¶…ä½“ç§¯æŒ‡æ ‡
        f.write("9.1 å½’ä¸€åŒ–è¶…ä½“ç§¯(HV)æŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                scale_results = normalized_results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('norm_hypervolume', 0)
                        values.append(f"{value:.4f}")
                    else:
                        values.append('0.0000')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 9.2 å½’ä¸€åŒ–IGDæŒ‡æ ‡
        f.write("9.2 å½’ä¸€åŒ–IGDæŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                scale_results = normalized_results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('norm_igd', 0)
                        values.append(f"{value:.4f}")
                    else:
                        values.append('0.0000')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 9.3 å½’ä¸€åŒ–GDæŒ‡æ ‡
        f.write("9.3 å½’ä¸€åŒ–GDæŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                scale_results = normalized_results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('norm_gd', 0)
                        values.append(f"{value:.4f}")
                    else:
                        values.append('0.0000')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 9.4 å½’ä¸€åŒ–SpacingæŒ‡æ ‡
        f.write("9.4 å½’ä¸€åŒ–SpacingæŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                scale_results = normalized_results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('norm_spacing', 0)
                        values.append(f"{value:.4f}")
                    else:
                        values.append('0.0000')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # 9.5 å½’ä¸€åŒ–RAæŒ‡æ ‡
        f.write("9.5 å½’ä¸€åŒ–RAæŒ‡æ ‡å¯¹æ¯”è¡¨\n")
        f.write("-" * 100 + "\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        f.write(f"| {'è§„æ¨¡':^13s} | {'RL-Chaotic-HHO':^13s} | {'I-NSGA-II':^11s} | {'MOPSO':^11s} | {'MODE':^11s} | {'DQN':^8s} | {'QL-ABC':^10s} |\n")
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n")
        
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                scale_results = normalized_results[scale]
                
                values = []
                for alg in algorithm_list:
                    if alg in scale_results:
                        value = scale_results[alg].get('norm_ra', 0)
                        values.append(f"{value:.4f}")
                    else:
                        values.append('0.0000')
                
                f.write(f"| {scale:^13s} | {values[0]:^13s} | {values[1]:^11s} | {values[2]:^11s} | {values[3]:^11s} | {values[4]:^8s} | {values[5]:^10s} |\n")
        
        f.write("+" + "-"*15 + "+" + "-"*15 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*13 + "+" + "-"*10 + "+" + "-"*12 + "+\n\n")
        
        # æ€»ç»“
        f.write("å®éªŒæ€»ç»“\n")
        f.write("=" * 100 + "\n")
        f.write(f"æœ¬å®éªŒå¯¹æ¯”äº†6ç§ç®—æ³•åœ¨{len(configs)}ä¸ªç‰¹å®šè§„æ¨¡ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚\n")
        f.write("è§„æ¨¡é…ç½®ï¼š\n")
        for config in configs:
            f.write(f"- {config['scale']}: {config['n_jobs']}ä¸ªä½œä¸šï¼Œ{config['n_stages']}ä¸ªé˜¶æ®µï¼Œ{config['n_factories']}ä¸ªå·¥å‚\n")
        f.write("æ¯ä¸ªé˜¶æ®µçš„æœºå™¨æ•°åœ¨(2,3,4,5)èŒƒå›´å†…ï¼Œå¹¶è¡Œæœºæ•°é‡éšè§„æ¨¡å¢å¤§è€Œå¢å¤šã€‚\n")
        f.write("æ‰€æœ‰ç®—æ³•å‡é‡‡ç”¨ç›¸åŒçš„ç§ç¾¤å¤§å°(100)å’Œè¿­ä»£æ¬¡æ•°(100)ç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚\n")
        f.write("è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬ï¼šHVã€IGDã€GDã€Spacingã€RAäº”ä¸ªæ ¸å¿ƒæŒ‡æ ‡ã€‚\n")
        f.write("æŒ‰ç…§å­¦æœ¯è®ºæ–‡æ ‡å‡†è®¡ç®—æ–¹å¼ï¼š\n")
        f.write("1. æ‰€æœ‰ç®—æ³•çš„ç›®æ ‡å€¼å…ˆè¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼ˆé¿å…ä¸åŒé‡çº²å½±å“ï¼‰\n")
        f.write("2. åŸºäºå½’ä¸€åŒ–ç›®æ ‡å€¼è®¡ç®—ç»„åˆå¸•ç´¯æ‰˜å‰æ²¿ä½œä¸ºçœŸå®å‰æ²¿PF*\n")
        f.write("3. åŸºäºå½’ä¸€åŒ–ç›®æ ‡å€¼å’Œç»„åˆå‰æ²¿è®¡ç®—å„é¡¹æŒ‡æ ‡\n")
        f.write("HVï¼ˆè¶…ä½“ç§¯ï¼‰ï¼šè¶Šå¤§è¶Šå¥½ï¼Œå·²å½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´ã€‚\n")
        f.write("IGDï¼ˆåå‘ä¸–ä»£è·ç¦»ï¼‰ï¼šè¶Šå°è¶Šå¥½ï¼ŒåŸºäºå½’ä¸€åŒ–ç›®æ ‡å€¼è®¡ç®—ï¼Œ0è¡¨ç¤ºæœ€ç†æƒ³ã€‚\n")
        f.write("GDï¼ˆä¸–ä»£è·ç¦»ï¼‰ï¼šè¶Šå°è¶Šå¥½ï¼ŒåŸºäºå½’ä¸€åŒ–ç›®æ ‡å€¼è®¡ç®—ï¼Œ0è¡¨ç¤ºæœ€ç†æƒ³ã€‚\n")
        f.write("Spacingï¼ˆé—´è·ï¼‰ï¼šè¶Šå°è¶Šå¥½ï¼ŒåŸºäºå½’ä¸€åŒ–ç›®æ ‡å€¼è®¡ç®—ï¼Œ0è¡¨ç¤ºæœ€ç†æƒ³ã€‚\n") 
        f.write("RAï¼ˆå¸•ç´¯æ‰˜æœ€ä¼˜è§£æ¯”ç‡ï¼‰ï¼šè¶Šå¤§è¶Šå¥½ï¼Œè¡¨ç¤ºç®—æ³•æ‰¾åˆ°çœŸå®å¸•ç´¯æ‰˜æœ€ä¼˜è§£çš„æ¯”ç‡ï¼Œç†æƒ³èŒƒå›´0-1ã€‚\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    print(f"\nç‰¹å®šè§„æ¨¡ç®—æ³•å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {filename}")
    
    # ç”ŸæˆExcelè¡¨æ ¼ï¼ˆåˆ†ç¦»ç‰ˆæœ¬ï¼‰
    excel_filename = f"results/ç‰¹å®šè§„æ¨¡ç®—æ³•å¯¹æ¯”æŠ¥å‘Š_{timestamp}.xlsx"
    generate_excel_report(results, normalized_results, configs, excel_filename)

def generate_excel_report(results: Dict, normalized_results: Dict, configs: List[Dict], filename: str):
    """ç”Ÿæˆåˆ†ç¦»çš„Excelæ ¼å¼æŠ¥å‘Š - å››ä¸ªæŒ‡æ ‡å’Œä¸¤ä¸ªä¼˜åŒ–ç›®æ ‡åˆ†åˆ«ä¿å­˜"""
    
    algorithm_list = ['RL-Chaotic-HHO', 'I-NSGA-II', 'MOPSO', 'MODE', 'DQN', 'QL-ABC']
    
    # è·å–åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    base_filename = filename.replace('.xlsx', '')
    
    # 1. ç”Ÿæˆä¸¤ä¸ªä¼˜åŒ–ç›®æ ‡çš„Excelæ–‡ä»¶
    objectives_filename = f"{base_filename}_ä¼˜åŒ–ç›®æ ‡.xlsx"
    with pd.ExcelWriter(objectives_filename, engine='openpyxl') as writer:
        
        # å®Œå·¥æ—¶é—´è¡¨
        makespan_data = []
        for config in configs:
            scale = config['scale']
            if scale in results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in results[scale]:
                        row[alg] = results[scale][alg].get('makespan_best', 0)
                    else:
                        row[alg] = 0
                makespan_data.append(row)
        
        makespan_df = pd.DataFrame(makespan_data)
        makespan_df.to_excel(writer, sheet_name='å®Œå·¥æ—¶é—´(Makespan)', index=False)
        
        # æ€»æ‹–æœŸè¡¨
        tardiness_data = []
        for config in configs:
            scale = config['scale']
            if scale in results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in results[scale]:
                        row[alg] = results[scale][alg].get('tardiness_best', 0)
                    else:
                        row[alg] = 0
                tardiness_data.append(row)
        
        tardiness_df = pd.DataFrame(tardiness_data)
        tardiness_df.to_excel(writer, sheet_name='æ€»æ‹–æœŸ(Total_Tardiness)', index=False)
        
        # åŠ æƒç›®æ ‡è¡¨
        weighted_data = []
        for config in configs:
            scale = config['scale']
            if scale in results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in results[scale]:
                        row[alg] = results[scale][alg].get('weighted_best', 0)
                    else:
                        row[alg] = 0
                weighted_data.append(row)
        
        weighted_df = pd.DataFrame(weighted_data)
        weighted_df.to_excel(writer, sheet_name='åŠ æƒç›®æ ‡', index=False)
        
        # å¸•ç´¯æ‰˜è§£æ•°é‡è¡¨
        pareto_count_data = []
        for config in configs:
            scale = config['scale']
            if scale in results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in results[scale]:
                        row[alg] = results[scale][alg].get('pareto_count', 0)
                    else:
                        row[alg] = 0
                pareto_count_data.append(row)
        
        pareto_count_df = pd.DataFrame(pareto_count_data)
        pareto_count_df.to_excel(writer, sheet_name='å¸•ç´¯æ‰˜è§£æ•°é‡', index=False)
    
    print(f"ä¼˜åŒ–ç›®æ ‡ExcelæŠ¥å‘Šå·²ä¿å­˜: {objectives_filename}")
    
    # 2. ç”Ÿæˆå››ä¸ªå½’ä¸€åŒ–æŒ‡æ ‡çš„Excelæ–‡ä»¶
    metrics_filename = f"{base_filename}_å½’ä¸€åŒ–æŒ‡æ ‡.xlsx"
    with pd.ExcelWriter(metrics_filename, engine='openpyxl') as writer:
        
        # å½’ä¸€åŒ–è¶…ä½“ç§¯è¡¨
        hv_data = []
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in normalized_results[scale]:
                        row[alg] = normalized_results[scale][alg].get('norm_hypervolume', 0)
                    else:
                        row[alg] = 0
                hv_data.append(row)
        
        hv_df = pd.DataFrame(hv_data)
        hv_df.to_excel(writer, sheet_name='å½’ä¸€åŒ–è¶…ä½“ç§¯(HV)', index=False)
        
        # å½’ä¸€åŒ–IGDè¡¨
        igd_data = []
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in normalized_results[scale]:
                        row[alg] = normalized_results[scale][alg].get('norm_igd', 0)
                    else:
                        row[alg] = 0
                igd_data.append(row)
        
        igd_df = pd.DataFrame(igd_data)
        igd_df.to_excel(writer, sheet_name='å½’ä¸€åŒ–IGD', index=False)
        
        # å½’ä¸€åŒ–GDè¡¨
        gd_data = []
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in normalized_results[scale]:
                        row[alg] = normalized_results[scale][alg].get('norm_gd', 0)
                    else:
                        row[alg] = 0
                gd_data.append(row)
        
        gd_df = pd.DataFrame(gd_data)
        gd_df.to_excel(writer, sheet_name='å½’ä¸€åŒ–GD', index=False)
        
        # å½’ä¸€åŒ–é—´è·è¡¨
        spacing_data = []
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in normalized_results[scale]:
                        row[alg] = normalized_results[scale][alg].get('norm_spacing', 0)
                    else:
                        row[alg] = 0
                spacing_data.append(row)
        
        spacing_df = pd.DataFrame(spacing_data)
        spacing_df.to_excel(writer, sheet_name='å½’ä¸€åŒ–é—´è·(Spacing)', index=False)
        
        # å½’ä¸€åŒ–RAæŒ‡æ ‡è¡¨
        ra_data = []
        for config in configs:
            scale = config['scale']
            if scale in normalized_results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in normalized_results[scale]:
                        row[alg] = normalized_results[scale][alg].get('norm_ra', 0)
                    else:
                        row[alg] = 0
                ra_data.append(row)
        
        ra_df = pd.DataFrame(ra_data)
        ra_df.to_excel(writer, sheet_name='å½’ä¸€åŒ–RAæŒ‡æ ‡', index=False)
        
        # åŸå§‹æŒ‡æ ‡å€¼è¡¨ï¼ˆä¾›å‚è€ƒï¼‰
        original_data = []
        for config in configs:
            scale = config['scale']
            if scale in results:
                row = {'è§„æ¨¡': scale}
                for alg in algorithm_list:
                    if alg in results[scale]:
                        row[f'{alg}_HV'] = results[scale][alg].get('hypervolume', 0)
                        row[f'{alg}_IGD'] = results[scale][alg].get('igd', float('inf'))
                        row[f'{alg}_GD'] = results[scale][alg].get('gd', float('inf'))
                        row[f'{alg}_Spacing'] = results[scale][alg].get('spacing', 0)
                        row[f'{alg}_RA'] = results[scale][alg].get('ra', 0)
                    else:
                        row[f'{alg}_HV'] = 0
                        row[f'{alg}_IGD'] = float('inf')
                        row[f'{alg}_GD'] = float('inf')
                        row[f'{alg}_Spacing'] = 0
                        row[f'{alg}_RA'] = 0
                original_data.append(row)
        
        original_df = pd.DataFrame(original_data)
        original_df.to_excel(writer, sheet_name='åŸå§‹æŒ‡æ ‡å€¼å‚è€ƒ', index=False)
    
    print(f"å½’ä¸€åŒ–æŒ‡æ ‡ExcelæŠ¥å‘Šå·²ä¿å­˜: {metrics_filename}")
    
    # 3. ç”Ÿæˆç»¼åˆç»Ÿè®¡Excelæ–‡ä»¶
    stats_filename = f"{base_filename}_ç»¼åˆç»Ÿè®¡.xlsx"
    with pd.ExcelWriter(stats_filename, engine='openpyxl') as writer:
        
        # ç®—æ³•æ€§èƒ½æ’åè¡¨
        ranking_data = []
        for alg in algorithm_list:
            alg_stats = {
                'ç®—æ³•': alg,
                'å®Œå·¥æ—¶é—´è·èƒœæ¬¡æ•°': 0,
                'æ€»æ‹–æœŸè·èƒœæ¬¡æ•°': 0,
                'HVè·èƒœæ¬¡æ•°': 0,
                'IGDè·èƒœæ¬¡æ•°': 0,
                'GDè·èƒœæ¬¡æ•°': 0,
                'Spacingè·èƒœæ¬¡æ•°': 0,
                'RAè·èƒœæ¬¡æ•°': 0,
                'å¹³å‡å¸•ç´¯æ‰˜è§£æ•°': 0
            }
            
            total_pareto_count = 0
            valid_scales = 0
            
            for config in configs:
                scale = config['scale']
                if scale in results and scale in normalized_results:
                    valid_scales += 1
                    
                    # ç»Ÿè®¡è·èƒœæ¬¡æ•°
                    if alg in results[scale]:
                        total_pareto_count += results[scale][alg].get('pareto_count', 0)
                        
                        # æ£€æŸ¥æ˜¯å¦åœ¨è¯¥è§„æ¨¡ä¸Šè·èƒœ
                        makespan_best = min(results[scale][a].get('makespan_best', float('inf')) 
                                          for a in algorithm_list if a in results[scale])
                        tardiness_best = min(results[scale][a].get('tardiness_best', float('inf'))
                                           for a in algorithm_list if a in results[scale])
                        
                        if results[scale][alg].get('makespan_best', float('inf')) == makespan_best:
                            alg_stats['å®Œå·¥æ—¶é—´è·èƒœæ¬¡æ•°'] += 1
                        if results[scale][alg].get('tardiness_best', float('inf')) == tardiness_best:
                            alg_stats['æ€»æ‹–æœŸè·èƒœæ¬¡æ•°'] += 1
                    
                    # ç»Ÿè®¡å½’ä¸€åŒ–æŒ‡æ ‡è·èƒœæ¬¡æ•°
                    if alg in normalized_results[scale]:
                        # HV: è¶Šå¤§è¶Šå¥½ï¼Œæ‰¾æœ€å¤§å€¼
                        hv_best = max(normalized_results[scale][a].get('norm_hypervolume', 0)
                                    for a in algorithm_list if a in normalized_results[scale])
                        
                        # IGD, GD, Spacing: è¶Šå°è¶Šå¥½ï¼Œæ‰¾æœ€å°å€¼ï¼›RA: è¶Šå¤§è¶Šå¥½ï¼Œæ‰¾æœ€å¤§å€¼
                        igd_best = min(normalized_results[scale][a].get('norm_igd', float('inf'))
                                     for a in algorithm_list if a in normalized_results[scale])
                        gd_best = min(normalized_results[scale][a].get('norm_gd', float('inf'))
                                    for a in algorithm_list if a in normalized_results[scale])
                        spacing_best = min(normalized_results[scale][a].get('norm_spacing', float('inf'))
                                         for a in algorithm_list if a in normalized_results[scale])
                        ra_best = max(normalized_results[scale][a].get('norm_ra', 0.0)
                                        for a in algorithm_list if a in normalized_results[scale])
                        
                        if normalized_results[scale][alg].get('norm_hypervolume', 0) == hv_best:
                            alg_stats['HVè·èƒœæ¬¡æ•°'] += 1
                        if normalized_results[scale][alg].get('norm_igd', float('inf')) == igd_best:
                            alg_stats['IGDè·èƒœæ¬¡æ•°'] += 1
                        if normalized_results[scale][alg].get('norm_gd', float('inf')) == gd_best:
                            alg_stats['GDè·èƒœæ¬¡æ•°'] += 1
                        if normalized_results[scale][alg].get('norm_spacing', float('inf')) == spacing_best:
                            alg_stats['Spacingè·èƒœæ¬¡æ•°'] += 1
                        if normalized_results[scale][alg].get('norm_ra', 0.0) == ra_best:
                            alg_stats['RAè·èƒœæ¬¡æ•°'] += 1
            
            if valid_scales > 0:
                alg_stats['å¹³å‡å¸•ç´¯æ‰˜è§£æ•°'] = total_pareto_count / valid_scales
            
            ranking_data.append(alg_stats)
        
        ranking_df = pd.DataFrame(ranking_data)
        ranking_df.to_excel(writer, sheet_name='ç®—æ³•æ€§èƒ½æ’å', index=False)
        
        # è§„æ¨¡éš¾åº¦åˆ†æè¡¨
        difficulty_data = []
        for config in configs:
            scale = config['scale']
            if scale in results:
                difficulty_stats = {
                    'è§„æ¨¡': scale,
                    'å¹³å‡å®Œå·¥æ—¶é—´': 0,
                    'å¹³å‡æ€»æ‹–æœŸ': 0,
                    'å¹³å‡å¸•ç´¯æ‰˜è§£æ•°': 0,
                    'æœ€ä½³å®Œå·¥æ—¶é—´': float('inf'),
                    'æœ€ä½³æ€»æ‹–æœŸ': float('inf'),
                    'å®Œå·¥æ—¶é—´æ ‡å‡†å·®': 0,
                    'æ€»æ‹–æœŸæ ‡å‡†å·®': 0
                }
                
                makespans = []
                tardiness_vals = []
                pareto_counts = []
                
                for alg in algorithm_list:
                    if alg in results[scale]:
                        makespan = results[scale][alg].get('makespan_best', 0)
                        tardiness = results[scale][alg].get('tardiness_best', 0)
                        pareto_count = results[scale][alg].get('pareto_count', 0)
                        
                        if makespan > 0:
                            makespans.append(makespan)
                            tardiness_vals.append(tardiness)
                            pareto_counts.append(pareto_count)
                
                if makespans:
                    difficulty_stats['å¹³å‡å®Œå·¥æ—¶é—´'] = np.mean(makespans)
                    difficulty_stats['å¹³å‡æ€»æ‹–æœŸ'] = np.mean(tardiness_vals)
                    difficulty_stats['å¹³å‡å¸•ç´¯æ‰˜è§£æ•°'] = np.mean(pareto_counts)
                    difficulty_stats['æœ€ä½³å®Œå·¥æ—¶é—´'] = min(makespans)
                    difficulty_stats['æœ€ä½³æ€»æ‹–æœŸ'] = min(tardiness_vals)
                    difficulty_stats['å®Œå·¥æ—¶é—´æ ‡å‡†å·®'] = np.std(makespans)
                    difficulty_stats['æ€»æ‹–æœŸæ ‡å‡†å·®'] = np.std(tardiness_vals)
                
                difficulty_data.append(difficulty_stats)
        
        difficulty_df = pd.DataFrame(difficulty_data)
        difficulty_df.to_excel(writer, sheet_name='è§„æ¨¡éš¾åº¦åˆ†æ', index=False)
    
    print(f"ç»¼åˆç»Ÿè®¡ExcelæŠ¥å‘Šå·²ä¿å­˜: {stats_filename}")
    
    print(f"\nâœ… æ‰€æœ‰ExcelæŠ¥å‘Šç”Ÿæˆå®Œæˆ:")
    print(f"   1. ä¼˜åŒ–ç›®æ ‡: {objectives_filename}")
    print(f"   2. å½’ä¸€åŒ–æŒ‡æ ‡: {metrics_filename}")
    print(f"   3. ç»¼åˆç»Ÿè®¡: {stats_filename}")

if __name__ == "__main__":
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    os.makedirs("results", exist_ok=True)
    
    # è¿è¡Œç‰¹å®šè§„æ¨¡å®éªŒ
    run_specific_scale_experiments()