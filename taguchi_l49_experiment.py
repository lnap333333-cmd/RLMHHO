#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RL-Chaotic-HHOç®—æ³•L49ç”°å£æ­£äº¤å®éªŒè®¾è®¡
é’ˆå¯¹100Ã—5Ã—3è§„æ¨¡ï¼Œæ€»æœºå™¨æ•°40çš„MO-DHFSPé—®é¢˜
è¯„ä»·æŒ‡æ ‡ï¼šè¶…ä½“ç§¯:IGD:GD = 5:3:2
"""

import numpy as np
import pandas as pd
import time
import json
import pickle
from datetime import datetime
from typing import List, Dict, Tuple, Any
import logging
import os

# å¯¼å…¥ç®—æ³•å’Œé—®é¢˜å®šä¹‰
from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.nsga2 import NSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from utils.data_generator import DataGenerator
from utils.performance_metrics import PerformanceEvaluator

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('taguchi_l49_experiment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TaguchiL49Experiment:
    """L49ç”°å£æ­£äº¤å®éªŒä¸»æ§åˆ¶ç±»"""
    
    def __init__(self):
        self.problem_config = {
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'total_machines': 40,
            'processing_time_range': (1, 10),
            'due_date_tightness': 1.5,
            'random_seed': 2025
        }
        
        # L49æ­£äº¤è¡¨å‚æ•°é…ç½®
        self.factor_levels = self._initialize_factor_levels()
        self.l49_design = self._generate_l49_design()
        
        # å®éªŒæ§åˆ¶å‚æ•°
        self.runs_per_experiment = 10  # æ¯ç»„å®éªŒé‡å¤10æ¬¡
        self.max_iterations = 50     # ç®—æ³•è¿­ä»£æ¬¡æ•°
        
        # ç»“æœå­˜å‚¨
        self.results_dir = f"taguchi_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.results_dir, exist_ok=True)
        
        # æ€§èƒ½è¯„ä¼°å™¨
        self.metrics_evaluator = MetricsEvaluator()
        
    def _initialize_factor_levels(self) -> Dict:
        """åˆå§‹åŒ–4å› å­7æ°´å¹³å‚æ•°"""
        return {
            'A_learning_rate': {
                1: 0.00005, 2: 0.0001, 3: 0.0002, 4: 0.0005,
                5: 0.001, 6: 0.002, 7: 0.005
            },
            'B_epsilon_decay': {
                1: 0.988, 2: 0.990, 3: 0.993, 4: 0.995,
                5: 0.997, 6: 0.999, 7: 0.9995
            },
            'C_group_ratios': {
                1: [0.70, 0.15, 0.10, 0.05],  # è¶…çº§æ¢ç´¢ä¸»å¯¼
                2: [0.60, 0.20, 0.15, 0.05],  # æç«¯æ¢ç´¢ä¸»å¯¼
                3: [0.50, 0.30, 0.15, 0.05],  # æ¢ç´¢ä¸»å¯¼
                4: [0.45, 0.25, 0.20, 0.10],  # åŸºå‡†å¹³è¡¡
                5: [0.35, 0.40, 0.20, 0.05],  # å¼€å‘ä¸»å¯¼
                6: [0.25, 0.45, 0.20, 0.10],  # æç«¯å¼€å‘ä¸»å¯¼
                7: [0.20, 0.50, 0.20, 0.10]   # è¶…çº§å¼€å‘ä¸»å¯¼
            },
            'D_gamma': {
                1: 0.80, 2: 0.85, 3: 0.90, 4: 0.95,
                5: 0.98, 6: 0.99, 7: 0.995
            }
        }
    
    def _generate_l49_design(self) -> List[Dict]:
        """ç”ŸæˆL49(7^4)æ­£äº¤è¡¨è®¾è®¡"""
        l49_experiments = [
            # å®éªŒ1-7: Aæ°´å¹³1çš„ç»„åˆ
            {'exp_id': 1,  'A': 1, 'B': 1, 'C': 1, 'D': 1},
            {'exp_id': 2,  'A': 1, 'B': 2, 'C': 2, 'D': 2},
            {'exp_id': 3,  'A': 1, 'B': 3, 'C': 3, 'D': 3},
            {'exp_id': 4,  'A': 1, 'B': 4, 'C': 4, 'D': 4},
            {'exp_id': 5,  'A': 1, 'B': 5, 'C': 5, 'D': 5},
            {'exp_id': 6,  'A': 1, 'B': 6, 'C': 6, 'D': 6},
            {'exp_id': 7,  'A': 1, 'B': 7, 'C': 7, 'D': 7},
            
            # å®éªŒ8-14: Aæ°´å¹³2çš„ç»„åˆ
            {'exp_id': 8,  'A': 2, 'B': 1, 'C': 2, 'D': 3},
            {'exp_id': 9,  'A': 2, 'B': 2, 'C': 3, 'D': 4},
            {'exp_id': 10, 'A': 2, 'B': 3, 'C': 4, 'D': 5},
            {'exp_id': 11, 'A': 2, 'B': 4, 'C': 5, 'D': 6},
            {'exp_id': 12, 'A': 2, 'B': 5, 'C': 6, 'D': 7},
            {'exp_id': 13, 'A': 2, 'B': 6, 'C': 7, 'D': 1},
            {'exp_id': 14, 'A': 2, 'B': 7, 'C': 1, 'D': 2},
            
            # å®éªŒ15-21: Aæ°´å¹³3çš„ç»„åˆ
            {'exp_id': 15, 'A': 3, 'B': 1, 'C': 3, 'D': 5},
            {'exp_id': 16, 'A': 3, 'B': 2, 'C': 4, 'D': 6},
            {'exp_id': 17, 'A': 3, 'B': 3, 'C': 5, 'D': 7},
            {'exp_id': 18, 'A': 3, 'B': 4, 'C': 6, 'D': 1},
            {'exp_id': 19, 'A': 3, 'B': 5, 'C': 7, 'D': 2},
            {'exp_id': 20, 'A': 3, 'B': 6, 'C': 1, 'D': 3},
            {'exp_id': 21, 'A': 3, 'B': 7, 'C': 2, 'D': 4},
            
            # å®éªŒ22-28: Aæ°´å¹³4çš„ç»„åˆ (åŸºå‡†å­¦ä¹ ç‡)
            {'exp_id': 22, 'A': 4, 'B': 1, 'C': 4, 'D': 7},
            {'exp_id': 23, 'A': 4, 'B': 2, 'C': 5, 'D': 1},
            {'exp_id': 24, 'A': 4, 'B': 3, 'C': 6, 'D': 2},
            {'exp_id': 25, 'A': 4, 'B': 4, 'C': 7, 'D': 3},
            {'exp_id': 26, 'A': 4, 'B': 5, 'C': 1, 'D': 4},
            {'exp_id': 27, 'A': 4, 'B': 6, 'C': 2, 'D': 5},
            {'exp_id': 28, 'A': 4, 'B': 7, 'C': 3, 'D': 6},
            
            # å®éªŒ29-35: Aæ°´å¹³5çš„ç»„åˆ
            {'exp_id': 29, 'A': 5, 'B': 1, 'C': 5, 'D': 2},
            {'exp_id': 30, 'A': 5, 'B': 2, 'C': 6, 'D': 3},
            {'exp_id': 31, 'A': 5, 'B': 3, 'C': 7, 'D': 4},
            {'exp_id': 32, 'A': 5, 'B': 4, 'C': 1, 'D': 5},
            {'exp_id': 33, 'A': 5, 'B': 5, 'C': 2, 'D': 6},
            {'exp_id': 34, 'A': 5, 'B': 6, 'C': 3, 'D': 7},
            {'exp_id': 35, 'A': 5, 'B': 7, 'C': 4, 'D': 1},
            
            # å®éªŒ36-42: Aæ°´å¹³6çš„ç»„åˆ
            {'exp_id': 36, 'A': 6, 'B': 1, 'C': 6, 'D': 4},
            {'exp_id': 37, 'A': 6, 'B': 2, 'C': 7, 'D': 5},
            {'exp_id': 38, 'A': 6, 'B': 3, 'C': 1, 'D': 6},
            {'exp_id': 39, 'A': 6, 'B': 4, 'C': 2, 'D': 7},
            {'exp_id': 40, 'A': 6, 'B': 5, 'C': 3, 'D': 1},
            {'exp_id': 41, 'A': 6, 'B': 6, 'C': 4, 'D': 2},
            {'exp_id': 42, 'A': 6, 'B': 7, 'C': 5, 'D': 3},
            
            # å®éªŒ43-49: Aæ°´å¹³7çš„ç»„åˆ
            {'exp_id': 43, 'A': 7, 'B': 1, 'C': 7, 'D': 6},
            {'exp_id': 44, 'A': 7, 'B': 2, 'C': 1, 'D': 7},
            {'exp_id': 45, 'A': 7, 'B': 3, 'C': 2, 'D': 1},
            {'exp_id': 46, 'A': 7, 'B': 4, 'C': 3, 'D': 2},
            {'exp_id': 47, 'A': 7, 'B': 5, 'C': 4, 'D': 3},
            {'exp_id': 48, 'A': 7, 'B': 6, 'C': 5, 'D': 4},
            {'exp_id': 49, 'A': 7, 'B': 7, 'C': 6, 'D': 5}
        ]
        
        return l49_experiments
    
    def generate_problem_instance(self) -> MO_DHFSP_Problem:
        """ç”Ÿæˆæ ‡å‡†åŒ–çš„é—®é¢˜å®ä¾‹"""
        logger.info("ç”Ÿæˆ100Ã—5Ã—3è§„æ¨¡é—®é¢˜å®ä¾‹ï¼Œæ€»æœºå™¨æ•°40")
        
        generator = DataGenerator(seed=self.problem_config['random_seed'])
        
        # åˆ†é…å„å·¥å‚å„é˜¶æ®µçš„æœºå™¨æ•°é‡ï¼Œç¡®ä¿æ€»æ•°ä¸º40
        machines_config = self._distribute_machines()
        
        problem_data = generator.generate_problem(
            n_jobs=self.problem_config['n_jobs'],
            n_factories=self.problem_config['n_factories'],
            n_stages=self.problem_config['n_stages'],
            machines_per_stage=machines_config[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥å‚çš„é…ç½®ä½œä¸ºåŸºå‡†
            processing_time_range=self.problem_config['processing_time_range'],
            due_date_tightness=self.problem_config['due_date_tightness']
        )
        
        # æ·»åŠ å¤šå·¥å‚æœºå™¨é…ç½®ä¿¡æ¯ï¼ˆä½¿ç”¨æ•´æ•°é”®ï¼‰
        problem_data['factory_machines'] = {
            i: machines_config[i] for i in range(len(machines_config))
        }
        
        problem = MO_DHFSP_Problem(problem_data)
        
        # ä¿å­˜é—®é¢˜å®ä¾‹
        with open(f"{self.results_dir}/problem_instance.pkl", 'wb') as f:
            pickle.dump(problem, f)
        
        logger.info(f"é—®é¢˜å®ä¾‹å·²ä¿å­˜ï¼Œæ€»æœºå™¨æ•°: {sum(sum(stage) for stage in machines_config)}")
        return problem
    
    def _distribute_machines(self) -> List[List[int]]:
        """åˆ†é…40å°æœºå™¨åˆ°5ä¸ªå·¥å‚3ä¸ªé˜¶æ®µ"""
        # ç¡®ä¿å¼‚æ„é…ç½®ï¼Œæ¯ä¸ªå·¥å‚æ¯ä¸ªé˜¶æ®µè‡³å°‘1å°æœºå™¨
        machines_config = [
            [3, 2, 2],  # å·¥å‚1: 7å°æœºå™¨
            [3, 3, 2],  # å·¥å‚2: 8å°æœºå™¨  
            [2, 3, 3],  # å·¥å‚3: 8å°æœºå™¨
            [3, 2, 3],  # å·¥å‚4: 8å°æœºå™¨
            [3, 3, 3]   # å·¥å‚5: 9å°æœºå™¨
        ]
        # æ€»è®¡: 7+8+8+8+9 = 40å°æœºå™¨
        
        return machines_config
    
    def run_single_experiment(self, exp_config: Dict, run_id: int, problem: MO_DHFSP_Problem) -> Dict:
        """è¿è¡Œå•æ¬¡å®éªŒ"""
        exp_id = exp_config['exp_id']
        
        # è·å–å‚æ•°é…ç½®
        params = self._get_experiment_parameters(exp_config)
        
        logger.info(f"å®éªŒ{exp_id}-è¿è¡Œ{run_id}: LR={params['learning_rate']:.5f}, "
                   f"Decay={params['epsilon_decay']:.4f}, "
                   f"Groups={params['group_ratios']}, "
                   f"Gamma={params['gamma']:.3f}")
        
        # åˆ›å»ºç®—æ³•å®ä¾‹
        optimizer = RL_ChaoticHHO_Optimizer(
            problem=problem,
            max_iterations=self.max_iterations,
            **params
        )
        
        # è¿è¡Œä¼˜åŒ–
        start_time = time.time()
        try:
            pareto_solutions, convergence_data = optimizer.optimize()
            runtime = time.time() - start_time
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            metrics = self.metrics_evaluator.evaluate_performance(
                pareto_solutions, problem, runtime
            )
            
            result = {
                'exp_id': exp_id,
                'run_id': run_id,
                'parameters': params,
                'pareto_solutions': pareto_solutions,
                'metrics': metrics,
                'convergence_data': convergence_data,
                'runtime': runtime,
                'success': True
            }
            
            logger.info(f"å®éªŒ{exp_id}-è¿è¡Œ{run_id}å®Œæˆ: HV={metrics['hypervolume']:.4f}, "
                       f"IGD={metrics['igd']:.4f}, GD={metrics['gd']:.4f}, "
                       f"æ—¶é—´={runtime:.2f}s")
            
        except Exception as e:
            logger.error(f"å®éªŒ{exp_id}-è¿è¡Œ{run_id}å¤±è´¥: {str(e)}")
            result = {
                'exp_id': exp_id,
                'run_id': run_id,
                'parameters': params,
                'error': str(e),
                'success': False
            }
        
        return result
    
    def _get_experiment_parameters(self, exp_config: Dict) -> Dict:
        """æ ¹æ®å®éªŒé…ç½®è·å–å…·ä½“å‚æ•°å€¼"""
        params = {
            'learning_rate': self.factor_levels['A_learning_rate'][exp_config['A']],
            'epsilon_decay': self.factor_levels['B_epsilon_decay'][exp_config['B']],
            'group_ratios': self.factor_levels['C_group_ratios'][exp_config['C']],
            'gamma': self.factor_levels['D_gamma'][exp_config['D']],
            # å›ºå®šå‚æ•°
            'population_size_override': 50,  # å¼ºåˆ¶è®¾ç½®ç§ç¾¤å¤§å°
            'epsilon': 0.9,
            'epsilon_min': 0.01
        }
        return params
    
    def run_experiment_group(self, exp_config: Dict, problem: MO_DHFSP_Problem) -> Dict:
        """è¿è¡Œå•ç»„å®éªŒï¼ˆ10æ¬¡é‡å¤ï¼‰"""
        exp_id = exp_config['exp_id']
        logger.info(f"å¼€å§‹å®éªŒç»„{exp_id} ({exp_id}/49)")
        
        group_results = []
        
        # è¿è¡Œ10æ¬¡é‡å¤å®éªŒ
        for run_id in range(1, self.runs_per_experiment + 1):
            result = self.run_single_experiment(exp_config, run_id, problem)
            group_results.append(result)
            
            # ä¿å­˜å•æ¬¡å®éªŒç»“æœ
            with open(f"{self.results_dir}/exp_{exp_id:02d}_run_{run_id}.json", 'w') as f:
                json.dump(result, f, indent=2, default=str)
        
        # ç»Ÿè®¡åˆ†æ
        statistics = self._analyze_group_results(group_results)
        
        group_summary = {
            'exp_id': exp_id,
            'exp_config': exp_config,
            'individual_results': group_results,
            'statistics': statistics,
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜ç»„æ±‡æ€»ç»“æœ
        with open(f"{self.results_dir}/exp_{exp_id:02d}_summary.json", 'w') as f:
            json.dump(group_summary, f, indent=2, default=str)
        
        logger.info(f"å®éªŒç»„{exp_id}å®Œæˆ: å¹³å‡HV={statistics['hv_mean']:.4f}, "
                   f"å¹³å‡IGD={statistics['igd_mean']:.4f}, "
                   f"å¹³å‡GD={statistics['gd_mean']:.4f}, "
                   f"ç»¼åˆå¾—åˆ†={statistics['comprehensive_mean']:.4f}, "
                   f"SNR={statistics['snr_value']:.2f}")
        
        return group_summary
    
    def _analyze_group_results(self, group_results: List[Dict]) -> Dict:
        """åˆ†æå®éªŒç»„ç»“æœ"""
        successful_results = [r for r in group_results if r.get('success', False)]
        
        if not successful_results:
            return {'error': 'No successful runs', 'snr_value': 0.0}
        
        # æå–æ€§èƒ½æŒ‡æ ‡
        hv_values = [r['metrics']['hypervolume'] for r in successful_results]
        igd_values = [r['metrics']['igd'] for r in successful_results]
        gd_values = [r['metrics']['gd'] for r in successful_results]
        
        # è®¡ç®—ç»¼åˆå¾—åˆ† (5:3:2æƒé‡)
        comprehensive_scores = []
        for hv, igd, gd in zip(hv_values, igd_values, gd_values):
            score = self.metrics_evaluator.comprehensive_evaluation_5_3_2(hv, igd, gd)
            comprehensive_scores.append(score)
        
        # è®¡ç®—ä¿¡å™ªæ¯”
        snr = self.metrics_evaluator.calculate_snr_comprehensive(comprehensive_scores)
        
        statistics = {
            'n_successful_runs': len(successful_results),
            'hv_mean': np.mean(hv_values),
            'hv_std': np.std(hv_values),
            'igd_mean': np.mean(igd_values),
            'igd_std': np.std(igd_values),
            'gd_mean': np.mean(gd_values),
            'gd_std': np.std(gd_values),
            'comprehensive_mean': np.mean(comprehensive_scores),
            'comprehensive_std': np.std(comprehensive_scores),
            'snr_value': snr,
            'runtime_mean': np.mean([r['runtime'] for r in successful_results])
        }
        
        return statistics
    
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰49ç»„å®éªŒ"""
        logger.info("å¼€å§‹L49ç”°å£æ­£äº¤å®éªŒ")
        
        # ç”Ÿæˆé—®é¢˜å®ä¾‹
        problem = self.generate_problem_instance()
        
        # ç”Ÿæˆå‚è€ƒå‰æ²¿
        logger.info("ç”Ÿæˆå‚è€ƒå‰æ²¿...")
        self.metrics_evaluator.generate_reference_front(problem)
        
        # è¿è¡Œæ‰€æœ‰å®éªŒç»„
        all_results = []
        total_experiments = len(self.l49_design)
        
        for i, exp_config in enumerate(self.l49_design):
            logger.info(f"è¿›åº¦: {i+1}/{total_experiments}")
            
            try:
                group_result = self.run_experiment_group(exp_config, problem)
                all_results.append(group_result)
                
                # æ¯5ç»„å®éªŒä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
                if (i + 1) % 5 == 0:
                    self._save_intermediate_results(all_results[:i+1])
                    
            except Exception as e:
                logger.error(f"å®éªŒç»„{exp_config['exp_id']}è¿è¡Œå¤±è´¥: {str(e)}")
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_final_results(all_results)
        
        # è¿›è¡Œç”°å£åˆ†æ
        logger.info("å¼€å§‹ç”°å£åˆ†æ...")
        taguchi_results = self._perform_taguchi_analysis(all_results)
        
        logger.info("L49ç”°å£å®éªŒå®Œæˆ!")
        return all_results, taguchi_results
    
    def _save_intermediate_results(self, results: List[Dict]):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        with open(f"{self.results_dir}/intermediate_results.json", 'w') as f:
            json.dump(results, f, indent=2, default=str)
    
    def _save_final_results(self, results: List[Dict]):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        with open(f"{self.results_dir}/final_results.json", 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        # ä¿å­˜ä¸ºExcelæ ¼å¼
        self._export_to_excel(results)
    
    def _export_to_excel(self, results: List[Dict]):
        """å¯¼å‡ºç»“æœåˆ°Excel"""
        # åˆ›å»ºæ±‡æ€»æ•°æ®æ¡†
        summary_data = []
        for result in results:
            if 'statistics' in result:
                row = {
                    'Exp_ID': result['exp_id'],
                    'A_LearningRate': self.factor_levels['A_learning_rate'][result['exp_config']['A']],
                    'B_EpsilonDecay': self.factor_levels['B_epsilon_decay'][result['exp_config']['B']],
                    'C_GroupRatios': str(self.factor_levels['C_group_ratios'][result['exp_config']['C']]),
                    'D_Gamma': self.factor_levels['D_gamma'][result['exp_config']['D']],
                    'HV_Mean': result['statistics']['hv_mean'],
                    'HV_Std': result['statistics']['hv_std'],
                    'IGD_Mean': result['statistics']['igd_mean'],
                    'IGD_Std': result['statistics']['igd_std'],
                    'GD_Mean': result['statistics']['gd_mean'],
                    'GD_Std': result['statistics']['gd_std'],
                    'Comprehensive_Mean': result['statistics']['comprehensive_mean'],
                    'Comprehensive_Std': result['statistics']['comprehensive_std'],
                    'SNR_Value': result['statistics']['snr_value'],
                    'Runtime_Mean': result['statistics']['runtime_mean'],
                    'Successful_Runs': result['statistics']['n_successful_runs']
                }
                summary_data.append(row)
        
        df = pd.DataFrame(summary_data)
        df.to_excel(f"{self.results_dir}/l49_results_summary.xlsx", index=False)
        logger.info("ç»“æœå·²å¯¼å‡ºåˆ°Excelæ–‡ä»¶")
    
    def _perform_taguchi_analysis(self, results: List[Dict]) -> Dict:
        """æ‰§è¡Œç”°å£åˆ†æ"""
        analyzer = TaguchiAnalyzer(self.factor_levels)
        taguchi_results = analyzer.analyze(results)
        
        # ä¿å­˜ç”°å£åˆ†æç»“æœ
        with open(f"{self.results_dir}/taguchi_analysis.json", 'w') as f:
            json.dump(taguchi_results, f, indent=2, default=str)
        
        return taguchi_results


class MetricsEvaluator:
    """æ€§èƒ½æŒ‡æ ‡è¯„ä¼°å™¨"""
    
    def __init__(self):
        self.reference_front = None
        self.reference_point = None
    
    def generate_reference_front(self, problem: MO_DHFSP_Problem):
        """ç”Ÿæˆå‚è€ƒå‰æ²¿"""
        logger.info("ä½¿ç”¨ç»å…¸ç®—æ³•ç”Ÿæˆå‚è€ƒå‰æ²¿...")
        
        all_solutions = []
        algorithms = ['NSGA2', 'MOEAD', 'MOPSO']
        
        for alg_name in algorithms:
            logger.info(f"è¿è¡Œ{alg_name}ç®—æ³•...")
            try:
                if alg_name == 'NSGA2':
                    optimizer = NSGA2_Optimizer(
                        problem, population_size=50, max_generations=50
                    )
                elif alg_name == 'MOEAD':
                    optimizer = MOEAD_Optimizer(
                        problem, population_size=50, max_generations=50
                    )
                elif alg_name == 'MOPSO':
                    optimizer = MOPSO_Optimizer(
                        problem, swarm_size=50, max_iterations=50
                    )
                
                solutions, _ = optimizer.optimize()
                all_solutions.extend(solutions)
                logger.info(f"{alg_name}å®Œæˆï¼Œè·å¾—{len(solutions)}ä¸ªè§£")
                
            except Exception as e:
                logger.warning(f"{alg_name}è¿è¡Œå¤±è´¥: {str(e)}")
        
        # æå–éæ”¯é…è§£ä½œä¸ºå‚è€ƒå‰æ²¿
        self.reference_front = self._extract_pareto_front(all_solutions)
        
        # è®¾ç½®å‚è€ƒç‚¹ï¼ˆæ¯”æœ€å·®è§£ç¨å·®ä¸€äº›ï¼‰
        if self.reference_front:
            max_makespan = max(sol.makespan for sol in self.reference_front)
            max_tardiness = max(sol.total_tardiness for sol in self.reference_front)
            self.reference_point = [max_makespan * 1.1, max_tardiness * 1.1]
        else:
            self.reference_point = [1000.0, 1000.0]  # é»˜è®¤å‚è€ƒç‚¹
        
        logger.info(f"å‚è€ƒå‰æ²¿ç”Ÿæˆå®Œæˆï¼š{len(self.reference_front)}ä¸ªè§£")
        logger.info(f"å‚è€ƒç‚¹è®¾ç½®ä¸ºï¼š{self.reference_point}")
    
    def _extract_pareto_front(self, solutions: List) -> List:
        """æå–å¸•ç´¯æ‰˜å‰æ²¿"""
        if not solutions:
            return []
        
        pareto_front = []
        for sol in solutions:
            is_dominated = False
            for other_sol in solutions:
                if (other_sol.makespan <= sol.makespan and 
                    other_sol.total_tardiness <= sol.total_tardiness and
                    (other_sol.makespan < sol.makespan or other_sol.total_tardiness < sol.total_tardiness)):
                    is_dominated = True
                    break
            
            if not is_dominated:
                pareto_front.append(sol)
        
        return pareto_front
    
    def evaluate_performance(self, pareto_solutions: List, problem: MO_DHFSP_Problem, runtime: float) -> Dict:
        """è¯„ä¼°ç®—æ³•æ€§èƒ½"""
        if not pareto_solutions:
            return {
                'hypervolume': 0.0,
                'igd': float('inf'),
                'gd': float('inf'),
                'pareto_size': 0,
                'runtime': runtime
            }
        
        # è®¡ç®—è¶…ä½“ç§¯
        hv = self._calculate_hypervolume(pareto_solutions)
        
        # è®¡ç®—IGDå’ŒGD
        igd = self._calculate_igd(pareto_solutions)
        gd = self._calculate_gd(pareto_solutions)
        
        return {
            'hypervolume': hv,
            'igd': igd,
            'gd': gd,
            'pareto_size': len(pareto_solutions),
            'runtime': runtime
        }
    
    def _calculate_hypervolume(self, pareto_solutions: List) -> float:
        """è®¡ç®—è¶…ä½“ç§¯æŒ‡æ ‡"""
        if not pareto_solutions or not self.reference_point:
            return 0.0
        
        # æ ‡å‡†åŒ–ç›®æ ‡å€¼
        normalized_solutions = []
        for sol in pareto_solutions:
            norm_makespan = sol.makespan / self.reference_point[0]
            norm_tardiness = sol.total_tardiness / self.reference_point[1]
            normalized_solutions.append([norm_makespan, norm_tardiness])
        
        # ç®€åŒ–çš„è¶…ä½“ç§¯è®¡ç®—ï¼ˆ2ç»´æƒ…å†µï¼‰
        ref_point = [1.1, 1.1]
        
        # æ’åºå¹¶è®¡ç®—
        normalized_solutions.sort(key=lambda x: x[0])
        
        hv = 0.0
        prev_x = 0.0
        
        for point in normalized_solutions:
            if point[0] < ref_point[0] and point[1] < ref_point[1]:
                width = min(point[0], ref_point[0]) - prev_x
                height = ref_point[1] - point[1]
                hv += width * height
                prev_x = min(point[0], ref_point[0])
        
        return max(0.0, min(hv, ref_point[0] * ref_point[1]))
    
    def _calculate_igd(self, pareto_solutions: List) -> float:
        """è®¡ç®—åå‘ä¸–ä»£è·ç¦»"""
        if not self.reference_front or not pareto_solutions:
            return float('inf')
        
        distances = []
        for ref_sol in self.reference_front:
            min_distance = min([
                self._euclidean_distance(
                    [ref_sol.makespan, ref_sol.total_tardiness],
                    [sol.makespan, sol.total_tardiness]
                ) for sol in pareto_solutions
            ])
            distances.append(min_distance)
        
        return np.mean(distances) if distances else float('inf')
    
    def _calculate_gd(self, pareto_solutions: List) -> float:
        """è®¡ç®—ä¸–ä»£è·ç¦»"""
        if not self.reference_front or not pareto_solutions:
            return float('inf')
        
        distances = []
        for sol in pareto_solutions:
            min_distance = min([
                self._euclidean_distance(
                    [sol.makespan, sol.total_tardiness],
                    [ref_sol.makespan, ref_sol.total_tardiness]
                ) for ref_sol in self.reference_front
            ])
            distances.append(min_distance)
        
        return np.mean(distances) if distances else float('inf')
    
    def _euclidean_distance(self, point1: List[float], point2: List[float]) -> float:
        """è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»"""
        return np.sqrt(sum((a - b) ** 2 for a, b in zip(point1, point2)))
    
    def comprehensive_evaluation_5_3_2(self, hv: float, igd: float, gd: float) -> float:
        """5:3:2æƒé‡ç»¼åˆè¯„ä»·"""
        # å½’ä¸€åŒ–å¤„ç†
        norm_hv = min(hv / 1.21, 1.0)  # å‡è®¾æœ€å¤§HVä¸º1.21
        norm_igd = 1.0 / (1.0 + igd)   # è½¬æ¢ä¸ºè¶Šå¤§è¶Šå¥½
        norm_gd = 1.0 / (1.0 + gd)     # è½¬æ¢ä¸ºè¶Šå¤§è¶Šå¥½
        
        # åŠ æƒç»¼åˆ
        comprehensive_score = 0.5 * norm_hv + 0.3 * norm_igd + 0.2 * norm_gd
        return comprehensive_score
    
    def calculate_snr_comprehensive(self, scores: List[float]) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†çš„ä¿¡å™ªæ¯”"""
        if not scores or len(scores) == 0:
            return 0.0
        
        # ç”°å£æ–¹æ³•æœ›å¤§ç‰¹æ€§ä¿¡å™ªæ¯”
        snr = -10 * np.log10(np.mean(1.0 / np.array(scores) ** 2))
        return snr


class TaguchiAnalyzer:
    """ç”°å£åˆ†æå™¨"""
    
    def __init__(self, factor_levels: Dict):
        self.factor_levels = factor_levels
    
    def analyze(self, results: List[Dict]) -> Dict:
        """æ‰§è¡Œç”°å£åˆ†æ"""
        # æå–ä¿¡å™ªæ¯”æ•°æ®
        snr_data = self._extract_snr_data(results)
        
        # å› å­æ•ˆåº”åˆ†æ
        factor_effects = self._calculate_factor_effects(snr_data)
        
        # ç¡®å®šæœ€ä¼˜æ°´å¹³ç»„åˆ
        optimal_combination = self._determine_optimal_combination(factor_effects)
        
        # æ–¹å·®åˆ†æ
        anova_results = self._perform_anova(snr_data, factor_effects)
        
        # é¢„æµ‹æœ€ä¼˜æ€§èƒ½
        predicted_snr = self._predict_optimal_snr(factor_effects, optimal_combination)
        
        return {
            'factor_effects': factor_effects,
            'optimal_combination': optimal_combination,
            'anova_results': anova_results,
            'predicted_snr': predicted_snr,
            'snr_data': snr_data
        }
    
    def _extract_snr_data(self, results: List[Dict]) -> np.ndarray:
        """æå–ä¿¡å™ªæ¯”æ•°æ®"""
        snr_values = []
        for result in results:
            if 'statistics' in result and 'snr_value' in result['statistics']:
                snr_values.append(result['statistics']['snr_value'])
            else:
                snr_values.append(0.0)  # å¤±è´¥å®éªŒçš„SNRè®¾ä¸º0
        
        return np.array(snr_values)
    
    def _calculate_factor_effects(self, snr_data: np.ndarray) -> Dict:
        """è®¡ç®—å› å­æ•ˆåº”"""
        effects = {}
        factors = ['A', 'B', 'C', 'D']
        
        for factor in factors:
            effects[factor] = {}
            for level in range(1, 8):  # 7ä¸ªæ°´å¹³
                # æ‰¾åˆ°è¯¥å› å­è¯¥æ°´å¹³å¯¹åº”çš„å®éªŒ
                level_indices = self._get_level_indices(factor, level)
                level_snr_values = snr_data[level_indices]
                effects[factor][level] = np.mean(level_snr_values)
            
            # è®¡ç®—æ•ˆåº”èŒƒå›´
            level_means = list(effects[factor].values())
            effects[factor]['range'] = max(level_means) - min(level_means)
            effects[factor]['rank'] = 0  # å°†åœ¨åé¢è®¡ç®—æ’å
        
        # è®¡ç®—é‡è¦æ€§æ’å
        ranges = [(factor, effects[factor]['range']) for factor in factors]
        ranges.sort(key=lambda x: x[1], reverse=True)
        
        for rank, (factor, _) in enumerate(ranges, 1):
            effects[factor]['rank'] = rank
        
        return effects
    
    def _get_level_indices(self, factor: str, level: int) -> List[int]:
        """è·å–æŒ‡å®šå› å­æ°´å¹³å¯¹åº”çš„å®éªŒç´¢å¼•"""
        indices = []
        
        # æ ¹æ®L49æ­£äº¤è¡¨çš„å®é™…è®¾è®¡ç¡®å®šç´¢å¼•
        for exp_id in range(49):
            if factor == 'A':
                exp_level = (exp_id // 7) + 1
            elif factor == 'B':
                exp_level = ((exp_id % 7) + (exp_id // 7)) % 7 + 1
            elif factor == 'C':
                exp_level = ((exp_id % 7) * 2 + (exp_id // 7)) % 7 + 1
            else:  # factor == 'D'
                exp_level = ((exp_id % 7) * 3 + (exp_id // 7)) % 7 + 1
            
            if exp_level == level:
                indices.append(exp_id)
        
        return indices
    
    def _determine_optimal_combination(self, factor_effects: Dict) -> Dict:
        """ç¡®å®šæœ€ä¼˜å‚æ•°ç»„åˆ"""
        optimal = {}
        for factor in ['A', 'B', 'C', 'D']:
            # é€‰æ‹©ä¿¡å™ªæ¯”æœ€å¤§çš„æ°´å¹³
            best_level = max(
                range(1, 8), 
                key=lambda level: factor_effects[factor][level]
            )
            optimal[factor] = best_level
        
        return optimal
    
    def _perform_anova(self, snr_data: np.ndarray, factor_effects: Dict) -> Dict:
        """æ‰§è¡Œæ–¹å·®åˆ†æ"""
        # ç®€åŒ–çš„æ–¹å·®åˆ†æ
        grand_mean = np.mean(snr_data)
        sst = np.sum((snr_data - grand_mean) ** 2)  # æ€»å¹³æ–¹å’Œ
        
        anova = {}
        for factor in ['A', 'B', 'C', 'D']:
            # è®¡ç®—å› å­å¹³æ–¹å’Œ
            ss_factor = 0
            for level in range(1, 8):
                level_indices = self._get_level_indices(factor, level)
                level_mean = np.mean(snr_data[level_indices])
                ss_factor += len(level_indices) * (level_mean - grand_mean) ** 2
            
            # è®¡ç®—Få€¼ï¼ˆç®€åŒ–ï¼‰
            ms_factor = ss_factor / 6  # è‡ªç”±åº¦ = æ°´å¹³æ•° - 1
            ms_error = (sst - ss_factor) / (49 - 7)  # ç®€åŒ–çš„è¯¯å·®å‡æ–¹
            f_value = ms_factor / ms_error if ms_error > 0 else 0
            
            anova[factor] = {
                'sum_of_squares': ss_factor,
                'mean_square': ms_factor,
                'f_value': f_value,
                'contribution': ss_factor / sst * 100  # è´¡çŒ®ç‡%
            }
        
        return anova
    
    def _predict_optimal_snr(self, factor_effects: Dict, optimal_combination: Dict) -> float:
        """é¢„æµ‹æœ€ä¼˜ç»„åˆçš„ä¿¡å™ªæ¯”"""
        grand_mean = np.mean([
            np.mean(list(factor_effects[factor].values())[:7])  # å‰7ä¸ªæ˜¯æ°´å¹³å‡å€¼
            for factor in ['A', 'B', 'C', 'D']
        ])
        
        predicted_snr = grand_mean
        for factor in ['A', 'B', 'C', 'D']:
            optimal_level = optimal_combination[factor]
            level_effect = factor_effects[factor][optimal_level] - np.mean(
                list(factor_effects[factor].values())[:7]
            )
            predicted_snr += level_effect
        
        return predicted_snr


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹RL-Chaotic-HHO L49ç”°å£æ­£äº¤å®éªŒ")
    print("=" * 60)
    print("ğŸ“Š å®éªŒé…ç½®:")
    print("   - é—®é¢˜è§„æ¨¡: 100Ã—5Ã—3")
    print("   - æ€»æœºå™¨æ•°: 40å°")
    print("   - å®éªŒç»„æ•°: 49ç»„")
    print("   - æ¯ç»„é‡å¤: 10æ¬¡")
    print("   - æ€»å®éªŒé‡: 490æ¬¡")
    print("   - è¯„ä»·æŒ‡æ ‡: è¶…ä½“ç§¯:åå‘ä¸–ä»£è·ç¦»:ä¸–ä»£è·ç¦» = 5:3:2åŠ æƒç»¼åˆ")
    print("=" * 60)
    
    # åˆ›å»ºå®éªŒæ§åˆ¶å™¨
    experiment = TaguchiL49Experiment()
    
    # è¿è¡Œå®éªŒ
    start_time = time.time()
    try:
        all_results, taguchi_results = experiment.run_all_experiments()
        
        total_time = time.time() - start_time
        print(f"\nğŸ‰ å®éªŒå®Œæˆ! æ€»è€—æ—¶: {total_time/3600:.2f}å°æ—¶")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {experiment.results_dir}")
        
        # è¾“å‡ºå…³é”®ç»“æœ
        print("\nğŸ“ˆ ç”°å£åˆ†æç»“æœ:")
        optimal = taguchi_results['optimal_combination']
        print(f"   æœ€ä¼˜å­¦ä¹ ç‡: {experiment.factor_levels['A_learning_rate'][optimal['A']]}")
        print(f"   æœ€ä¼˜è¡°å‡ç‡: {experiment.factor_levels['B_epsilon_decay'][optimal['B']]}")
        print(f"   æœ€ä¼˜åˆ†ç»„æ¯”ä¾‹: {experiment.factor_levels['C_group_ratios'][optimal['C']]}")
        print(f"   æœ€ä¼˜æŠ˜æ‰£å› å­: {experiment.factor_levels['D_gamma'][optimal['D']]}")
        print(f"   é¢„æµ‹SNR: {taguchi_results['predicted_snr']:.2f}")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å®éªŒè¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 