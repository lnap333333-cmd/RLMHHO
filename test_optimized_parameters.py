#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\næµ‹è¯•åº”ç”¨ç”°å£å®éªŒæœ€ä¼˜å‚æ•°åçš„ç®—æ³•æ•ˆæœ\néªŒè¯ç¬¬32ç»„æœ€ä¼˜é…ç½®çš„å®é™…æ€§èƒ½\n\"\"\"\n\nimport time\nimport numpy as np\nfrom algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer\nfrom problem.mo_dhfsp import MO_DHFSP_Problem\nfrom utils.problem_generator import ProblemGenerator\nfrom utils.metrics_evaluator import MetricsEvaluator\n\ndef test_optimized_algorithm():\n    \"\"\"æµ‹è¯•åº”ç”¨æœ€ä¼˜å‚æ•°åçš„ç®—æ³•\"\"\"\n    print(\"ğŸš€ æµ‹è¯•ç”°å£å®éªŒæœ€ä¼˜å‚æ•°é…ç½®\")\n    print(\"=\" * 60)\n    \n    # ç”°å£å®éªŒç¬¬32ç»„æœ€ä¼˜é…ç½®\n    optimal_config = {\n        'learning_rate': 0.001,                    # Aå› å­æ°´å¹³5\n        'epsilon_decay': 0.995,                   # Bå› å­æ°´å¹³4  \n        'gamma': 0.98,                           # Då› å­æ°´å¹³5\n        'group_ratios': [0.70, 0.15, 0.10, 0.05], # Cå› å­æ°´å¹³1 - è¶…çº§æ¢ç´¢ä¸»å¯¼\n        'expected_snr': -15.998,                 # é¢„æœŸSNR\n        'expected_score': 0.170476               # é¢„æœŸåŠ æƒå¾—åˆ†\n    }\n    \n    print(\"ğŸ† åº”ç”¨çš„æœ€ä¼˜é…ç½®:\")\n    print(f\"  ğŸ“ˆ å­¦ä¹ ç‡: {optimal_config['learning_rate']:.6f}\")\n    print(f\"  ğŸ“‰ æ¢ç´¢ç‡è¡°å‡: {optimal_config['epsilon_decay']:.4f}\")\n    print(f\"  ğŸ¯ æŠ˜æ‰£å› å­: {optimal_config['gamma']:.3f}\")\n    print(f\"  ğŸ¦… é¹°ç¾¤åˆ†ç»„: æ¢ç´¢{optimal_config['group_ratios'][0]*100:.0f}% + å¼€å‘{optimal_config['group_ratios'][1]*100:.0f}% + å¹³è¡¡{optimal_config['group_ratios'][2]*100:.0f}% + ç²¾è‹±{optimal_config['group_ratios'][3]*100:.0f}%\")\n    print(f\"  ğŸŠ é¢„æœŸSNR: {optimal_config['expected_snr']:.3f} dB\")\n    \n    # åˆ›å»ºæµ‹è¯•é—®é¢˜ (ä¸ç”°å£å®éªŒç›¸åŒè§„æ¨¡)\n    generator = ProblemGenerator()\n    problem = generator.generate_heterogeneous_problem(\n        n_jobs=50,\n        n_factories=5,\n        n_stages=3,\n        machines_config=[\n            [3, 2, 2],  # å·¥å‚1: 7å°æœºå™¨\n            [3, 3, 2],  # å·¥å‚2: 8å°æœºå™¨\n            [2, 3, 3],  # å·¥å‚3: 8å°æœºå™¨\n            [3, 2, 3],  # å·¥å‚4: 8å°æœºå™¨\n            [3, 3, 3]   # å·¥å‚5: 9å°æœºå™¨\n        ]\n    )\n    \n    print(f\"\\nğŸ“‹ æµ‹è¯•é—®é¢˜:\")\n    print(f\"  ä½œä¸šæ•°: {problem.n_jobs}\")\n    print(f\"  å·¥å‚æ•°: {problem.n_factories}\")\n    print(f\"  é˜¶æ®µæ•°: {problem.n_stages}\")\n    print(f\"  æ€»æœºå™¨æ•°: {sum(sum(config) for config in [[3,2,2],[3,3,2],[2,3,3],[3,2,3],[3,3,3]])}å°\")\n    \n    # åˆ›å»ºä¼˜åŒ–ç®—æ³•å®ä¾‹ (è‡ªåŠ¨åº”ç”¨æœ€ä¼˜å‚æ•°)\n    optimizer = RL_ChaoticHHO_Optimizer(\n        problem=problem,\n        max_iterations=100,\n        population_size_override=50,\n        # ä¼ é€’æœ€ä¼˜å‚æ•°\n        learning_rate=optimal_config['learning_rate'],\n        epsilon_decay=optimal_config['epsilon_decay'],\n        gamma=optimal_config['gamma']\n    )\n    \n    print(f\"\\nğŸ”§ ç®—æ³•é…ç½®éªŒè¯:\")\n    print(f\"  RLå­¦ä¹ ç‡: {optimizer.rl_coordinator.learning_rate:.6f}\")\n    print(f\"  RLæ¢ç´¢è¡°å‡: {optimizer.rl_coordinator.epsilon_decay:.4f}\")\n    print(f\"  RLæŠ˜æ‰£å› å­: {optimizer.rl_coordinator.gamma:.3f}\")\n    print(f\"  é¹°ç¾¤åˆ†ç»„å·²åº”ç”¨æœ€ä¼˜é…ç½® âœ“\")\n    \n    # è¿è¡Œä¼˜åŒ–\n    print(f\"\\nğŸš€ å¼€å§‹ä¼˜åŒ–...\")\n    start_time = time.time()\n    \n    try:\n        pareto_solutions, convergence_data = optimizer.optimize()\n        runtime = time.time() - start_time\n        \n        # è¯„ä¼°æ€§èƒ½\n        evaluator = MetricsEvaluator()\n        metrics = evaluator.evaluate_performance(pareto_solutions, problem, runtime)\n        \n        print(f\"\\nğŸ‰ ä¼˜åŒ–å®Œæˆ!\")\n        print(f\"=\" * 60)\n        print(f\"ğŸ“Š æ€§èƒ½ç»“æœ:\")\n        print(f\"  è¿è¡Œæ—¶é—´: {runtime:.2f}ç§’\")\n        print(f\"  å¸•ç´¯æ‰˜è§£æ•°é‡: {len(pareto_solutions)}\")\n        print(f\"  è¶…ä½“ç§¯ (HV): {metrics['hypervolume']:.6f}\")\n        print(f\"  åå‘ä¸–ä»£è·ç¦» (IGD): {metrics['igd']:.6f}\")\n        print(f\"  ä¸–ä»£è·ç¦» (GD): {metrics['gd']:.6f}\")\n        \n        # è®¡ç®—åŠ æƒå¾—åˆ† (ç”°å£å®éªŒä¸­çš„5:3:2æƒé‡)\n        weighted_score = (\n            0.5 * metrics['hypervolume'] + \n            0.3 * (1.0 / (1.0 + metrics['igd'])) + \n            0.2 * (1.0 / (1.0 + metrics['gd']))\n        )\n        print(f\"  åŠ æƒå¾—åˆ†: {weighted_score:.6f}\")\n        \n        # è®¡ç®—SNRå€¼ (ç”°å£æ–¹æ³•)\n        snr_value = -10 * np.log10(1.0 / (weighted_score ** 2))\n        print(f\"  SNRå€¼: {snr_value:.3f} dB\")\n        \n        # ä¸æœŸæœ›æ€§èƒ½å¯¹æ¯”\n        print(f\"\\nğŸ¯ æ€§èƒ½å¯¹æ¯”åˆ†æ:\")\n        print(f\"  æœŸæœ›åŠ æƒå¾—åˆ†: {optimal_config['expected_score']:.6f}\")\n        print(f\"  å®é™…åŠ æƒå¾—åˆ†: {weighted_score:.6f}\")\n        performance_ratio = weighted_score / optimal_config['expected_score'] * 100\n        print(f\"  æ€§èƒ½è¾¾æˆç‡: {performance_ratio:.1f}%\")\n        \n        print(f\"  æœŸæœ›SNRå€¼: {optimal_config['expected_snr']:.3f} dB\")\n        print(f\"  å®é™…SNRå€¼: {snr_value:.3f} dB\")\n        snr_diff = snr_value - optimal_config['expected_snr']\n        print(f\"  SNRå·®å¼‚: {snr_diff:+.3f} dB\")\n        \n        # æ€§èƒ½è¯„ä»·\n        print(f\"\\nğŸ“ˆ æ•ˆæœè¯„ä»·:\")\n        if performance_ratio >= 95:\n            print(f\"  âœ… ä¼˜ç§€! è¾¾åˆ°ç”°å£å®éªŒé¢„æœŸæ°´å¹³\")\n        elif performance_ratio >= 85:\n            print(f\"  ğŸŸ¡ è‰¯å¥½! æ¥è¿‘ç”°å£å®éªŒé¢„æœŸ\")\n        elif performance_ratio >= 75:\n            print(f\"  ğŸ”µ ä¸€èˆ¬! æœ‰æ”¹è¿›ç©ºé—´\")\n        else:\n            print(f\"  ğŸ”´ å¾…ä¼˜åŒ–! éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´\")\n        \n        if snr_diff >= -1.0:\n            print(f\"  âœ… SNRè¡¨ç°è‰¯å¥½! ç¬¦åˆé¢„æœŸ\")\n        elif snr_diff >= -2.0:\n            print(f\"  ğŸŸ¡ SNRè¡¨ç°å¯æ¥å—\")\n        else:\n            print(f\"  ğŸ”´ SNRéœ€è¦æ”¹è¿›\")\n            \n        # åˆ†ææ”¶æ•›è¿‡ç¨‹\n        print(f\"\\nğŸ“Š æ”¶æ•›åˆ†æ:\")\n        if 'hypervolume_history' in convergence_data:\n            hv_history = convergence_data['hypervolume_history']\n            if len(hv_history) > 10:\n                early_hv = np.mean(hv_history[:10])\n                late_hv = np.mean(hv_history[-10:])\n                improvement = (late_hv - early_hv) / early_hv * 100\n                print(f\"  è¶…ä½“ç§¯æ”¹è¿›: {improvement:.1f}%\")\n                \n                if improvement > 10:\n                    print(f\"  âœ… æ”¶æ•›æ€§ä¼˜ç§€\")\n                elif improvement > 5:\n                    print(f\"  ğŸŸ¡ æ”¶æ•›æ€§è‰¯å¥½\")\n                else:\n                    print(f\"  ğŸ”µ æ”¶æ•›æ€§ä¸€èˆ¬\")\n        \n        return {\n            'success': True,\n            'metrics': metrics,\n            'weighted_score': weighted_score,\n            'snr_value': snr_value,\n            'performance_ratio': performance_ratio,\n            'snr_diff': snr_diff,\n            'runtime': runtime,\n            'pareto_size': len(pareto_solutions)\n        }\n        \n    except Exception as e:\n        print(f\"âŒ ä¼˜åŒ–å¤±è´¥: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return {'success': False, 'error': str(e)}\n\ndef run_multiple_tests(n_runs=3):\n    \"\"\"è¿è¡Œå¤šæ¬¡æµ‹è¯•ä»¥éªŒè¯ç¨³å®šæ€§\"\"\"\n    print(f\"\\nğŸ”„ è¿è¡Œ {n_runs} æ¬¡æµ‹è¯•éªŒè¯ç¨³å®šæ€§\")\n    print(\"=\" * 60)\n    \n    results = []\n    for i in range(n_runs):\n        print(f\"\\nğŸ“‹ ç¬¬ {i+1}/{n_runs} æ¬¡æµ‹è¯•\")\n        print(\"-\" * 40)\n        result = test_optimized_algorithm()\n        if result['success']:\n            results.append(result)\n        else:\n            print(f\"ç¬¬{i+1}æ¬¡æµ‹è¯•å¤±è´¥\")\n    \n    if not results:\n        print(\"âŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº†\")\n        return\n    \n    # ç»Ÿè®¡åˆ†æ\n    print(f\"\\nğŸ“Š {len(results)} æ¬¡æµ‹è¯•ç»Ÿè®¡åˆ†æ\")\n    print(\"=\" * 60)\n    \n    scores = [r['weighted_score'] for r in results]\n    snrs = [r['snr_value'] for r in results]\n    ratios = [r['performance_ratio'] for r in results]\n    runtimes = [r['runtime'] for r in results]\n    \n    print(f\"åŠ æƒå¾—åˆ†ç»Ÿè®¡:\")\n    print(f\"  å¹³å‡: {np.mean(scores):.6f} Â± {np.std(scores):.6f}\")\n    print(f\"  æœ€ä½³: {np.max(scores):.6f}\")\n    print(f\"  æœ€å·®: {np.min(scores):.6f}\")\n    \n    print(f\"\\nSNRç»Ÿè®¡:\")\n    print(f\"  å¹³å‡: {np.mean(snrs):.3f} Â± {np.std(snrs):.3f} dB\")\n    print(f\"  æœ€ä½³: {np.max(snrs):.3f} dB\")\n    print(f\"  æœ€å·®: {np.min(snrs):.3f} dB\")\n    \n    print(f\"\\næ€§èƒ½è¾¾æˆç‡ç»Ÿè®¡:\")\n    print(f\"  å¹³å‡: {np.mean(ratios):.1f}% Â± {np.std(ratios):.1f}%\")\n    print(f\"  æœ€ä½³: {np.max(ratios):.1f}%\")\n    print(f\"  æœ€å·®: {np.min(ratios):.1f}%\")\n    \n    print(f\"\\nè¿è¡Œæ—¶é—´ç»Ÿè®¡:\")\n    print(f\"  å¹³å‡: {np.mean(runtimes):.2f} Â± {np.std(runtimes):.2f} ç§’\")\n    \n    # ç¨³å®šæ€§è¯„ä»·\n    score_cv = np.std(scores) / np.mean(scores) * 100\n    snr_cv = np.std(snrs) / abs(np.mean(snrs)) * 100\n    \n    print(f\"\\nğŸ¯ ç¨³å®šæ€§è¯„ä»·:\")\n    print(f\"  åŠ æƒå¾—åˆ†å˜å¼‚ç³»æ•°: {score_cv:.2f}%\")\n    print(f\"  SNRå˜å¼‚ç³»æ•°: {snr_cv:.2f}%\")\n    \n    if score_cv < 5 and snr_cv < 10:\n        print(f\"  âœ… ç®—æ³•æ€§èƒ½éå¸¸ç¨³å®š\")\n    elif score_cv < 10 and snr_cv < 20:\n        print(f\"  ğŸŸ¡ ç®—æ³•æ€§èƒ½è¾ƒç¨³å®š\")\n    else:\n        print(f\"  ğŸ”´ ç®—æ³•æ€§èƒ½æ³¢åŠ¨è¾ƒå¤§\")\n\ndef main():\n    \"\"\"ä¸»å‡½æ•°\"\"\"\n    print(\"ğŸ”¬ ç”°å£å®éªŒæœ€ä¼˜å‚æ•°æ•ˆæœéªŒè¯\")\n    print(\"=\" * 60)\n    print(\"åº”ç”¨é…ç½®: ç¬¬32ç»„æœ€ä¼˜å‚æ•°\")\n    print(\"å­¦ä¹ ç‡: 0.001 | æ¢ç´¢è¡°å‡: 0.995 | æŠ˜æ‰£å› å­: 0.98\")\n    print(\"é¹°ç¾¤åˆ†ç»„: æ¢ç´¢70% + å¼€å‘15% + å¹³è¡¡10% + ç²¾è‹±5%\")\n    print(\"=\" * 60)\n    \n    # å•æ¬¡æµ‹è¯•\n    result = test_optimized_algorithm()\n    \n    if result['success']:\n        print(f\"\\nâœ… å•æ¬¡æµ‹è¯•æˆåŠŸ!\")\n        \n        # è¯¢é—®æ˜¯å¦è¿›è¡Œå¤šæ¬¡æµ‹è¯•\n        print(f\"\\nğŸ”„ å»ºè®®è¿è¡Œå¤šæ¬¡æµ‹è¯•éªŒè¯ç¨³å®šæ€§\")\n        print(f\"è¿è¡Œå¤šæ¬¡æµ‹è¯•ä»¥è·å¾—æ›´å¯é çš„ç»Ÿè®¡ç»“æœ...\")\n        \n        # è¿è¡Œå¤šæ¬¡æµ‹è¯•\n        run_multiple_tests(3)\n        \n    else:\n        print(f\"\\nâŒ æµ‹è¯•å¤±è´¥\")\n        \n    print(f\"\\nğŸ‰ éªŒè¯å®Œæˆ!\")\n    print(f\"å‚æ•°é…ç½®å·²æˆåŠŸåº”ç”¨åˆ°ä¸»ä½“ç®—æ³•ä¸­\")\n\nif __name__ == \"__main__\":\n    main() 