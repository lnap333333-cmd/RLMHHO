#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¡¨æ ¼æ ¼å¼ç®—æ³•å¯¹æ¯”å®éªŒç¨‹åº - åŒ…å«QL-ABCç®—æ³•
å¯¹æ¯”ç®—æ³•ï¼šRL-Chaotic-HHOã€I-NSGA-IIã€MOEA/Dã€MOPSOã€MODEã€DQNã€QL-ABC
ç»Ÿä¸€å‚æ•°è®¾ç½®ç¡®ä¿å…¬å¹³æ¯”è¾ƒï¼š
- æ‰€æœ‰ç®—æ³•ç§ç¾¤å¤§å°ï¼š50
- æ‰€æœ‰ç®—æ³•è¿­ä»£æ¬¡æ•°ï¼š50
ç»“æœæ ¼å¼ï¼šåˆ†ç¦»è¡¨æ ¼æ˜¾ç¤ºæœ€ä¼˜å€¼ã€å¹³å‡å€¼ã€è¿è¡Œæ—¶é—´
åŒ…å«å®Œå·¥æ—¶é—´ã€æ‹–æœŸå’Œå¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾
æ”¯æŒå®Œå…¨å¼‚æ„çš„æœºå™¨é…ç½®
"""

import os
import time
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from typing import Dict, List, Tuple

from problem.mo_dhfsp import MO_DHFSP_Problem
from algorithm.rl_chaotic_hho import RL_ChaoticHHO_Optimizer
from algorithm.improved_nsga2 import ImprovedNSGA2_Optimizer
from algorithm.moead import MOEAD_Optimizer
from algorithm.mopso import MOPSO_Optimizer
from algorithm.mode import MODE_Optimizer
from algorithm.dqn_algorithm_wrapper import DQNAlgorithmWrapper
from algorithm.ql_abc import QLABC_Optimizer
from utils.data_generator import DataGenerator

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

def generate_custom_urgencies(n_jobs: int, urgency_range: List[float]) -> List[float]:
    """
    ç”ŸæˆæŒ‡å®šèŒƒå›´çš„ç´§æ€¥åº¦
    
    Args:
        n_jobs: ä½œä¸šæ•°é‡
        urgency_range: [æœ€å°å€¼, å¹³å‡å€¼, æœ€å¤§å€¼]
    
    Returns:
        ç´§æ€¥åº¦åˆ—è¡¨
    """
    min_val, avg_val, max_val = urgency_range
    
    # ç”Ÿæˆæ­£æ€åˆ†å¸ƒçš„ç´§æ€¥åº¦ï¼Œå‡å€¼ä¸ºavg_val
    std_dev = (max_val - min_val) / 6  # 6ä¸ªæ ‡å‡†å·®è¦†ç›–èŒƒå›´
    urgencies = np.random.normal(avg_val, std_dev, n_jobs)
    
    # é™åˆ¶åœ¨æŒ‡å®šèŒƒå›´å†…
    urgencies = np.clip(urgencies, min_val, max_val)
    
    # ç¡®ä¿è¾¹ç•Œå€¼çš„å­˜åœ¨
    urgencies[0] = min_val
    urgencies[1] = max_val
    urgencies[2] = avg_val
    
    return urgencies.tolist()

def generate_heterogeneous_problem_data(config: Dict) -> Dict:
    """
    ç”Ÿæˆå¼‚æ„æœºå™¨é…ç½®çš„é—®é¢˜æ•°æ®
    
    Args:
        config: å®éªŒé…ç½®
        
    Returns:
        é—®é¢˜æ•°æ®å­—å…¸
    """
    generator = DataGenerator(seed=42)
    
    # ç”ŸæˆåŸºç¡€é—®é¢˜æ•°æ®ï¼ˆä½¿ç”¨å¹³å‡æœºå™¨é…ç½®ï¼‰
    problem_data = generator.generate_problem(
        n_jobs=config['n_jobs'],
        n_factories=config['n_factories'],
        n_stages=config['n_stages'],
        machines_per_stage=config['machines_per_stage'],
        processing_time_range=config['processing_time_range'],
        due_date_tightness=1.5
    )
    
    # ä½¿ç”¨è‡ªå®šä¹‰ç´§æ€¥åº¦
    problem_data['urgencies'] = generate_custom_urgencies(
        config['n_jobs'], 
        config['urgency_ddt']
    )
    
    # æ·»åŠ å¼‚æ„æœºå™¨é…ç½®ä¿¡æ¯
    problem_data['heterogeneous_machines'] = config['heterogeneous_machines']
    
    return problem_data

def run_single_experiment(problem_config: Dict, algorithm_name: str, algorithm_class, algorithm_params: Dict, runs: int = 3) -> Dict:
    """
    è¿è¡Œå•ä¸ªç®—æ³•çš„å¤šæ¬¡å®éªŒ
    
    Args:
        problem_config: é—®é¢˜é…ç½®
        algorithm_name: ç®—æ³•åç§°
        algorithm_class: ç®—æ³•ç±»
        algorithm_params: ç®—æ³•å‚æ•°
        runs: è¿è¡Œæ¬¡æ•°
        
    Returns:
        ç»Ÿè®¡ç»“æœå­—å…¸
    """
    print(f"  æ­£åœ¨è¿è¡Œ {algorithm_name} ({runs}æ¬¡è¿è¡Œ)...")
    
    weighted_values = []    # å­˜å‚¨åŠ æƒç›®æ ‡å‡½æ•°å€¼
    makespan_values = []   # å­˜å‚¨å®Œå·¥æ—¶é—´
    tardiness_values = []  # å­˜å‚¨æ€»æ‹–æœŸ
    runtimes = []
    all_pareto_solutions = []  # å­˜å‚¨æ‰€æœ‰å¸•ç´¯æ‰˜è§£
    
    for run in range(runs):
        try:
            # åˆ›å»ºé—®é¢˜å®ä¾‹
            problem = MO_DHFSP_Problem(problem_config)
            
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = algorithm_class(problem, **algorithm_params)
            
            # è®°å½•è¿è¡Œæ—¶é—´
            start_time = time.time()
            
            # è¿è¡Œä¼˜åŒ–
            pareto_solutions, convergence_data = optimizer.optimize()
            
            end_time = time.time()
            runtime = end_time - start_time
            runtimes.append(runtime)
            
            # è®¡ç®—ç›®æ ‡å‡½æ•°å€¼
            if pareto_solutions:
                # è®¡ç®—å„ç§æŒ‡æ ‡çš„æœ€ä¼˜å€¼
                makespans = [sol.makespan for sol in pareto_solutions]
                tardiness = [sol.total_tardiness for sol in pareto_solutions]
                weighted_objs = [0.55 * sol.makespan + 0.45 * sol.total_tardiness for sol in pareto_solutions]
                
                weighted_values.append(min(weighted_objs))
                makespan_values.append(min(makespans))
                tardiness_values.append(min(tardiness))
                
                # æ”¶é›†å¸•ç´¯æ‰˜è§£ç”¨äºç»˜å›¾ (åªæ”¶é›†ç¬¬ä¸€æ¬¡è¿è¡Œçš„)
                if run == 0:
                    all_pareto_solutions = pareto_solutions
            else:
                weighted_values.append(float('inf'))
                makespan_values.append(float('inf'))
                tardiness_values.append(float('inf'))
                
            print(f"    è¿è¡Œ {run+1}/{runs}: åŠ æƒç›®æ ‡={weighted_values[-1]:.2f}, å®Œå·¥æ—¶é—´={makespan_values[-1]:.2f}, æ‹–æœŸ={tardiness_values[-1]:.2f}, æ—¶é—´={runtime:.2f}s")
            
        except Exception as e:
            print(f"    è¿è¡Œ {run+1}/{runs} å¤±è´¥: {str(e)}")
            weighted_values.append(float('inf'))
            makespan_values.append(float('inf'))
            tardiness_values.append(float('inf'))
            runtimes.append(0.0)
    
    # è®¡ç®—ç»Ÿè®¡ç»“æœ
    valid_weighted = [v for v in weighted_values if v != float('inf')]
    valid_makespans = [v for v in makespan_values if v != float('inf')]
    valid_tardiness = [v for v in tardiness_values if v != float('inf')]
    
    if valid_weighted:
        results = {
            'weighted_best': min(valid_weighted),
            'weighted_mean': np.mean(valid_weighted),
            'makespan_best': min(valid_makespans),
            'makespan_mean': np.mean(valid_makespans),
            'tardiness_best': min(valid_tardiness),
            'tardiness_mean': np.mean(valid_tardiness),
            'runtime': np.mean(runtimes),
            'pareto_solutions': all_pareto_solutions
        }
    else:
        results = {
            'weighted_best': float('inf'),
            'weighted_mean': float('inf'),
            'makespan_best': float('inf'),
            'makespan_mean': float('inf'),
            'tardiness_best': float('inf'),
            'tardiness_mean': float('inf'),
            'runtime': 0.0,
            'pareto_solutions': []
        }
    
    return results

def plot_pareto_comparison(all_results: Dict, scale: str):
    """ç»˜åˆ¶å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾"""
    
    plt.figure(figsize=(12, 8))
    
    colors = ['red', 'blue', 'cyan', 'green', 'orange', 'purple', 'brown']
    markers = ['o', 's', 'p', '^', 'D', 'v', 'x']
    algorithm_names = ['RL-Chaotic-HHO', 'I-NSGA-II', 'MOEA/D', 'MOPSO', 'MODE', 'DQN', 'QL-ABC']
    
    for i, (alg_name, results) in enumerate(all_results.items()):
        if results['pareto_solutions']:
            makespans = [sol.makespan for sol in results['pareto_solutions']]
            tardiness = [sol.total_tardiness for sol in results['pareto_solutions']]
            
            plt.scatter(makespans, tardiness, 
                       c=colors[i % len(colors)], 
                       marker=markers[i % len(markers)], 
                       s=50, alpha=0.7, label=alg_name)
    
    plt.xlabel('å®Œå·¥æ—¶é—´ (Makespan)', fontsize=12)
    plt.ylabel('æ€»æ‹–æœŸ (Total Tardiness)', fontsize=12)
    plt.title(f'å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾ - {scale}è§„æ¨¡é—®é¢˜\n(åŒ…å«QL-ABCç®—æ³•)', fontsize=14)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    plt.savefig(f'pareto_comparison_with_ql_abc_{scale}_{timestamp}.png', dpi=300, bbox_inches='tight')
    plt.show()

def print_scale_details(config: Dict, problem_data: Dict):
    """æ‰“å°é—®é¢˜è§„æ¨¡è¯¦ç»†ä¿¡æ¯"""
    print(f"\né—®é¢˜é…ç½®è¯¦æƒ…:")
    print(f"  ä½œä¸šæ•°: {config['n_jobs']}")
    print(f"  å·¥å‚æ•°: {config['n_factories']}")
    print(f"  é˜¶æ®µæ•°: {config['n_stages']}")
    print(f"  å¹³å‡æœºå™¨é…ç½®: {config['machines_per_stage']}")
    print(f"  å¤„ç†æ—¶é—´èŒƒå›´: {config['processing_time_range']}")
    print(f"  ç´§æ€¥åº¦èŒƒå›´: {config['urgency_ddt']}")
    
    # è®¡ç®—æ€»æœºå™¨æ•°
    if 'heterogeneous_machines' in config:
        total_machines = sum(sum(stages) for stages in config['heterogeneous_machines'].values())
        print(f"  æ€»æœºå™¨æ•°: {total_machines}")
        print(f"  å„å·¥å‚æœºå™¨åˆ†å¸ƒ:")
        for factory_id, machines in config['heterogeneous_machines'].items():
            print(f"    å·¥å‚ {factory_id}: {machines} (åˆè®¡: {sum(machines)})")

def run_table_format_experiments():
    """è¿è¡Œè¡¨æ ¼æ ¼å¼çš„ç®—æ³•å¯¹æ¯”å®éªŒï¼ˆåŒ…å«QL-ABCï¼‰"""
    
    print("ğŸš€ å¼€å§‹è¡¨æ ¼æ ¼å¼ç®—æ³•å¯¹æ¯”å®éªŒ (åŒ…å«QL-ABCç®—æ³•)")
    print("=" * 80)
    
    # å®éªŒé…ç½®
    configs = [
        {
            'name': 'å°è§„æ¨¡',
            'n_jobs': 20,
            'n_factories': 3,
            'n_stages': 2,
            'machines_per_stage': [3, 4],
            'processing_time_range': (1, 15),
            'urgency_ddt': [0.8, 1.5, 2.2],
            'heterogeneous_machines': {
                0: [3, 4],  # å·¥å‚1: 7å°æœºå™¨
                1: [2, 5],  # å·¥å‚2: 7å°æœºå™¨
                2: [4, 3]   # å·¥å‚3: 7å°æœºå™¨
            }
        },
        {
            'name': 'ä¸­è§„æ¨¡',
            'n_jobs': 50,
            'n_factories': 4,
            'n_stages': 3,
            'machines_per_stage': [4, 4, 4],
            'processing_time_range': (1, 25),
            'urgency_ddt': [1.0, 1.8, 2.8],
            'heterogeneous_machines': {
                0: [4, 4, 4],  # å·¥å‚1: 12å°æœºå™¨
                1: [3, 5, 3],  # å·¥å‚2: 11å°æœºå™¨
                2: [5, 3, 4],  # å·¥å‚3: 12å°æœºå™¨
                3: [3, 4, 5]   # å·¥å‚4: 12å°æœºå™¨
            }
        },
        {
            'name': 'å¤§è§„æ¨¡',
            'n_jobs': 100,
            'n_factories': 5,
            'n_stages': 3,
            'machines_per_stage': [6, 6, 6],
            'processing_time_range': (1, 30),
            'urgency_ddt': [1.2, 2.0, 3.0],
            'heterogeneous_machines': {
                0: [6, 6, 6],  # å·¥å‚1: 18å°æœºå™¨
                1: [5, 7, 6],  # å·¥å‚2: 18å°æœºå™¨
                2: [7, 5, 6],  # å·¥å‚3: 18å°æœºå™¨
                3: [6, 6, 6],  # å·¥å‚4: 18å°æœºå™¨
                4: [4, 8, 6]   # å·¥å‚5: 18å°æœºå™¨
            }
        }
    ]
    
    # ç®—æ³•é…ç½®ï¼ˆç»Ÿä¸€å‚æ•°ï¼‰
    common_params = {
        'population_size': 50,
        'max_iterations': 50
    }
    
    algorithms = {
        'RL-Chaotic-HHO': (RL_ChaoticHHO_Optimizer, {
            **common_params,
            'archive_size': 100,
            'learning_rate': 0.001,
            'epsilon': 0.1
        }),
        'I-NSGA-II': (ImprovedNSGA2_Optimizer, {
            **common_params,
            'crossover_prob': 0.9,
            'mutation_prob': 0.1
        }),
        'MOEA/D': (MOEAD_Optimizer, {
            **common_params,
            'crossover_prob': 0.9,
            'mutation_prob': 0.1
        }),
        'MOPSO': (MOPSO_Optimizer, {
            **common_params,
            'w': 0.4,
            'c1': 2.0,
            'c2': 2.0
        }),
        'MODE': (MODE_Optimizer, {
            **common_params,
            'crossover_prob': 0.9,
            'mutation_factor': 0.5
        }),
        'DQN': (DQNAlgorithmWrapper, {
            **common_params,
            'learning_rate': 0.001,
            'epsilon': 0.1
        }),
        'QL-ABC': (QLABC_Optimizer, {
            **common_params,
            'learning_rate': 0.1,
            'epsilon': 0.05,
            'limit': 10
        })
    }
    
    all_scale_results = {}
    
    # å¯¹æ¯ä¸ªè§„æ¨¡è¿è¡Œå®éªŒ
    for config in configs:
        scale_name = config['name']
        print(f"\nğŸ”¬ è¿è¡Œ{scale_name}å®éªŒ")
        print("=" * 60)
        
        # æ‰“å°è§„æ¨¡è¯¦æƒ…
        print_scale_details(config, {})
        
        # ç”Ÿæˆé—®é¢˜æ•°æ®
        problem_data = generate_heterogeneous_problem_data(config)
        
        # å­˜å‚¨è¯¥è§„æ¨¡çš„ç»“æœ
        scale_results = {}
        
        # è¿è¡Œæ¯ä¸ªç®—æ³•
        for alg_name, (alg_class, alg_params) in algorithms.items():
            results = run_single_experiment(
                problem_data, alg_name, alg_class, alg_params, runs=3
            )
            scale_results[alg_name] = results
        
        all_scale_results[scale_name] = scale_results
        
        # ç»˜åˆ¶è¯¥è§„æ¨¡çš„å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾
        print(f"\nğŸ“Š ç»˜åˆ¶{scale_name}å¸•ç´¯æ‰˜å‰æ²¿å¯¹æ¯”å›¾...")
        plot_pareto_comparison(scale_results, scale_name)
    
    # ç”Ÿæˆç»¼åˆå¯¹æ¯”æŠ¥å‘Š
    generate_enhanced_table_report(all_scale_results, configs)

def generate_enhanced_table_report(results: Dict, configs: List[Dict]):
    """ç”Ÿæˆå¢å¼ºç‰ˆè¡¨æ ¼å¯¹æ¯”æŠ¥å‘Šï¼ˆåŒ…å«QL-ABCï¼‰"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"algorithm_comparison_with_ql_abc_{timestamp}.txt"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("å¤šç›®æ ‡åˆ†å¸ƒå¼æ··åˆæµæ°´è½¦é—´è°ƒåº¦ç®—æ³•å¯¹æ¯”æŠ¥å‘Š (åŒ…å«QL-ABC)\n")
        f.write("=" * 80 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"å¯¹æ¯”ç®—æ³•: RL-Chaotic-HHO, I-NSGA-II, MOEA/D, MOPSO, MODE, DQN, QL-ABC\n")
        f.write(f"ç»Ÿä¸€å‚æ•°: ç§ç¾¤å¤§å°=50, è¿­ä»£æ¬¡æ•°=50\n\n")
        
        # ä¸ºæ¯ä¸ªè§„æ¨¡ç”Ÿæˆè¡¨æ ¼
        for scale_name, scale_results in results.items():
            f.write(f"{scale_name}é—®é¢˜å¯¹æ¯”ç»“æœ\n")
            f.write("-" * 60 + "\n")
            
            # æœ€ä¼˜å€¼è¡¨æ ¼
            f.write("æœ€ä¼˜å€¼å¯¹æ¯”:\n")
            f.write(f"{'ç®—æ³•':<15} {'å®Œå·¥æ—¶é—´':<12} {'æ‹–æœŸ':<12} {'åŠ æƒç›®æ ‡':<12} {'å¸•ç´¯æ‰˜è§£':<10} {'è¿è¡Œæ—¶é—´(s)':<12}\n")
            f.write("-" * 80 + "\n")
            
            for alg_name, alg_results in scale_results.items():
                f.write(f"{alg_name:<15} {alg_results['makespan_best']:<12.2f} "
                       f"{alg_results['tardiness_best']:<12.2f} {alg_results['weighted_best']:<12.2f} "
                       f"{len(alg_results['pareto_solutions']):<10} {alg_results['runtime']:<12.2f}\n")
            
            f.write("\n")
            
            # å¹³å‡å€¼è¡¨æ ¼
            f.write("å¹³å‡å€¼å¯¹æ¯”:\n")
            f.write(f"{'ç®—æ³•':<15} {'å®Œå·¥æ—¶é—´':<12} {'æ‹–æœŸ':<12} {'åŠ æƒç›®æ ‡':<12}\n")
            f.write("-" * 60 + "\n")
            
            for alg_name, alg_results in scale_results.items():
                f.write(f"{alg_name:<15} {alg_results['makespan_mean']:<12.2f} "
                       f"{alg_results['tardiness_mean']:<12.2f} {alg_results['weighted_mean']:<12.2f}\n")
            
            f.write("\n" + "="*80 + "\n")
        
        # ç®—æ³•æ’ååˆ†æ
        f.write("ç®—æ³•æ€§èƒ½æ’ååˆ†æ (åŸºäºåŠ æƒç›®æ ‡å‡½æ•°)\n")
        f.write("-" * 50 + "\n")
        
        for scale_name, scale_results in results.items():
            f.write(f"\n{scale_name}æ’å:\n")
            
            # æŒ‰åŠ æƒç›®æ ‡å‡½æ•°æ’åº
            sorted_algorithms = sorted(scale_results.items(), 
                                     key=lambda x: x[1]['weighted_best'])
            
            for rank, (alg_name, alg_results) in enumerate(sorted_algorithms, 1):
                f.write(f"  {rank}. {alg_name}: {alg_results['weighted_best']:.2f}\n")
        
        # QL-ABCæ€§èƒ½è¯„ä»·
        f.write("\nQL-ABCç®—æ³•æ€§èƒ½è¯„ä»·:\n")
        f.write("-" * 30 + "\n")
        
        for scale_name, scale_results in results.items():
            ql_abc_results = scale_results.get('QL-ABC', {})
            hho_results = scale_results.get('RL-Chaotic-HHO', {})
            
            if ql_abc_results and hho_results:
                ql_abc_weighted = ql_abc_results['weighted_best']
                hho_weighted = hho_results['weighted_best']
                
                if ql_abc_weighted != float('inf') and hho_weighted != float('inf'):
                    improvement = (hho_weighted - ql_abc_weighted) / hho_weighted * 100
                    f.write(f"{scale_name}: QL-ABC vs RL-Chaotic-HHO = {improvement:+.2f}%\n")
    
    print(f"\nğŸ“„ ç»¼åˆå¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        run_table_format_experiments()
        print("\nâœ… è¡¨æ ¼æ ¼å¼ç®—æ³•å¯¹æ¯”å®éªŒå®Œæˆï¼")
        return True
    except Exception as e:
        print(f"\nâŒ å®éªŒå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ åŒ…å«QL-ABCçš„ç®—æ³•å¯¹æ¯”å®éªŒæˆåŠŸå®Œæˆï¼")
    else:
        print("\nğŸ’¥ å®éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚") 